{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example-Based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of the Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the Tagalog Part of Speech Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in the dataset: 17740\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tokenized</th>\n",
       "      <th>Single Word</th>\n",
       "      <th>Determiner</th>\n",
       "      <th>Conjunction</th>\n",
       "      <th>Verb</th>\n",
       "      <th>Noun</th>\n",
       "      <th>Adjective</th>\n",
       "      <th>Adverb</th>\n",
       "      <th>Preposition</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GENESIS</td>\n",
       "      <td>[genesis]</td>\n",
       "      <td>[genesis]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[SW]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nilalang ng Dios ang sanglibutan.</td>\n",
       "      <td>[nilalang, ng, dios, ang, sanglibutan]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ng, ang]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[nilalang]</td>\n",
       "      <td>[dios, sanglibutan]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VB, DT, NN, DT, NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nang pasimula ay nilikha ng Dios ang langit at...</td>\n",
       "      <td>[nang, pasimula, ay, nilikha, ng, dios, ang, l...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[nang, ay, ng, ang, ang]</td>\n",
       "      <td>[at]</td>\n",
       "      <td>[nilikha]</td>\n",
       "      <td>[dios, langit, lupa]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[pasimula]</td>\n",
       "      <td>[DT, UNK, DT, VB, DT, NN, DT, NN, CC, DT, NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>At ang lupa ay walang anyo at walang laman; at...</td>\n",
       "      <td>[at, ang, lupa, ay, walang, anyo, at, walang, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ang, ay, ang, ay, sumasa, ng, ang, ng, ay, su...</td>\n",
       "      <td>[at, at, at, at]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[lupa, anyo, laman, kadiliman, kalaliman, espi...</td>\n",
       "      <td>[walang, walang]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ibabaw, ibabaw]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[CC, DT, NN, DT, JJ, NN, CC, JJ, NN, CC, DT, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>At sinabi ng Dios Magkaroon ng liwanag; at nag...</td>\n",
       "      <td>[at, sinabi, ng, dios, magkaroon, ng, liwanag,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ng, ng, ng]</td>\n",
       "      <td>[at, at]</td>\n",
       "      <td>[sinabi, magkaroon, nagkaroon]</td>\n",
       "      <td>[dios, liwanag, liwanag]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[CC, VB, DT, NN, VB, DT, NN, CC, VB, DT, NN]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0                                            GENESIS   \n",
       "1                  Nilalang ng Dios ang sanglibutan.   \n",
       "2  Nang pasimula ay nilikha ng Dios ang langit at...   \n",
       "3  At ang lupa ay walang anyo at walang laman; at...   \n",
       "4  At sinabi ng Dios Magkaroon ng liwanag; at nag...   \n",
       "\n",
       "                                           Tokenized Single Word  \\\n",
       "0                                          [genesis]   [genesis]   \n",
       "1             [nilalang, ng, dios, ang, sanglibutan]          []   \n",
       "2  [nang, pasimula, ay, nilikha, ng, dios, ang, l...          []   \n",
       "3  [at, ang, lupa, ay, walang, anyo, at, walang, ...          []   \n",
       "4  [at, sinabi, ng, dios, magkaroon, ng, liwanag,...          []   \n",
       "\n",
       "                                          Determiner       Conjunction  \\\n",
       "0                                                 []                []   \n",
       "1                                          [ng, ang]                []   \n",
       "2                           [nang, ay, ng, ang, ang]              [at]   \n",
       "3  [ang, ay, ang, ay, sumasa, ng, ang, ng, ay, su...  [at, at, at, at]   \n",
       "4                                       [ng, ng, ng]          [at, at]   \n",
       "\n",
       "                             Verb  \\\n",
       "0                              []   \n",
       "1                      [nilalang]   \n",
       "2                       [nilikha]   \n",
       "3                              []   \n",
       "4  [sinabi, magkaroon, nagkaroon]   \n",
       "\n",
       "                                                Noun         Adjective Adverb  \\\n",
       "0                                                 []                []     []   \n",
       "1                                [dios, sanglibutan]                []     []   \n",
       "2                               [dios, langit, lupa]                []     []   \n",
       "3  [lupa, anyo, laman, kadiliman, kalaliman, espi...  [walang, walang]     []   \n",
       "4                           [dios, liwanag, liwanag]                []     []   \n",
       "\n",
       "        Preposition     Unknown  \\\n",
       "0                []          []   \n",
       "1                []          []   \n",
       "2                []  [pasimula]   \n",
       "3  [ibabaw, ibabaw]          []   \n",
       "4                []          []   \n",
       "\n",
       "                                                 POS  \n",
       "0                                               [SW]  \n",
       "1                               [VB, DT, NN, DT, NN]  \n",
       "2      [DT, UNK, DT, VB, DT, NN, DT, NN, CC, DT, NN]  \n",
       "3  [CC, DT, NN, DT, JJ, NN, CC, JJ, NN, CC, DT, N...  \n",
       "4       [CC, VB, DT, NN, VB, DT, NN, CC, VB, DT, NN]  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the tagalog POS dataset\n",
    "tl_pos_data = pd.read_json('../../src/json data/Tagalog to Ilokano/tl_pos.json')\n",
    "\n",
    "tl_doc_len = len(tl_pos_data)\n",
    "\n",
    "print('Number of documents in the dataset: {}'.format(tl_doc_len))\n",
    "\n",
    "tl_pos_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the Ilokano Part of Speech Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in the dataset: 17740\n"
     ]
    }
   ],
   "source": [
    "# Read the ilokano POS dataset\n",
    "il_pos_data = pd.read_json('../../src/json data/Ilokano to Tagalog/il_pos.json')\n",
    "\n",
    "il_doc_len = len(il_pos_data)\n",
    "\n",
    "il_pos_data.head()\n",
    "\n",
    "print('Number of documents in the dataset: {}'.format(il_doc_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the Tagalog Part of Speech Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sen_poss = pd.DataFrame(tl_pos_data['POS'])\n",
    "\n",
    "dict_sen_poss.columns = ['Tagalog POS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the Ilokano Part of Speech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tagalog POS</th>\n",
       "      <th>Ilokano POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[SW]</td>\n",
       "      <td>[SW]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[VB, DT, NN, DT, NN]</td>\n",
       "      <td>[DT, VB, DT, NN, DT, NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[DT, UNK, DT, VB, DT, NN, DT, NN, CC, DT, NN]</td>\n",
       "      <td>[DT, NN, DT, NN, VB, DT, NN, DT, DT, NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CC, DT, NN, DT, JJ, NN, CC, JJ, NN, CC, DT, N...</td>\n",
       "      <td>[CC, DT, NN, VB, DT, DT, NN, DT, JJ, NN, CC, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CC, VB, DT, NN, VB, DT, NN, CC, VB, DT, NN]</td>\n",
       "      <td>[CC, DT, NN, VB, VB, DT, NN, CC, VB, DT, NN]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Tagalog POS  \\\n",
       "0                                               [SW]   \n",
       "1                               [VB, DT, NN, DT, NN]   \n",
       "2      [DT, UNK, DT, VB, DT, NN, DT, NN, CC, DT, NN]   \n",
       "3  [CC, DT, NN, DT, JJ, NN, CC, JJ, NN, CC, DT, N...   \n",
       "4       [CC, VB, DT, NN, VB, DT, NN, CC, VB, DT, NN]   \n",
       "\n",
       "                                         Ilokano POS  \n",
       "0                                               [SW]  \n",
       "1                           [DT, VB, DT, NN, DT, NN]  \n",
       "2           [DT, NN, DT, NN, VB, DT, NN, DT, DT, NN]  \n",
       "3  [CC, DT, NN, VB, DT, DT, NN, DT, JJ, NN, CC, D...  \n",
       "4       [CC, DT, NN, VB, VB, DT, NN, CC, VB, DT, NN]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_sen_poss['Ilokano POS'] = il_pos_data['POS']\n",
    "\n",
    "dict_sen_poss.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagalog to Ilokano Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_sen_poss_list = dict_sen_poss['Tagalog POS']\n",
    "il_sen_poss_list = dict_sen_poss['Ilokano POS']\n",
    "\"\"\"\n",
    "putting the POS of the sentences in a list object\n",
    "\"\"\"\n",
    "\n",
    "dict_tl_il_sw = pd.DataFrame(columns=['Tagalog Single Words', 'Ilokano Single Words'])\n",
    "dict_tl_il_vb = pd.DataFrame(columns=['Tagalog Verb', 'Ilokano Verb'])\n",
    "dict_tl_il_nn = pd.DataFrame(columns=['Tagalog Noun', 'Ilokano Noun'])\n",
    "dict_tl_il_jj = pd.DataFrame(columns=['Tagalog Adjective', 'Ilokano Adjective'])\n",
    "dict_tl_il_rb = pd.DataFrame(columns=['Tagalog Adverb', 'Ilokano Adverb'])\n",
    "dict_tl_il_cc = pd.DataFrame(columns=['Tagalog Conjunction', 'Ilokano Conjunction'])\n",
    "dict_tl_il_pr = pd.DataFrame(columns=['Tagalog Preposition', 'Ilokano Preposition'])\n",
    "dict_tl_il_dt = pd.DataFrame(columns=['Tagalog Determiner', 'Ilokano Determiner'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending in the List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Verb List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_vb_list(tl_verb, tl_verb_list, il_verb, il_verb_list, curr_il_pos, next_il_pos, next2_il_pos, matched, sp_index, wp_index, il_verb_count_list, il_verb_count, tl_verb_count_list, tl_verb_count, tl_verb_term_count, tl_verb_sen, tl_verb_count_list_tf, tl_sen_len, il_verb_sen, il_verb_count_list_idf, il_verb_count_list_tf, il_verb_count_tf, il_sen_len):\n",
    "    \n",
    "    if tl_verb not in tl_verb_list: # tl_verb_list = json file of verbs\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        tl_verb_list.append(tl_verb)\n",
    "        tl_verb_count.append(1) \n",
    "        tl_verb_term_count.append(tl_verb_count) # not necessary\n",
    "        \n",
    "        if tl_verb not in tl_verb_sen: # tl_verb_sen - list of verbs in a single sentence\n",
    "            tl_verb_sen.append(tl_verb)\n",
    "            tl_verb_count_list.append(1)\n",
    "            tl_verb_count_list_tf.append([1/tl_sen_len])\n",
    "\n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = tl_verb_list.index(tl_verb)\n",
    "        \n",
    "        temp_verb_index = tl_verb_list[temp_index].index(tl_verb[0]) # not necessary\n",
    "        tl_verb_term_count[temp_index][temp_verb_index] += 1\n",
    "\n",
    "        if tl_verb not in tl_verb_sen:\n",
    "            tl_verb_sen.append(tl_verb)\n",
    "            tl_verb_count_list[temp_index] += 1\n",
    "            tl_verb_count_list_tf[temp_index].append(1/tl_sen_len)\n",
    "        else:\n",
    "            try:\n",
    "                tl_verb_count_list_tf[temp_index][sp_index] += (1/tl_sen_len)\n",
    "            except:\n",
    "                tl_verb_count_list_tf[temp_index].append(1/tl_sen_len)\n",
    "        \n",
    "        inDict = True\n",
    "\n",
    "    \"\"\"\n",
    "    append the the verb in the tagalog verb\n",
    "    \"\"\"\n",
    "\n",
    "    if curr_il_pos == 'VB' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if VB : VB\n",
    "        if the Ilokano POS is a verb\n",
    "        \"\"\"\n",
    "        temp_verb = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        il_verb.append(temp_verb)\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "    elif curr_il_pos == 'DT' and next_il_pos == 'VB' and wp_index not in matched:    \n",
    "        \"\"\"\n",
    "        if VB : DT VB\n",
    "        if the Ilokano POS is a determiner and the next POS is a verb\n",
    "        eg. Nilalang : ti Aramid\n",
    "        \"\"\"\n",
    "        temp_verb = il_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        il_verb.append(temp_verb)\n",
    "        matched.append(wp_index)\n",
    "        matched.append(wp_index + 1) \n",
    "\n",
    "    elif curr_il_pos == 'NN' and next_il_pos == 'VB' and wp_index not in matched:    \n",
    "        \"\"\"\n",
    "        if VB : NN VB\n",
    "        if the Ilokano POS is a determiner and the next POS is a verb\n",
    "        \"\"\"\n",
    "        temp_verb = il_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        il_verb.append(temp_verb)\n",
    "        matched.append(wp_index + 1)\n",
    "        \n",
    "    elif curr_il_pos == 'DT' and next_il_pos == 'NN' and next2_il_pos == 'VB' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if VB DT NN : DT NN VB\n",
    "        if the Ilokano POS is a determiner and the next POS is a verb\n",
    "        \"\"\"\n",
    "        temp_verb = il_pos_data['Tokenized'][sp_index][wp_index + 2]\n",
    "        il_verb.append(temp_verb)\n",
    "        matched.append(wp_index + 2)\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if VB : Other POS\n",
    "        if the Ilokano POS is not a verb\n",
    "        \"\"\"\n",
    "        il_verb.append('None')\n",
    "        matched.append(wp_index)\n",
    "\n",
    "    if not inDict:\n",
    "        il_verb_list.append(il_verb)\n",
    "        if il_verb[0] == 'None':\n",
    "            il_verb_count.append(0)\n",
    "            il_verb_count_tf.append(round((0/il_sen_len), 6))\n",
    "        else:\n",
    "            il_verb_count.append(1)\n",
    "            il_verb_count_tf.append(round((1/il_sen_len), 6))\n",
    "        il_verb_count_list.append(il_verb_count)\n",
    "        il_verb_count_list_tf.append(il_verb_count_tf)\n",
    "        \n",
    "        if il_verb[0] not in il_verb_sen:\n",
    "            il_verb_sen.append(il_verb[0])\n",
    "            if il_verb[0] == 'None':\n",
    "                il_verb_count_list_idf.append([0])\n",
    "            else:\n",
    "                il_verb_count_list_idf.append([1])\n",
    "        else:\n",
    "            il_verb_count_list_idf.append([0])\n",
    "            \n",
    "    else:\n",
    "        if il_verb[0] not in il_verb_list[temp_index]:\n",
    "            il_verb_list[temp_index].append(il_verb[0]) # temp_index = row index of the verb\n",
    "            if il_verb[0] == 'None':\n",
    "                il_verb_count_list[temp_index].append(0)\n",
    "                il_verb_count_list_tf[temp_index].append(round((0/il_sen_len), 6))\n",
    "            else:\n",
    "                il_verb_count_list[temp_index].append(1)\n",
    "                il_verb_count_list_tf[temp_index].append(round((1/il_sen_len), 6)) \n",
    "            \n",
    "            if il_verb[0] not in il_verb_sen: # il_verb_sen = list of verbs in  a single sentence\n",
    "                il_verb_sen.append(il_verb[0])\n",
    "                if il_verb[0] == 'None':\n",
    "                    il_verb_count_list_idf[temp_index].append(0)\n",
    "                else:\n",
    "                    il_verb_count_list_idf[temp_index].append(1)\n",
    "            else:\n",
    "                il_verb_count_list_idf[temp_index].append(0)\n",
    "            \n",
    "        else: # if the verb is already in il_verb_list\n",
    "            temp_verb_index = il_verb_list[temp_index].index(il_verb[0])\n",
    "            if il_verb[0] == 'None':\n",
    "                il_verb_count_list[temp_index][temp_verb_index] += 0\n",
    "                il_verb_count_list_tf[temp_index][temp_verb_index] += (0/il_sen_len)\n",
    "            else:\n",
    "                il_verb_count_list[temp_index][temp_verb_index] += 1\n",
    "                il_verb_count_list_tf[temp_index][temp_verb_index] += (1/il_sen_len)\n",
    "            il_verb_count_list_tf[temp_index][temp_verb_index] = round(il_verb_count_list_tf[temp_index][temp_verb_index], 6)\n",
    "            \n",
    "            if il_verb[0] not in il_verb_sen:\n",
    "                il_verb_sen.append(il_verb[0])\n",
    "                if il_verb[0] == 'None':\n",
    "                    il_verb_count_list_idf[temp_index][temp_verb_index] += 0\n",
    "                else:\n",
    "                    il_verb_count_list_idf[temp_index][temp_verb_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Noun List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_nn_list(tl_noun, tl_noun_list, il_noun, il_noun_list, curr_il_pos, next_il_pos, matched, sp_index, wp_index, il_noun_count_list, il_noun_count, tl_noun_count_list, tl_noun_count, tl_noun_term_count, tl_noun_sen, tl_noun_count_list_tf, tl_sen_len, il_noun_sen, il_noun_count_list_idf, il_noun_count_list_tf, il_noun_count_tf, il_sen_len):\n",
    "    \n",
    "    if tl_noun not in tl_noun_list:\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        tl_noun_list.append(tl_noun)\n",
    "        tl_noun_count.append(1) \n",
    "        tl_noun_term_count.append(tl_noun_count)\n",
    "        \n",
    "        if tl_noun not in tl_noun_sen:\n",
    "            tl_noun_sen.append(tl_noun)\n",
    "            tl_noun_count_list.append(1)\n",
    "            tl_noun_count_list_tf.append([1/tl_sen_len])\n",
    "\n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = tl_noun_list.index(tl_noun)\n",
    "\n",
    "        temp_noun_index = tl_noun_list[temp_index].index(tl_noun[0])\n",
    "        tl_noun_term_count[temp_index][temp_noun_index] += 1\n",
    "        \n",
    "        if tl_noun not in tl_noun_sen:\n",
    "            tl_noun_sen.append(tl_noun)\n",
    "            tl_noun_count_list[temp_index] += 1\n",
    "            tl_noun_count_list_tf[temp_index].append(1/tl_sen_len)\n",
    "        else:\n",
    "            try:\n",
    "                tl_noun_count_list_tf[temp_index][sp_index] += (1/tl_sen_len)\n",
    "            except:\n",
    "                tl_noun_count_list_tf[temp_index].append(1/tl_sen_len)\n",
    "        \n",
    "        inDict = True\n",
    "\n",
    "    \"\"\"\n",
    "    append the the noun in the tagalog noun\n",
    "    \"\"\"\n",
    "\n",
    "    if curr_il_pos == 'NN':\n",
    "        \"\"\"\n",
    "        if NN : NN\n",
    "        if the Ilokano POS is a noun\n",
    "        \"\"\"\n",
    "        temp_noun = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        il_noun.append(temp_noun)\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "        \n",
    "    elif curr_il_pos == 'DT' and next_il_pos == 'NN':    \n",
    "        \"\"\"\n",
    "        if NN : DT NN\n",
    "        if the Ilokano POS is a determiner and the next POS is a noun\n",
    "        \"\"\"\n",
    "        temp_next_noun = il_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        il_noun.append(temp_next_noun) \n",
    "        matched.append(wp_index + 1)\n",
    "          \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if NN : Other POS\n",
    "        if the Ilokano POS is not a noun\n",
    "        \"\"\"\n",
    "        il_noun.append('None')\n",
    "        matched.append(wp_index)\n",
    "\n",
    "    if not inDict:\n",
    "        il_noun_list.append(il_noun)\n",
    "        if il_noun[0] == 'None':\n",
    "            il_noun_count.append(0)\n",
    "            il_noun_count_tf.append(round((0/il_sen_len), 6))\n",
    "        else:\n",
    "            il_noun_count.append(1)\n",
    "            il_noun_count_tf.append(round((1/il_sen_len), 6))\n",
    "        il_noun_count_list.append(il_noun_count)\n",
    "        il_noun_count_list_tf.append(il_noun_count_tf)\n",
    "        \n",
    "        if il_noun[0] not in il_noun_sen:\n",
    "            il_noun_sen.append(il_noun[0])\n",
    "            if il_noun[0] == 'None':\n",
    "                il_noun_count_list_idf.append([0])\n",
    "            else:\n",
    "                il_noun_count_list_idf.append([1])\n",
    "        else:\n",
    "            il_noun_count_list_idf.append([0])\n",
    "            \n",
    "    else:\n",
    "        if il_noun[0] not in il_noun_list[temp_index]:\n",
    "            il_noun_list[temp_index].append(il_noun[0]) # temp_index = row index of the noun\n",
    "            if il_noun[0] == 'None':\n",
    "                il_noun_count_list[temp_index].append(0)\n",
    "                il_noun_count_list_tf[temp_index].append(round((0/il_sen_len), 6))\n",
    "            else:\n",
    "                il_noun_count_list[temp_index].append(1)\n",
    "                il_noun_count_list_tf[temp_index].append(round((1/il_sen_len), 6)) \n",
    "            \n",
    "            if il_noun[0] not in il_noun_sen: # il_noun_sen = list of nouns in  a single sentence\n",
    "                il_noun_sen.append(il_noun[0])\n",
    "                if il_noun[0] == 'None':\n",
    "                    il_noun_count_list_idf[temp_index].append(0)\n",
    "                else:\n",
    "                    il_noun_count_list_idf[temp_index].append(1)\n",
    "            else:\n",
    "                il_noun_count_list_idf[temp_index].append(0)\n",
    "            \n",
    "        else: # if the noun is already in il_noun_list\n",
    "            temp_noun_index = il_noun_list[temp_index].index(il_noun[0])\n",
    "            if il_noun[0] == 'None':\n",
    "                il_noun_count_list[temp_index][temp_noun_index] += 0\n",
    "                il_noun_count_list_tf[temp_index][temp_noun_index] += (0/il_sen_len)\n",
    "            else:\n",
    "                il_noun_count_list[temp_index][temp_noun_index] += 1\n",
    "                il_noun_count_list_tf[temp_index][temp_noun_index] += (1/il_sen_len)\n",
    "            il_noun_count_list_tf[temp_index][temp_noun_index] = round(il_noun_count_list_tf[temp_index][temp_noun_index], 6)\n",
    "            \n",
    "            if il_noun[0] not in il_noun_sen:\n",
    "                il_noun_sen.append(il_noun[0])\n",
    "                if il_noun[0] == 'None':\n",
    "                    il_noun_count_list_idf[temp_index][temp_noun_index] += 0\n",
    "                else:\n",
    "                    il_noun_count_list_idf[temp_index][temp_noun_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Adjective List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_jj_list(tl_adj, tl_adj_list, il_adj, il_adj_list, curr_il_pos, next_il_pos, next2_il_pos, matched, sp_index, wp_index, il_adj_count_list, il_adj_count, tl_adj_count_list, tl_adj_count, tl_adj_term_count, tl_adj_sen, tl_adj_count_list_tf, tl_sen_len, il_adj_sen, il_adj_count_list_idf, il_adj_count_list_tf, il_adj_count_tf, il_sen_len):\n",
    "    \n",
    "    if tl_adj not in tl_adj_list:\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        tl_adj_list.append(tl_adj)\n",
    "        tl_adj_count.append(1) \n",
    "        tl_adj_term_count.append(tl_adj_count)\n",
    "        \n",
    "        if tl_adj not in tl_adj_sen:\n",
    "            tl_adj_sen.append(tl_adj)\n",
    "            tl_adj_count_list.append(1)\n",
    "            tl_adj_count_list_tf.append([1/tl_sen_len])\n",
    "\n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = tl_adj_list.index(tl_adj)\n",
    "\n",
    "        temp_adj_index = tl_adj_list[temp_index].index(tl_adj[0])\n",
    "        tl_adj_term_count[temp_index][temp_adj_index] += 1\n",
    "        \n",
    "        if tl_adj not in tl_adj_sen:\n",
    "            tl_adj_sen.append(tl_adj)\n",
    "            tl_adj_count_list[temp_index] += 1\n",
    "            tl_adj_count_list_tf[temp_index].append(1/tl_sen_len)\n",
    "        else:\n",
    "            try:\n",
    "                tl_adj_count_list_tf[temp_index][sp_index] += (1/tl_sen_len)\n",
    "            except:\n",
    "                tl_adj_count_list_tf[temp_index].append(1/tl_sen_len)\n",
    "        \n",
    "        inDict = True\n",
    "\n",
    "    \"\"\"\n",
    "    append the the adj in the tagalog adj\n",
    "    \"\"\"\n",
    "\n",
    "    if curr_il_pos == 'JJ':\n",
    "        \"\"\"\n",
    "        if JJ : JJ\n",
    "        if the Ilokano POS is an adj\n",
    "        \"\"\"\n",
    "        temp_adj = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        il_adj.append(temp_adj)\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "    elif curr_il_pos == 'DT' and next_il_pos == 'JJ':    \n",
    "        \"\"\"\n",
    "        if JJ : DT JJ\n",
    "        if the Ilokano POS is a determiner and the next POS is an adj\n",
    "        eg. mabubuting : ken naimbag\n",
    "        \"\"\"\n",
    "        temp_next_adj = il_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        il_adj.append(temp_next_adj) \n",
    "        matched.append(wp_index + 1)\n",
    "        \n",
    "    elif curr_il_pos == 'JJ' and next_il_pos == 'DT' and next2_il_pos == 'NN':    \n",
    "        \"\"\"\n",
    "        if JJ : JJ NN\n",
    "        if the Ilokano POS is a determiner and the next POS is an adj\n",
    "        eg. mabubuting : ken naimbag\n",
    "        \"\"\"\n",
    "        temp_curr_adj = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        il_adj.append(temp_curr_adj) \n",
    "        matched.append(wp_index + 1)\n",
    "\n",
    "    else:\n",
    "        \"\"\"\n",
    "        if JJ : Other POS\n",
    "        if the Ilokano POS is not an adj\n",
    "        \"\"\"\n",
    "        il_adj.append('None')\n",
    "        matched.append(wp_index)\n",
    "\n",
    "    if not inDict:\n",
    "        il_adj_list.append(il_adj)\n",
    "        if il_adj[0] == 'None':\n",
    "            il_adj_count.append(0)\n",
    "            il_adj_count_tf.append(round((0/il_sen_len), 6))\n",
    "        else:\n",
    "            il_adj_count.append(1)\n",
    "            il_adj_count_tf.append(round((1/il_sen_len), 6))\n",
    "        il_adj_count_list.append(il_adj_count)\n",
    "        il_adj_count_list_tf.append(il_adj_count_tf)\n",
    "        \n",
    "        if il_adj[0] not in il_adj_sen:\n",
    "            il_adj_sen.append(il_adj[0])\n",
    "            if il_adj[0] == 'None':\n",
    "                il_adj_count_list_idf.append([0])\n",
    "            else:\n",
    "                il_adj_count_list_idf.append([1])\n",
    "        else:\n",
    "            il_adj_count_list_idf.append([0])\n",
    "            \n",
    "    else:\n",
    "        if il_adj[0] not in il_adj_list[temp_index]:\n",
    "            il_adj_list[temp_index].append(il_adj[0]) # temp_index = row index of the adj\n",
    "            if il_adj[0] == 'None':\n",
    "                il_adj_count_list[temp_index].append(0)\n",
    "                il_adj_count_list_tf[temp_index].append(round((0/il_sen_len), 6))\n",
    "            else:\n",
    "                il_adj_count_list[temp_index].append(1)\n",
    "                il_adj_count_list_tf[temp_index].append(round((1/il_sen_len), 6)) \n",
    "            \n",
    "            if il_adj[0] not in il_adj_sen: # il_adj_sen = list of adjs in  a single sentence\n",
    "                il_adj_sen.append(il_adj[0])\n",
    "                if il_adj[0] == 'None':\n",
    "                    il_adj_count_list_idf[temp_index].append(0)\n",
    "                else:\n",
    "                    il_adj_count_list_idf[temp_index].append(1)\n",
    "            else:\n",
    "                il_adj_count_list_idf[temp_index].append(0)\n",
    "            \n",
    "        else: # if the adj is already in il_adj_list\n",
    "            temp_adj_index = il_adj_list[temp_index].index(il_adj[0])\n",
    "            if il_adj[0] == 'None':\n",
    "                il_adj_count_list[temp_index][temp_adj_index] += 0\n",
    "                il_adj_count_list_tf[temp_index][temp_adj_index] += (0/il_sen_len)\n",
    "            else:\n",
    "                il_adj_count_list[temp_index][temp_adj_index] += 1\n",
    "                il_adj_count_list_tf[temp_index][temp_adj_index] += (1/il_sen_len)\n",
    "            il_adj_count_list_tf[temp_index][temp_adj_index] = round(il_adj_count_list_tf[temp_index][temp_adj_index], 6)\n",
    "            \n",
    "            if il_adj[0] not in il_adj_sen:\n",
    "                il_adj_sen.append(il_adj[0])\n",
    "                if il_adj[0] == 'None':\n",
    "                    il_adj_count_list_idf[temp_index][temp_adj_index] += 0\n",
    "                else:\n",
    "                    il_adj_count_list_idf[temp_index][temp_adj_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Adverb List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_rb_list(tl_adv, tl_adv_list, il_adv, il_adv_list, curr_il_pos, next_il_pos, next2_il_pos, next3_il_pos, prev_il_pos, matched, sp_index, wp_index, il_adv_count_list, il_adv_count, tl_adv_count_list, tl_adv_count, tl_adv_term_count, tl_adv_sen, tl_adv_count_list_tf, tl_sen_len, il_adv_sen, il_adv_count_list_idf, il_adv_count_list_tf, il_adv_count_tf, il_sen_len):\n",
    "    \n",
    "    if tl_adv not in tl_adv_list:\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        tl_adv_list.append(tl_adv)\n",
    "        tl_adv_count.append(1) \n",
    "        tl_adv_term_count.append(tl_adv_count)\n",
    "        \n",
    "        if tl_adv not in tl_adv_sen:\n",
    "            tl_adv_sen.append(tl_adv)\n",
    "            tl_adv_count_list.append(1)\n",
    "            tl_adv_count_list_tf.append([1/tl_sen_len])\n",
    "\n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = tl_adv_list.index(tl_adv)\n",
    "\n",
    "        temp_adv_index = tl_adv_list[temp_index].index(tl_adv[0])\n",
    "        tl_adv_term_count[temp_index][temp_adv_index] += 1\n",
    "        \n",
    "        if tl_adv not in tl_adv_sen:\n",
    "            tl_adv_sen.append(tl_adv)\n",
    "            tl_adv_count_list[temp_index] += 1\n",
    "            tl_adv_count_list_tf[temp_index].append(1/tl_sen_len)\n",
    "        else:\n",
    "            try:\n",
    "                tl_adv_count_list_tf[temp_index][sp_index] += (1/tl_sen_len)\n",
    "            except:\n",
    "                tl_adv_count_list_tf[temp_index].append(1/tl_sen_len)\n",
    "        \n",
    "        inDict = True\n",
    "\n",
    "    \"\"\"\n",
    "    append the the verb in the tagalog verb\n",
    "    \"\"\"\n",
    "\n",
    "    if curr_il_pos == 'RB':\n",
    "        \"\"\"\n",
    "        if RB : RB\n",
    "        if the Ilokano POS is a adverb\n",
    "        \"\"\"\n",
    "        temp_adverb = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        il_adv.append(temp_adverb)\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "    elif curr_il_pos == 'DT' and next_il_pos == 'RB':    \n",
    "        \"\"\"\n",
    "        if RB : DT RB\n",
    "        \"\"\"\n",
    "        temp_next_adverb = il_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        il_adv.append(temp_next_adverb) \n",
    "        matched.append(wp_index + 1)\n",
    "  \n",
    "        \n",
    "    elif curr_il_pos == 'DT' and next_il_pos == 'NN' and next2_il_pos == 'DT' and next3_il_pos == 'RB' :  \n",
    "        \"\"\"\n",
    "        if RB : DT NN DT RB\n",
    "        \n",
    "        \"\"\"\n",
    "        temp_adverb = il_pos_data['Tokenized'][sp_index][wp_index + 3]\n",
    "        il_adv.append(temp_adverb)\n",
    "        matched.append(wp_index + 3)\n",
    "        \n",
    "    elif curr_il_pos == 'DT' and prev_il_pos == 'RB':\n",
    "        \"\"\"\n",
    "        if RB : DT with RB behind DT\n",
    "        \n",
    "        \"\"\"\n",
    "        temp_adverb = il_pos_data['Tokenized'][sp_index][wp_index - 1]\n",
    "        il_adv.append(temp_adverb)\n",
    "        matched.append(wp_index - 1)\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if RB : Other POS\n",
    "        if the Ilokano POS is not a adverb\n",
    "        \"\"\"\n",
    "        il_adv.append('None')\n",
    "        matched.append(wp_index)\n",
    "\n",
    "    if not inDict:\n",
    "        il_adv_list.append(il_adv)\n",
    "        if il_adv[0] == 'None':\n",
    "            il_adv_count.append(0)\n",
    "            il_adv_count_tf.append(round((0/il_sen_len), 6))\n",
    "        else:\n",
    "            il_adv_count.append(1)\n",
    "            il_adv_count_tf.append(round((1/il_sen_len), 6))\n",
    "        il_adv_count_list.append(il_adv_count)\n",
    "        il_adv_count_list_tf.append(il_adv_count_tf)\n",
    "        \n",
    "        if il_adv[0] not in il_adv_sen:\n",
    "            il_adv_sen.append(il_adv[0])\n",
    "            if il_adv[0] == 'None':\n",
    "                il_adv_count_list_idf.append([0])\n",
    "            else:\n",
    "                il_adv_count_list_idf.append([1])\n",
    "        else:\n",
    "            il_adv_count_list_idf.append([0])\n",
    "            \n",
    "    else:\n",
    "        if il_adv[0] not in il_adv_list[temp_index]:\n",
    "            il_adv_list[temp_index].append(il_adv[0]) # temp_index = row index of the adv\n",
    "            if il_adv[0] == 'None':\n",
    "                il_adv_count_list[temp_index].append(0)\n",
    "                il_adv_count_list_tf[temp_index].append(round((0/il_sen_len), 6))\n",
    "            else:\n",
    "                il_adv_count_list[temp_index].append(1)\n",
    "                il_adv_count_list_tf[temp_index].append(round((1/il_sen_len), 6)) \n",
    "            \n",
    "            if il_adv[0] not in il_adv_sen: # il_adv_sen = list of advs in  a single sentence\n",
    "                il_adv_sen.append(il_adv[0])\n",
    "                if il_adv[0] == 'None':\n",
    "                    il_adv_count_list_idf[temp_index].append(0)\n",
    "                else:\n",
    "                    il_adv_count_list_idf[temp_index].append(1)\n",
    "            else:\n",
    "                il_adv_count_list_idf[temp_index].append(0)\n",
    "            \n",
    "        else: # if the adv is already in il_adv_list\n",
    "            temp_adv_index = il_adv_list[temp_index].index(il_adv[0])\n",
    "            if il_adv[0] == 'None':\n",
    "                il_adv_count_list[temp_index][temp_adv_index] += 0\n",
    "                il_adv_count_list_tf[temp_index][temp_adv_index] += (0/il_sen_len)\n",
    "            else:\n",
    "                il_adv_count_list[temp_index][temp_adv_index] += 1\n",
    "                il_adv_count_list_tf[temp_index][temp_adv_index] += (1/il_sen_len)\n",
    "            il_adv_count_list_tf[temp_index][temp_adv_index] = round(il_adv_count_list_tf[temp_index][temp_adv_index], 6)\n",
    "            \n",
    "            if il_adv[0] not in il_adv_sen:\n",
    "                il_adv_sen.append(il_adv[0])\n",
    "                if il_adv[0] == 'None':\n",
    "                    il_adv_count_list_idf[temp_index][temp_adv_index] += 0\n",
    "                else:\n",
    "                    il_adv_count_list_idf[temp_index][temp_adv_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Conjunction List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_cc_list(tl_conj, tl_conj_list, il_conj, il_conj_list, curr_il_pos, matched, sp_index, wp_index, il_conj_count_list, il_conj_count, tl_conj_count_list, tl_conj_count, tl_conj_term_count, tl_conj_sen, tl_conj_count_list_tf, tl_sen_len, il_conj_sen, il_conj_count_list_idf, il_conj_count_list_tf, il_conj_count_tf, il_sen_len):\n",
    "    \n",
    "    if tl_conj not in tl_conj_list: # tl_conj_list = json file of verbs\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        tl_conj_list.append(tl_conj)\n",
    "        tl_conj_count.append(1) \n",
    "        tl_conj_term_count.append(tl_conj_count)\n",
    "        \n",
    "        if tl_conj not in tl_conj_sen:\n",
    "            tl_conj_sen.append(tl_conj)\n",
    "            tl_conj_count_list.append(1)\n",
    "            tl_conj_count_list_tf.append([1/tl_sen_len])\n",
    "\n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = tl_conj_list.index(tl_conj)\n",
    "\n",
    "        temp_conj_index = tl_conj_list[temp_index].index(tl_conj[0])\n",
    "        tl_conj_term_count[temp_index][temp_conj_index] += 1\n",
    "        \n",
    "        if tl_conj not in tl_conj_sen:\n",
    "            tl_conj_sen.append(tl_conj)\n",
    "            tl_conj_count_list[temp_index] += 1\n",
    "            tl_conj_count_list_tf[temp_index].append(1/tl_sen_len)\n",
    "        else:\n",
    "            try:\n",
    "                tl_conj_count_list_tf[temp_index][sp_index] += (1/tl_sen_len)\n",
    "            except:\n",
    "                tl_conj_count_list_tf[temp_index].append(1/tl_sen_len)\n",
    "        \n",
    "        inDict = True\n",
    "\n",
    "    \"\"\"\n",
    "    append the the conj in the tagalog conj\n",
    "    \"\"\"\n",
    "\n",
    "    if curr_il_pos == 'CC':\n",
    "        \"\"\"\n",
    "        if CC : CC\n",
    "        if the Ilokano POS is a conj\n",
    "        \"\"\"\n",
    "        temp_conj = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        il_conj.append(temp_conj)\n",
    "        matched.append(wp_index)\n",
    "          \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if CC : Other POS\n",
    "        if the Ilokano POS is not a conj\n",
    "        \"\"\"\n",
    "        il_conj.append('None')\n",
    "        matched.append(wp_index)\n",
    "\n",
    "    if not inDict:\n",
    "        il_conj_list.append(il_conj)\n",
    "        if il_conj[0] == 'None':\n",
    "            il_conj_count.append(0)\n",
    "            il_conj_count_tf.append(round((0/il_sen_len), 6))\n",
    "        else:\n",
    "            il_conj_count.append(1)\n",
    "            il_conj_count_tf.append(round((1/il_sen_len), 6))\n",
    "        il_conj_count_list.append(il_conj_count)\n",
    "        il_conj_count_list_tf.append(il_conj_count_tf)\n",
    "        \n",
    "        if il_conj[0] not in il_conj_sen:\n",
    "            il_conj_sen.append(il_conj[0])\n",
    "            if il_conj[0] == 'None':\n",
    "                il_conj_count_list_idf.append([0])\n",
    "            else:\n",
    "                il_conj_count_list_idf.append([1])\n",
    "        else:\n",
    "            il_conj_count_list_idf.append([0])\n",
    "            \n",
    "    else:\n",
    "        if il_conj[0] not in il_conj_list[temp_index]:\n",
    "            il_conj_list[temp_index].append(il_conj[0]) # temp_index = row index of the conj\n",
    "            if il_conj[0] == 'None':\n",
    "                il_conj_count_list[temp_index].append(0)\n",
    "                il_conj_count_list_tf[temp_index].append(round((0/il_sen_len), 6))\n",
    "            else:\n",
    "                il_conj_count_list[temp_index].append(1)\n",
    "                il_conj_count_list_tf[temp_index].append(round((1/il_sen_len), 6)) \n",
    "            \n",
    "            if il_conj[0] not in il_conj_sen: # il_conj_sen = list of conjs in  a single sentence\n",
    "                il_conj_sen.append(il_conj[0])\n",
    "                if il_conj[0] == 'None':\n",
    "                    il_conj_count_list_idf[temp_index].append(0)\n",
    "                else:\n",
    "                    il_conj_count_list_idf[temp_index].append(1)\n",
    "            else:\n",
    "                il_conj_count_list_idf[temp_index].append(0)\n",
    "            \n",
    "        else: # if the conj is already in il_conj_list\n",
    "            temp_conj_index = il_conj_list[temp_index].index(il_conj[0])\n",
    "            if il_conj[0] == 'None':\n",
    "                il_conj_count_list[temp_index][temp_conj_index] += 0\n",
    "                il_conj_count_list_tf[temp_index][temp_conj_index] += (0/il_sen_len)\n",
    "            else:\n",
    "                il_conj_count_list[temp_index][temp_conj_index] += 1\n",
    "                il_conj_count_list_tf[temp_index][temp_conj_index] += (1/il_sen_len)\n",
    "            il_conj_count_list_tf[temp_index][temp_conj_index] = round(il_conj_count_list_tf[temp_index][temp_conj_index], 6)\n",
    "            \n",
    "            if il_conj[0] not in il_conj_sen:\n",
    "                il_conj_sen.append(il_conj[0])\n",
    "                if il_conj[0] == 'None':\n",
    "                    il_conj_count_list_idf[temp_index][temp_conj_index] += 0\n",
    "                else:\n",
    "                    il_conj_count_list_idf[temp_index][temp_conj_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Preposition List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_pr_list(tl_prepo, tl_prepo_list, il_prepo, il_prepo_list, curr_il_pos, next_il_pos, next2_il_pos, matched, sp_index, wp_index, il_prepo_count_list, il_prepo_count, tl_prepo_count_list, tl_prepo_count, tl_prepo_term_count, tl_prepo_sen, tl_prepo_count_list_tf, tl_sen_len, il_prepo_sen, il_prepo_count_list_idf, il_prepo_count_list_tf, il_prepo_count_tf, il_sen_len):\n",
    "    \n",
    "    if tl_prepo not in tl_prepo_list: # tl_prepo_list = json file of verbs\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        tl_prepo_list.append(tl_prepo)\n",
    "        tl_prepo_count.append(1) \n",
    "        tl_prepo_term_count.append(tl_prepo_count)\n",
    "        \n",
    "        if tl_prepo not in tl_prepo_sen:\n",
    "            tl_prepo_sen.append(tl_prepo)\n",
    "            tl_prepo_count_list.append(1)\n",
    "            tl_prepo_count_list_tf.append([1/tl_sen_len])\n",
    "\n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = tl_prepo_list.index(tl_prepo)\n",
    "\n",
    "        temp_prepo_index = tl_prepo_list[temp_index].index(tl_prepo[0])\n",
    "        tl_prepo_term_count[temp_index][temp_prepo_index] += 1\n",
    "        \n",
    "        if tl_prepo not in tl_prepo_sen:\n",
    "            tl_prepo_sen.append(tl_prepo)\n",
    "            tl_prepo_count_list[temp_index] += 1\n",
    "            tl_prepo_count_list_tf[temp_index].append(1/tl_sen_len)\n",
    "        else:\n",
    "            try:\n",
    "                tl_prepo_count_list_tf[temp_index][sp_index] += (1/tl_sen_len)\n",
    "            except:\n",
    "                tl_prepo_count_list_tf[temp_index].append(1/tl_sen_len)\n",
    "        \n",
    "        inDict = True\n",
    "    \n",
    "    \"\"\"\n",
    "    append the the verb in the tagalog verb\n",
    "    \"\"\"\n",
    "    \n",
    "    if curr_il_pos == 'PR' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if PR : PR\n",
    "        if the Ilokano POS is a verb\n",
    "        \"\"\"\n",
    "        temp_prepo = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        il_prepo.append(temp_prepo)\n",
    "        matched.append(wp_index)\n",
    "    if curr_il_pos == 'DT' and next_il_pos == 'PR' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if PR : PR\n",
    "        if the Ilokano POS is a verb\n",
    "        \"\"\"\n",
    "        temp_prepo = il_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        il_prepo.append(temp_prepo)\n",
    "        matched.append(wp_index + 1)\n",
    "    if curr_il_pos == 'DT' and next_il_pos == 'PR' and next2_il_pos == 'DT' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if PR : DT PR DT\n",
    "        if the Ilokano prepo is sandwiched between 2 determiners\n",
    "        \"\"\"\n",
    "        temp_prepo = il_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        il_prepo.append(temp_prepo)\n",
    "        matched.append(wp_index + 1)\n",
    "    if curr_il_pos == 'PR' and next_il_pos == 'DT' and next2_il_pos == 'NN' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if PR : DT PR DT\n",
    "        if the Ilokano prepo is sandwiched between 2 determiners\n",
    "        \"\"\"\n",
    "        temp_prepo = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        il_prepo.append(temp_prepo)\n",
    "        matched.append(wp_index)\n",
    "    \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if VB : Other POS\n",
    "        if the Ilokano POS is not a verb\n",
    "        \"\"\"\n",
    "        il_prepo.append('None')\n",
    "        matched.append(wp_index)\n",
    "    \n",
    "    if not inDict:\n",
    "        il_prepo_list.append(il_prepo)\n",
    "        if il_prepo[0] == 'None':\n",
    "            il_prepo_count.append(0)\n",
    "            il_prepo_count_tf.append(round((0/il_sen_len), 6))\n",
    "        else:\n",
    "            il_prepo_count.append(1)\n",
    "            il_prepo_count_tf.append(round((1/il_sen_len), 6))\n",
    "        il_prepo_count_list.append(il_prepo_count)\n",
    "        il_prepo_count_list_tf.append(il_prepo_count_tf)\n",
    "        \n",
    "        if il_prepo[0] not in il_prepo_sen:\n",
    "            il_prepo_sen.append(il_prepo[0])\n",
    "            if il_prepo[0] == 'None':\n",
    "                il_prepo_count_list_idf.append([0])\n",
    "            else:\n",
    "                il_prepo_count_list_idf.append([1])\n",
    "        else:\n",
    "            il_prepo_count_list_idf.append([0])\n",
    "            \n",
    "    else:\n",
    "        if il_prepo[0] not in il_prepo_list[temp_index]:\n",
    "            il_prepo_list[temp_index].append(il_prepo[0]) # temp_index = row index of the prepo\n",
    "            if il_prepo[0] == 'None':\n",
    "                il_prepo_count_list[temp_index].append(0)\n",
    "                il_prepo_count_list_tf[temp_index].append(round((0/il_sen_len), 6))\n",
    "            else:\n",
    "                il_prepo_count_list[temp_index].append(1)\n",
    "                il_prepo_count_list_tf[temp_index].append(round((1/il_sen_len), 6)) \n",
    "            \n",
    "            if il_prepo[0] not in il_prepo_sen: # il_prepo_sen = list of prepos in  a single sentence\n",
    "                il_prepo_sen.append(il_prepo[0])\n",
    "                if il_prepo[0] == 'None':\n",
    "                    il_prepo_count_list_idf[temp_index].append(0)\n",
    "                else:\n",
    "                    il_prepo_count_list_idf[temp_index].append(1)\n",
    "            else:\n",
    "                il_prepo_count_list_idf[temp_index].append(0)\n",
    "            \n",
    "        else: # if the prepo is already in il_prepo_list\n",
    "            temp_prepo_index = il_prepo_list[temp_index].index(il_prepo[0])\n",
    "            il_prepo_count_list[temp_index][temp_prepo_index]\n",
    "            \n",
    "            if il_prepo[0] == 'None':\n",
    "                il_prepo_count_list[temp_index][temp_prepo_index] += 0\n",
    "                il_prepo_count_list_tf[temp_index][temp_prepo_index] += (0/il_sen_len)\n",
    "            else:\n",
    "                il_prepo_count_list[temp_index][temp_prepo_index] += 1\n",
    "                il_prepo_count_list_tf[temp_index][temp_prepo_index] += (1/il_sen_len)\n",
    "            il_prepo_count_list_tf[temp_index][temp_prepo_index] = round(il_prepo_count_list_tf[temp_index][temp_prepo_index], 6)\n",
    "            \n",
    "            if il_prepo[0] not in il_prepo_sen:\n",
    "                il_prepo_sen.append(il_prepo[0])\n",
    "                if il_prepo[0] == 'None':\n",
    "                    il_prepo_count_list_idf[temp_index][temp_prepo_index] += 0\n",
    "                else:\n",
    "                    il_prepo_count_list_idf[temp_index][temp_prepo_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Determiner List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_dt_list(tl_dt, tl_dt_list, il_dt, il_dt_list, curr_il_pos, next_il_pos, next2_il_pos, matched, sp_index, wp_index, il_dt_count_list, il_dt_count, tl_dt_count_list, tl_dt_count, tl_dt_term_count, tl_dt_sen, tl_dt_count_list_tf, tl_sen_len, il_dt_sen, il_dt_count_list_idf, il_dt_count_list_tf, il_dt_count_tf, il_sen_len):\n",
    "    \n",
    "    if tl_dt not in tl_dt_list: # tl_dt_list = json file of verbs\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        tl_dt_list.append(tl_dt)\n",
    "        tl_dt_count.append(1) \n",
    "        tl_dt_term_count.append(tl_dt_count)\n",
    "        \n",
    "        if tl_dt not in tl_dt_sen:\n",
    "            tl_dt_sen.append(tl_dt)\n",
    "            tl_dt_count_list.append(1)\n",
    "            tl_dt_count_list_tf.append([1/tl_sen_len])\n",
    "\n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = tl_dt_list.index(tl_dt)\n",
    "\n",
    "        temp_dt_index = tl_dt_list[temp_index].index(tl_dt[0])\n",
    "        tl_dt_term_count[temp_index][temp_dt_index] += 1\n",
    "        \n",
    "        if tl_dt not in tl_dt_sen:\n",
    "            tl_dt_sen.append(tl_dt)\n",
    "            tl_dt_count_list[temp_index] += 1\n",
    "            tl_dt_count_list_tf[temp_index].append(1/tl_sen_len)\n",
    "        else:\n",
    "            try:\n",
    "                tl_dt_count_list_tf[temp_index][sp_index] += (1/tl_sen_len)\n",
    "            except:\n",
    "                tl_dt_count_list_tf[temp_index].append(1/tl_sen_len)\n",
    "        \n",
    "        inDict = True\n",
    "    \n",
    "    \"\"\"\n",
    "    append the the verb in the tagalog verb\n",
    "    \"\"\"\n",
    "    \n",
    "    if curr_il_pos == 'DT' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if PR : PR\n",
    "        if the Ilokano POS is a verb\n",
    "        \"\"\"\n",
    "        temp_prepo = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        il_dt.append(temp_prepo)\n",
    "        matched.append(wp_index)\n",
    "    \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if VB : Other POS\n",
    "        if the Ilokano POS is not a verb\n",
    "        \"\"\"\n",
    "        il_dt.append('None')\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "    if not inDict:\n",
    "        il_dt_list.append(il_dt)\n",
    "        if il_dt[0] == 'None':\n",
    "            il_dt_count.append(0)\n",
    "            il_dt_count_tf.append(round((0/il_sen_len), 6))\n",
    "        else:\n",
    "            il_dt_count.append(1)\n",
    "            il_dt_count_tf.append(round((1/il_sen_len), 6))\n",
    "        il_dt_count_list.append(il_dt_count)\n",
    "        il_dt_count_list_tf.append(il_dt_count_tf)\n",
    "        \n",
    "        if il_dt[0] not in il_dt_sen:\n",
    "            il_dt_sen.append(il_dt[0])\n",
    "            if il_dt[0] == 'None':\n",
    "                il_dt_count_list_idf.append([0])\n",
    "            else:\n",
    "                il_dt_count_list_idf.append([1])\n",
    "        else:\n",
    "            il_dt_count_list_idf.append([0])\n",
    "            \n",
    "    else:\n",
    "        if il_dt[0] not in il_dt_list[temp_index]:\n",
    "            il_dt_list[temp_index].append(il_dt[0]) # temp_index = row index of the dt\n",
    "            if il_dt[0] == 'None':\n",
    "                il_dt_count_list[temp_index].append(0)\n",
    "                il_dt_count_list_tf[temp_index].append(round((0/il_sen_len), 6))\n",
    "            else:\n",
    "                il_dt_count_list[temp_index].append(1)\n",
    "                il_dt_count_list_tf[temp_index].append(round((1/il_sen_len), 6)) \n",
    "            \n",
    "            if il_dt[0] not in il_dt_sen: # il_dt_sen = list of dts in  a single sentence\n",
    "                il_dt_sen.append(il_dt[0])\n",
    "                if il_dt[0] == 'None':\n",
    "                    il_dt_count_list_idf[temp_index].append(0)\n",
    "                else:\n",
    "                    il_dt_count_list_idf[temp_index].append(1)\n",
    "            else:\n",
    "                il_dt_count_list_idf[temp_index].append(0)\n",
    "            \n",
    "        else: # if the dt is already in il_dt_list\n",
    "            temp_dt_index = il_dt_list[temp_index].index(il_dt[0])\n",
    "            if il_dt[0] == 'None':\n",
    "                il_dt_count_list[temp_index][temp_dt_index] += 0\n",
    "                il_dt_count_list_tf[temp_index][temp_dt_index] += (0/il_sen_len)\n",
    "            else:\n",
    "                il_dt_count_list[temp_index][temp_dt_index] += 1\n",
    "                il_dt_count_list_tf[temp_index][temp_dt_index] += (1/il_sen_len)\n",
    "            il_dt_count_list_tf[temp_index][temp_dt_index] = round(il_dt_count_list_tf[temp_index][temp_dt_index], 6)\n",
    "            \n",
    "            if il_dt[0] not in il_dt_sen:\n",
    "                il_dt_sen.append(il_dt[0])\n",
    "                if il_dt[0] == 'None':\n",
    "                    il_dt_count_list_idf[temp_index][temp_dt_index] += 0\n",
    "                else:\n",
    "                    il_dt_count_list_idf[temp_index][temp_dt_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_idf(tl_count_list):\n",
    "    tl_idf = []\n",
    "    for tl_count in tl_count_list:\n",
    "        temp_quo = tl_doc_len/tl_count\n",
    "        tl_idf.append(abs(math.log10(temp_quo)))\n",
    "        \n",
    "    return tl_idf\n",
    "# end of get_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf_il(il_verb_count_list_idf):\n",
    "    il_idf_list = []\n",
    "    for il_count_list in il_verb_count_list_idf:\n",
    "        il_idf = []\n",
    "        for il_count in il_count_list:\n",
    "            try:\n",
    "                temp_quo = il_doc_len/il_count\n",
    "                il_idf.append(round(abs(math.log10(temp_quo)), 6))\n",
    "            except:\n",
    "                temp_quo = 0\n",
    "                il_idf.append(0)\n",
    "                \n",
    "        il_idf_list.append(il_idf)\n",
    "    return il_idf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_il(il_count_sen_list, il_verb_count_list_tf):\n",
    "    il_tf_list = []\n",
    "    \n",
    "    for il_count_list in il_verb_count_list_tf:\n",
    "        il_tf = []\n",
    "\n",
    "        for il_count_sen in il_count_sen_list:\n",
    "            temp_sum = 0\n",
    "            \n",
    "            for il_count in il_count_sen:\n",
    "                temp_sum += il_count\n",
    "                \n",
    "            temp_len = len(il_count_sen)\n",
    "            temp_quo = temp_sum/temp_len\n",
    "            il_tf.append(round(temp_quo, 6))\n",
    "        \n",
    "    return il_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf(tl_count_sen_list):\n",
    "    tl_tf = []\n",
    "\n",
    "    for tl_count_sen in tl_count_sen_list:\n",
    "        temp_sum = 0\n",
    "        \n",
    "        for tl_count in tl_count_sen:\n",
    "            temp_sum += tl_count\n",
    "            \n",
    "        temp_len = len(tl_count_sen)\n",
    "        temp_quo = temp_sum/temp_len\n",
    "        tl_tf.append(round(temp_quo, 6))\n",
    "        \n",
    "    return tl_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf(tl_tf, tl_idf):\n",
    "    tf_idf_tl = []\n",
    "    \n",
    "    for i in range(len(tl_tf)):\n",
    "        temp_score = tl_tf[i] * tl_idf[i]\n",
    "        tf_idf_tl.append(round(temp_score, 2))\n",
    "        \n",
    "    return tf_idf_tl\n",
    "# end of get_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf_il(il_tf_list, il_idf_list):\n",
    "    il_tf_idf_list = []\n",
    "    \n",
    "    for i in range(len(il_tf_list)):\n",
    "        il_tf_idf = []\n",
    "        for j in range(len(il_tf_list[i])):\n",
    "            temp_score = il_tf_list[i][j] * il_idf_list[i][j]\n",
    "            il_tf_idf.append(round(temp_score, 2))\n",
    "            \n",
    "        il_tf_idf_list.append(il_tf_idf)\n",
    "        \n",
    "    return il_tf_idf_list\n",
    "# end of get_tf_idf_il"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagalog to Ilokano Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "wp_index = None # word position index\n",
    "\n",
    "\"\"\"\n",
    "instantiating the verb lists\n",
    "\"\"\"\n",
    "\n",
    "def match_tl_il_pos():\n",
    "    \"\"\"\n",
    "    This function matches the POS of the sentences in the Tagalog and Ilokano datasets\n",
    "    \"\"\"\n",
    "    sp_index = 0\n",
    "    \n",
    "    tl_sw_list = []\n",
    "    il_sw_list = []\n",
    "    tl_verb_list = []\n",
    "    il_verb_list = []\n",
    "    tl_noun_list = []\n",
    "    il_noun_list = []\n",
    "    tl_adj_list = []\n",
    "    il_adj_list = []\n",
    "    tl_adv_list = []\n",
    "    il_adv_list = []\n",
    "    tl_conj_list = []\n",
    "    il_conj_list = []\n",
    "    tl_prepo_list = []\n",
    "    il_prepo_list = []\n",
    "    tl_dt_list = []\n",
    "    il_dt_list = []\n",
    "    tl_to_il_verb_list = []\n",
    "    \"\"\"\n",
    "    instantiating the verb lists\n",
    "    \"\"\"\n",
    "    \n",
    "    il_verb_count_list = []\n",
    "    il_noun_count_list = []\n",
    "    il_adj_count_list = []\n",
    "    il_adv_count_list = []\n",
    "    il_conj_count_list = []\n",
    "    il_prepo_count_list = []\n",
    "    il_dt_count_list = []\n",
    "    \n",
    "    tl_verb_count_list = []\n",
    "    tl_noun_count_list = []\n",
    "    tl_adj_count_list = []\n",
    "    tl_adv_count_list = []\n",
    "    tl_conj_count_list = []\n",
    "    tl_prepo_count_list = []\n",
    "    tl_dt_count_list = []\n",
    "\n",
    "    tl_verb_count_list_tf = []\n",
    "    tl_noun_count_list_tf = []\n",
    "    tl_adj_count_list_tf = []\n",
    "    tl_adv_count_list_tf = []\n",
    "    tl_conj_count_list_tf = []\n",
    "    tl_prepo_count_list_tf = []\n",
    "    tl_dt_count_list_tf = []\n",
    "\n",
    "    il_verb_count_list_tf = []\n",
    "    il_noun_count_list_tf = []\n",
    "    il_adj_count_list_tf = []\n",
    "    il_adv_count_list_tf = []\n",
    "    il_conj_count_list_tf = []\n",
    "    il_prepo_count_list_tf = []\n",
    "    il_dt_count_list_tf = []\n",
    "\n",
    "    tl_verb_term_count = []\n",
    "    tl_noun_term_count = []\n",
    "    tl_adj_term_count = []\n",
    "    tl_adv_term_count = []\n",
    "    tl_conj_term_count = []\n",
    "    tl_prepo_term_count = []\n",
    "    tl_dt_term_count = []\n",
    "    \n",
    "    tl_sen_len_list = []\n",
    "    il_sen_len_list = []\n",
    "    \n",
    "    il_verb_count_list_idf = []\n",
    "    il_noun_count_list_idf = []\n",
    "    il_adj_count_list_idf = []\n",
    "    il_adv_count_list_idf = []\n",
    "    il_conj_count_list_idf = []\n",
    "    il_prepo_count_list_idf = []\n",
    "    il_dt_count_list_idf = []\n",
    "    \n",
    "    il_verb_count_list_tf = []\n",
    "    il_noun_count_list_tf = []\n",
    "    il_adj_count_list_tf = []\n",
    "    il_adv_count_list_tf = []\n",
    "    il_conj_count_list_tf = []\n",
    "    il_prepo_count_list_tf = []\n",
    "    il_dt_count_list_tf = []\n",
    "    \n",
    "    for tl_sen_pos in tl_sen_poss_list:\n",
    "        # loop for getting the pos structure of every sentence\n",
    "        \"\"\"\n",
    "        tl_sen is a list of POS of a sentence\n",
    "        eg. ['VB', 'DT', 'NN', 'DT', 'NN']\n",
    "        \"\"\"\n",
    "        matched = []\n",
    "        il_sen = il_sen_poss_list[sp_index]\n",
    "        il_sen_len = len(il_sen)\n",
    "        tl_sen_len = len(tl_sen_pos)\n",
    "        il_sen_len = len(il_sen)\n",
    "        \n",
    "        tl_sen_len_list.append(tl_sen_len)\n",
    "        il_sen_len_list.append(il_sen_len)\n",
    "        \n",
    "        wp_index = 0\n",
    "        \"\"\"\n",
    "        instantiating the variables\n",
    "        \"\"\"\n",
    "        \n",
    "        tl_verb_sen = []\n",
    "        tl_noun_sen = []\n",
    "        tl_adj_sen = []\n",
    "        tl_adv_sen = []\n",
    "        tl_conj_sen = []\n",
    "        tl_prepo_sen = []\n",
    "        tl_dt_sen = []\n",
    "        \n",
    "        il_verb_sen = []\n",
    "        il_noun_sen = []\n",
    "        il_adj_sen = []\n",
    "        il_adv_sen = []\n",
    "        il_conj_sen = []\n",
    "        il_prepo_sen = []\n",
    "        il_dt_sen = []\n",
    "        \n",
    "        for tl_word_pos in tl_sen_pos:\n",
    "            # loop for each pos in a sentence\n",
    "            \"\"\"\n",
    "            tl_word_pos is a POS of a word\n",
    "            eg. 'VB'\n",
    "            \"\"\"\n",
    "            \n",
    "            il_verb = []\n",
    "            il_noun = []\n",
    "            il_adj = []\n",
    "            il_adv = []\n",
    "            il_conj = []\n",
    "            il_prepo = []\n",
    "            il_dt = []\n",
    "            \n",
    "            il_verb_count = []\n",
    "            il_noun_count = []\n",
    "            il_adj_count = []\n",
    "            il_adv_count = []\n",
    "            il_conj_count = []\n",
    "            il_prepo_count = []\n",
    "            il_dt_count = []\n",
    "            \n",
    "            il_verb_count_tf = []\n",
    "            il_noun_count_tf = []\n",
    "            il_adj_count_tf = []\n",
    "            il_adv_count_tf = []\n",
    "            il_conj_count_tf = []\n",
    "            il_prepo_count_tf = []\n",
    "            il_dt_count_tf = []\n",
    "\n",
    "            tl_verb_count = []\n",
    "            tl_noun_count = []\n",
    "            tl_adj_count = []\n",
    "            tl_adv_count = []\n",
    "            tl_conj_count = []\n",
    "            tl_prepo_count = []\n",
    "            tl_dt_count = []\n",
    "            \n",
    "            \n",
    "            tl_word = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "            # gets the word in every sentence\n",
    "            \n",
    "            try:\n",
    "                curr_il_pos = il_sen[wp_index] # ti\n",
    "            except IndexError:\n",
    "                curr_il_pos = 'None'\n",
    "            try:\n",
    "                next_il_pos = il_sen[wp_index + 1]\n",
    "            except IndexError:\n",
    "                next_il_pos = 'None'\n",
    "            try:\n",
    "                next2_il_pos = il_sen[wp_index + 2]\n",
    "            except IndexError:\n",
    "                next2_il_pos = 'None'\n",
    "            try:\n",
    "                next3_il_pos = il_sen[wp_index + 3]\n",
    "            except IndexError:\n",
    "                next3_il_pos = 'None'\n",
    "            try:\n",
    "                prev_il_pos = il_sen[wp_index - 1]\n",
    "                if (wp_index - 1) < 0:\n",
    "                    prev_il_pos = 'None'\n",
    "            except IndexError:\n",
    "                prev_il_pos = 'None'\n",
    "            \"\"\"\n",
    "            getting the current, next, and previous POS in the sentence\n",
    "            \"\"\"\n",
    "            \n",
    "            # Matching Conditions\n",
    "            \n",
    "            # 1. SW\n",
    "            if tl_word_pos == 'SW':\n",
    "                \"\"\"\n",
    "                if SW : SW\n",
    "                if the Tagalog POS is a SW\n",
    "                \"\"\"\n",
    "                il_word = il_pos_data['Tokenized'][sp_index]\n",
    "                tl_sw_list.append(tl_word)\n",
    "                il_sw_list.append(il_word)\n",
    "            \n",
    "            # 2. VB\n",
    "            if tl_word_pos == 'VB':\n",
    "                \"\"\"\n",
    "                Verb Matching\n",
    "                if the POS is a verb, append the index of the verb to the verb list\n",
    "                \"\"\"\n",
    "                \n",
    "                append_vb_list(tl_word, tl_verb_list, il_verb, il_verb_list, curr_il_pos, next_il_pos, next2_il_pos, matched, sp_index, wp_index, il_verb_count_list, il_verb_count, tl_verb_count_list, tl_verb_count, tl_verb_term_count, tl_verb_sen, tl_verb_count_list_tf, tl_sen_len, il_verb_sen, il_verb_count_list_idf, il_verb_count_list_tf, il_verb_count_tf, il_sen_len)\n",
    "                \n",
    "            # 3. NN\n",
    "            if tl_word_pos == 'NN':\n",
    "                \"\"\"\n",
    "                Noun Matching\n",
    "                if the POS is a noun, append the index of the noun to the noun list\n",
    "                \"\"\"\n",
    "                append_nn_list(tl_word, tl_noun_list, il_noun, il_noun_list, curr_il_pos, next_il_pos, matched, sp_index, wp_index, il_noun_count_list, il_noun_count, tl_noun_count_list, tl_noun_count, tl_noun_term_count, tl_noun_sen, tl_noun_count_list_tf, tl_sen_len, il_noun_sen, il_noun_count_list_idf, il_noun_count_list_tf, il_noun_count_tf, il_sen_len)\n",
    "\n",
    "            # 4. JJ\n",
    "            if tl_word_pos == 'JJ':\n",
    "                \"\"\"\n",
    "                Adj Matching\n",
    "                if the POS is a adj, append the index of the adj to the adj list\n",
    "                \"\"\"\n",
    "                append_jj_list(tl_word, tl_adj_list, il_adj, il_adj_list, curr_il_pos, next_il_pos, next2_il_pos, matched, sp_index, wp_index, il_adj_count_list, il_adj_count, tl_adj_count_list, tl_adj_count, tl_adj_term_count, tl_adj_sen, tl_adj_count_list_tf, tl_sen_len, il_adj_sen, il_adj_count_list_idf, il_adj_count_list_tf, il_adj_count_tf, il_sen_len)\n",
    "            \n",
    "            # 5. RB\n",
    "            if tl_word_pos == 'RB':\n",
    "                \"\"\"\n",
    "                Adverb Matching\n",
    "                if the POS is a adverb, append the index of the adverb to the adverb list\n",
    "                \"\"\"\n",
    "                append_rb_list(tl_word, tl_adv_list, il_adv, il_adv_list, curr_il_pos, next_il_pos, next2_il_pos, next3_il_pos, prev_il_pos, matched, sp_index, wp_index, il_adv_count_list, il_adv_count, tl_adv_count_list, tl_adv_count, tl_adv_term_count, tl_adv_sen, tl_adv_count_list_tf, tl_sen_len, il_adv_sen, il_adv_count_list_idf, il_adv_count_list_tf, il_adv_count_tf, il_sen_len)\n",
    "            \n",
    "            # 6. CC\n",
    "            if tl_word_pos == 'CC':\n",
    "                \"\"\"\n",
    "                Conjunction Matching\n",
    "                if the POS is a conjunction, append the index of the conjunction to the conjunction list\n",
    "                \"\"\"\n",
    "                append_cc_list(tl_word, tl_conj_list, il_conj, il_conj_list, curr_il_pos, matched, sp_index, wp_index, il_conj_count_list, il_conj_count, tl_conj_count_list, tl_conj_count, tl_conj_term_count, tl_conj_sen, tl_conj_count_list_tf, tl_sen_len, il_conj_sen, il_conj_count_list_idf, il_conj_count_list_tf, il_conj_count_tf, il_sen_len)\n",
    "            \n",
    "            # 7. PR\n",
    "            if tl_word_pos == 'PR':\n",
    "                \"\"\"\n",
    "                Preposition Matching\n",
    "                if the POS is a preposition, append the index of the conjunction to the conjunction list\n",
    "                \"\"\"\n",
    "                # append_pr_list(tl_word, tl_prepo_list, il_prepo, il_prepo_list, curr_il_pos, next_il_pos, next2_il_pos, matched, sp_index, wp_index, il_prepo_count_list, il_prepo_count, tl_prepo_count_list, tl_prepo_count, tl_prepo_term_count, tl_prepo_sen, tl_prepo_count_list_tf, tl_sen_len, il_prepo_sen, il_prepo_count_list_idf, il_prepo_count_list_tf, il_prepo_count_tf, il_sen_len)\n",
    "            \n",
    "            # 8. DT\n",
    "            if tl_word_pos == 'DT':\n",
    "                \"\"\"\n",
    "                Determiner Matching\n",
    "                if the POS is a determiner, append the index of the conjunction to the conjunction list\n",
    "                \"\"\"\n",
    "                append_dt_list(tl_word, tl_dt_list, il_dt, il_dt_list, curr_il_pos, next_il_pos, next2_il_pos, matched, sp_index, wp_index, il_dt_count_list, il_dt_count, tl_dt_count_list, tl_dt_count, tl_dt_term_count, tl_dt_sen, tl_dt_count_list_tf, tl_sen_len, il_dt_sen, il_dt_count_list_idf, il_dt_count_list_tf, il_dt_count_tf, il_sen_len)\n",
    "            \n",
    "                          \n",
    "            wp_index += 1  \n",
    "        sp_index += 1\n",
    "    \n",
    "    tl_verb_idf = get_idf(tl_verb_count_list)\n",
    "    tl_noun_idf = get_idf(tl_noun_count_list)\n",
    "    tl_adj_idf = get_idf(tl_adj_count_list)\n",
    "    tl_adv_idf = get_idf(tl_adv_count_list)\n",
    "    tl_conj_idf = get_idf(tl_conj_count_list)\n",
    "    tl_prepo_idf = get_idf(tl_prepo_count_list)\n",
    "    tl_dt_idf = get_idf(tl_dt_count_list)\n",
    "\n",
    "    tl_verb_tf = get_tf(tl_verb_count_list_tf)\n",
    "    tl_noun_tf = get_tf(tl_noun_count_list_tf)\n",
    "    tl_adj_tf = get_tf(tl_adj_count_list_tf)\n",
    "    tl_adv_tf = get_tf(tl_adv_count_list_tf)\n",
    "    tl_conj_tf = get_tf(tl_conj_count_list_tf)\n",
    "    tl_prepo_tf = get_tf(tl_prepo_count_list_tf)\n",
    "    tl_dt_tf = get_tf(tl_dt_count_list_tf)\n",
    "    \n",
    "    tl_verb_tf_idf = get_tf_idf(tl_verb_tf, tl_verb_idf)\n",
    "    tl_noun_tf_idf = get_tf_idf(tl_noun_tf, tl_noun_idf)\n",
    "    tl_adj_tf_idf = get_tf_idf(tl_adj_tf, tl_adj_idf)\n",
    "    tl_adv_tf_idf = get_tf_idf(tl_adv_tf, tl_adv_idf)\n",
    "    tl_conj_tf_idf = get_tf_idf(tl_conj_tf, tl_conj_idf)\n",
    "    tl_prepo_tf_idf = get_tf_idf(tl_prepo_tf, tl_prepo_idf)\n",
    "    tl_dt_tf_idf = get_tf_idf(tl_dt_tf, tl_dt_idf)\n",
    "        \n",
    "    il_verb_idf = get_idf_il(il_verb_count_list_idf)\n",
    "    il_noun_idf = get_idf_il(il_noun_count_list_idf)\n",
    "    il_adj_idf = get_idf_il(il_adj_count_list_idf)\n",
    "    il_adv_idf = get_idf_il(il_adv_count_list_idf)\n",
    "    il_conj_idf = get_idf_il(il_conj_count_list_idf)\n",
    "    il_prepo_idf = get_idf_il(il_prepo_count_list_idf)\n",
    "    il_dt_idf = get_idf_il(il_dt_count_list_idf)\n",
    "    \n",
    "    il_verb_tf_idf = get_tf_idf_il(il_verb_count_list_tf, il_verb_idf)\n",
    "    il_noun_tf_idf = get_tf_idf_il(il_noun_count_list_tf, il_noun_idf)\n",
    "    il_adj_tf_idf = get_tf_idf_il(il_adj_count_list_tf, il_adj_idf)\n",
    "    il_adv_tf_idf = get_tf_idf_il(il_adv_count_list_tf, il_adv_idf)\n",
    "    il_conj_tf_idf = get_tf_idf_il(il_conj_count_list_tf, il_conj_idf)\n",
    "    il_prepo_tf_idf = get_tf_idf_il(il_prepo_count_list_tf, il_prepo_idf)\n",
    "    il_dt_tf_idf = get_tf_idf_il(il_dt_count_list_tf, il_dt_idf)\n",
    "    \n",
    "    dict_tl_il_sw['Tagalog Single Words'] = tl_sw_list\n",
    "    dict_tl_il_sw['Ilokano Single Words'] = il_sw_list\n",
    "    \n",
    "    dict_tl_il_vb['Tagalog Verb'] = tl_verb_list\n",
    "    dict_tl_il_vb['Tagalog Verb TF-IDF'] = tl_verb_tf_idf\n",
    "    dict_tl_il_vb['Tagalog Verb Count'] = tl_verb_term_count\n",
    "    dict_tl_il_vb['Ilokano Verb'] = il_verb_list\n",
    "    dict_tl_il_vb['Ilokano Verb Count'] = il_verb_count_list\n",
    "    dict_tl_il_vb['Ilokano Verb TF-IDF'] = il_verb_tf_idf\n",
    "    \n",
    "    dict_tl_il_nn['Tagalog Noun'] = tl_noun_list\n",
    "    dict_tl_il_nn['Tagalog Noun TF-IDF'] = tl_noun_tf_idf\n",
    "    dict_tl_il_nn['Tagalog Noun Count'] = tl_noun_count_list\n",
    "    dict_tl_il_nn['Ilokano Noun'] = il_noun_list\n",
    "    dict_tl_il_nn['Ilokano Noun Count'] = il_noun_count_list\n",
    "    dict_tl_il_nn['Ilokano Noun TF-IDF'] = il_noun_tf_idf\n",
    "    \n",
    "    dict_tl_il_jj['Tagalog Adjective'] = tl_adj_list\n",
    "    dict_tl_il_jj['Tagalog Adjective TF-IDF'] = tl_adj_tf_idf\n",
    "    dict_tl_il_jj['Tagalog Adjective Count'] = tl_adj_count_list\n",
    "    dict_tl_il_jj['Ilokano Adjective'] = il_adj_list\n",
    "    dict_tl_il_jj['Ilokano Adjective Count'] = il_adj_count_list\n",
    "    dict_tl_il_jj['Ilokano Adjective TF-IDF'] = il_adj_tf_idf\n",
    "\n",
    "    dict_tl_il_rb['Tagalog Adverb'] = tl_adv_list\n",
    "    dict_tl_il_rb['Tagalog Adverb TF-IDF'] = tl_adv_tf_idf\n",
    "    dict_tl_il_rb['Tagalog Adverb Count'] = tl_adv_count_list\n",
    "    dict_tl_il_rb['Ilokano Adverb'] = il_adv_list\n",
    "    dict_tl_il_rb['Ilokano Adverb Count'] = il_adv_count_list\n",
    "    dict_tl_il_rb['Ilokano Adverb TF-IDF'] = il_adv_tf_idf\n",
    "\n",
    "    dict_tl_il_cc['Tagalog Conjunction'] = tl_conj_list\n",
    "    dict_tl_il_cc['Tagalog Conjunction TF-IDF'] = tl_conj_tf_idf\n",
    "    dict_tl_il_cc['Tagalog Conjunction Count'] = tl_conj_count_list\n",
    "    dict_tl_il_cc['Ilokano Conjunction'] = il_conj_list\n",
    "    dict_tl_il_cc['Ilokano Conjunction Count'] = il_conj_count_list\n",
    "    dict_tl_il_cc['Ilokano Conjunction TF-IDF'] = il_conj_tf_idf\n",
    "\n",
    "    # dict_tl_il_pr['Tagalog Preposition'] = tl_prepo_list\n",
    "    # dict_tl_il_pr['Tagalog Preposition TF-IDF'] = tl_prepo_tf_idf\n",
    "    # dict_tl_il_pr['Tagalog Preposition Count'] = tl_prepo_count_list\n",
    "    # dict_tl_il_pr['Ilokano Preposition'] = il_prepo_list\n",
    "    # dict_tl_il_pr['Ilokano Preposition Count'] = il_prepo_count_list\n",
    "    # dict_tl_il_pr['Ilokano Preposition TF-IDF'] = il_prepo_tf_idf\n",
    "    \n",
    "    dict_tl_il_dt['Tagalog Determiner'] = tl_dt_list\n",
    "    dict_tl_il_dt['Tagalog Determiner TF-IDF'] = tl_dt_tf_idf\n",
    "    dict_tl_il_dt['Tagalog Determiner Count'] = tl_dt_count_list\n",
    "    dict_tl_il_dt['Ilokano Determiner'] = il_dt_list\n",
    "    dict_tl_il_dt['Ilokano Determiner Count'] = il_dt_count_list\n",
    "    dict_tl_il_dt['Ilokano Determiner TF-IDF'] = il_dt_tf_idf\n",
    "    \n",
    "match_tl_il_pos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tagalog Determiner</th>\n",
       "      <th>Ilokano Determiner</th>\n",
       "      <th>Tagalog Determiner TF-IDF</th>\n",
       "      <th>Tagalog Determiner Count</th>\n",
       "      <th>Ilokano Determiner Count</th>\n",
       "      <th>Ilokano Determiner TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ng</td>\n",
       "      <td>[None, iti, ti, coma, dagiti, ken, a, pay, idi...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11417</td>\n",
       "      <td>[0, 1404, 2434, 52, 956, 502, 1648, 10, 68, 36...</td>\n",
       "      <td>[0.0, 76.03, 127.82, 7.75, 65.23, 29.56, 79.46...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ang</td>\n",
       "      <td>[None, ti, a, dagiti, coma, ken, nga, iti, ni,...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11379</td>\n",
       "      <td>[0, 3525, 926, 1866, 79, 482, 346, 575, 521, 1...</td>\n",
       "      <td>[0.0, 185.58, 51.59, 123.32, 9.43, 32.79, 24.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nang</td>\n",
       "      <td>[idi, iti, None, nga, a, ti, ken, ni, dagiti, ...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1575</td>\n",
       "      <td>[494, 150, 0, 83, 54, 21, 9, 28, 7, 6, 2, 1, 1...</td>\n",
       "      <td>[32.76, 12.8, 0.0, 7.36, 5.08, 2.91, 1.02, 3.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ay</td>\n",
       "      <td>[ti, None, a, ken, dagiti, ni, iti, idi, nga, ...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>7394</td>\n",
       "      <td>[533, 0, 604, 142, 170, 258, 534, 112, 172, 99...</td>\n",
       "      <td>[44.99, 0.0, 44.41, 16.35, 18.18, 27.39, 43.93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sumasa</td>\n",
       "      <td>[None, nga, a, idi, ken, iti, ni, ti]</td>\n",
       "      <td>0.13</td>\n",
       "      <td>36</td>\n",
       "      <td>[0, 1, 3, 4, 1, 1, 1, 1]</td>\n",
       "      <td>[0.0, 0.25, 0.37, 0.57, 0.11, 0.85, 0.0, 0.11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>na</td>\n",
       "      <td>[None, nga, a, ti, ken, dagiti, iti, pay, ni, ...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>9891</td>\n",
       "      <td>[0, 1441, 2984, 821, 365, 248, 798, 16, 579, 1...</td>\n",
       "      <td>[0.0, 71.43, 130.74, 50.73, 21.77, 19.38, 47.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sa</td>\n",
       "      <td>[cadagiti, None, dagiti, nga, iti, ken, ti, a,...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>13051</td>\n",
       "      <td>[912, 0, 472, 624, 3677, 736, 1720, 1796, 20, ...</td>\n",
       "      <td>[61.22, 0.0, 35.07, 36.54, 145.52, 42.44, 89.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nasa</td>\n",
       "      <td>[None, nga, iti, dagiti, ti, idiay, ditoy, idi...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>729</td>\n",
       "      <td>[0, 55, 106, 9, 47, 28, 1, 29, 26, 5, 9, 9, 9, 2]</td>\n",
       "      <td>[0.0, 5.0, 10.55, 0.99, 5.26, 4.16, 0.18, 4.16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mga</td>\n",
       "      <td>[None, dagiti, ti, a, iti, ken, nga, ni, cadag...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>8178</td>\n",
       "      <td>[0, 1049, 737, 1015, 493, 562, 309, 313, 480, ...</td>\n",
       "      <td>[0.0, 68.58, 51.79, 61.07, 37.02, 33.21, 23.8,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pa</td>\n",
       "      <td>[None, pay, a, ti, dagiti, iti, ni, idi, ken, ...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>331</td>\n",
       "      <td>[0, 27, 20, 24, 7, 11, 4, 7, 3, 4, 4, 1]</td>\n",
       "      <td>[0.0, 5.85, 2.76, 4.39, 1.14, 1.24, 0.75, 0.89...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ni</td>\n",
       "      <td>[None, ni, ti, dagiti, ken, nga, idi, a, iti, ...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>4979</td>\n",
       "      <td>[0, 1021, 202, 95, 130, 270, 41, 423, 126, 41,...</td>\n",
       "      <td>[0.0, 76.39, 18.19, 12.04, 11.61, 19.48, 4.17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>si</td>\n",
       "      <td>[ni, None, nga, ken, ti, iti, a, dagiti, coma,...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>3323</td>\n",
       "      <td>[1371, 0, 105, 319, 70, 52, 173, 23, 7, 5, 2, ...</td>\n",
       "      <td>[95.69, 0.0, 11.63, 36.01, 11.28, 5.79, 14.19,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ngayon</td>\n",
       "      <td>[ti, None, nga, ita, iti, dagiti, a, ken, coma...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>348</td>\n",
       "      <td>[12, 0, 14, 97, 11, 2, 11, 2, 5, 4, 1]</td>\n",
       "      <td>[2.54, 0.0, 1.51, 12.67, 1.47, 0.23, 1.78, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pagkatapos</td>\n",
       "      <td>[None, ti, ken, iti, a, idi, nga, ni, dagiti]</td>\n",
       "      <td>0.08</td>\n",
       "      <td>210</td>\n",
       "      <td>[0, 15, 2, 47, 9, 10, 6, 2, 2]</td>\n",
       "      <td>[0.0, 2.43, 0.29, 5.2, 0.87, 1.7, 1.35, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>maaga</td>\n",
       "      <td>[None, nasapa, pay, a, iti, dagiti, ti]</td>\n",
       "      <td>0.08</td>\n",
       "      <td>44</td>\n",
       "      <td>[0, 14, 1, 8, 1, 1, 1]</td>\n",
       "      <td>[0.0, 1.36, 0.2, 0.86, 0.2, 0.16, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>kagabi</td>\n",
       "      <td>[None]</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nakaraan</td>\n",
       "      <td>[None, nga, a]</td>\n",
       "      <td>0.11</td>\n",
       "      <td>12</td>\n",
       "      <td>[0, 2, 2]</td>\n",
       "      <td>[0.0, 0.22, 0.31]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>kahapon</td>\n",
       "      <td>[None, idi]</td>\n",
       "      <td>0.19</td>\n",
       "      <td>5</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.0, 0.14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bukas</td>\n",
       "      <td>[None, a, iti, ti]</td>\n",
       "      <td>0.10</td>\n",
       "      <td>34</td>\n",
       "      <td>[0, 2, 1, 1]</td>\n",
       "      <td>[0.0, 0.39, 0.07, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tagalog Determiner                                 Ilokano Determiner  \\\n",
       "0                  ng  [None, iti, ti, coma, dagiti, ken, a, pay, idi...   \n",
       "1                 ang  [None, ti, a, dagiti, coma, ken, nga, iti, ni,...   \n",
       "2                nang  [idi, iti, None, nga, a, ti, ken, ni, dagiti, ...   \n",
       "3                  ay  [ti, None, a, ken, dagiti, ni, iti, idi, nga, ...   \n",
       "4              sumasa              [None, nga, a, idi, ken, iti, ni, ti]   \n",
       "5                  na  [None, nga, a, ti, ken, dagiti, iti, pay, ni, ...   \n",
       "6                  sa  [cadagiti, None, dagiti, nga, iti, ken, ti, a,...   \n",
       "7                nasa  [None, nga, iti, dagiti, ti, idiay, ditoy, idi...   \n",
       "8                 mga  [None, dagiti, ti, a, iti, ken, nga, ni, cadag...   \n",
       "9                  pa  [None, pay, a, ti, dagiti, iti, ni, idi, ken, ...   \n",
       "10                 ni  [None, ni, ti, dagiti, ken, nga, idi, a, iti, ...   \n",
       "11                 si  [ni, None, nga, ken, ti, iti, a, dagiti, coma,...   \n",
       "12             ngayon  [ti, None, nga, ita, iti, dagiti, a, ken, coma...   \n",
       "13         pagkatapos      [None, ti, ken, iti, a, idi, nga, ni, dagiti]   \n",
       "14              maaga            [None, nasapa, pay, a, iti, dagiti, ti]   \n",
       "15             kagabi                                             [None]   \n",
       "16           nakaraan                                     [None, nga, a]   \n",
       "17            kahapon                                        [None, idi]   \n",
       "18              bukas                                 [None, a, iti, ti]   \n",
       "\n",
       "    Tagalog Determiner TF-IDF  Tagalog Determiner Count  \\\n",
       "0                        0.01                     11417   \n",
       "1                        0.01                     11379   \n",
       "2                        0.04                      1575   \n",
       "3                        0.02                      7394   \n",
       "4                        0.13                        36   \n",
       "5                        0.01                      9891   \n",
       "6                        0.01                     13051   \n",
       "7                        0.06                       729   \n",
       "8                        0.01                      8178   \n",
       "9                        0.09                       331   \n",
       "10                       0.03                      4979   \n",
       "11                       0.04                      3323   \n",
       "12                       0.08                       348   \n",
       "13                       0.08                       210   \n",
       "14                       0.08                        44   \n",
       "15                       0.12                         2   \n",
       "16                       0.11                        12   \n",
       "17                       0.19                         5   \n",
       "18                       0.10                        34   \n",
       "\n",
       "                             Ilokano Determiner Count  \\\n",
       "0   [0, 1404, 2434, 52, 956, 502, 1648, 10, 68, 36...   \n",
       "1   [0, 3525, 926, 1866, 79, 482, 346, 575, 521, 1...   \n",
       "2   [494, 150, 0, 83, 54, 21, 9, 28, 7, 6, 2, 1, 1...   \n",
       "3   [533, 0, 604, 142, 170, 258, 534, 112, 172, 99...   \n",
       "4                            [0, 1, 3, 4, 1, 1, 1, 1]   \n",
       "5   [0, 1441, 2984, 821, 365, 248, 798, 16, 579, 1...   \n",
       "6   [912, 0, 472, 624, 3677, 736, 1720, 1796, 20, ...   \n",
       "7   [0, 55, 106, 9, 47, 28, 1, 29, 26, 5, 9, 9, 9, 2]   \n",
       "8   [0, 1049, 737, 1015, 493, 562, 309, 313, 480, ...   \n",
       "9            [0, 27, 20, 24, 7, 11, 4, 7, 3, 4, 4, 1]   \n",
       "10  [0, 1021, 202, 95, 130, 270, 41, 423, 126, 41,...   \n",
       "11  [1371, 0, 105, 319, 70, 52, 173, 23, 7, 5, 2, ...   \n",
       "12             [12, 0, 14, 97, 11, 2, 11, 2, 5, 4, 1]   \n",
       "13                     [0, 15, 2, 47, 9, 10, 6, 2, 2]   \n",
       "14                             [0, 14, 1, 8, 1, 1, 1]   \n",
       "15                                                [0]   \n",
       "16                                          [0, 2, 2]   \n",
       "17                                             [0, 1]   \n",
       "18                                       [0, 2, 1, 1]   \n",
       "\n",
       "                            Ilokano Determiner TF-IDF  \n",
       "0   [0.0, 76.03, 127.82, 7.75, 65.23, 29.56, 79.46...  \n",
       "1   [0.0, 185.58, 51.59, 123.32, 9.43, 32.79, 24.2...  \n",
       "2   [32.76, 12.8, 0.0, 7.36, 5.08, 2.91, 1.02, 3.4...  \n",
       "3   [44.99, 0.0, 44.41, 16.35, 18.18, 27.39, 43.93...  \n",
       "4      [0.0, 0.25, 0.37, 0.57, 0.11, 0.85, 0.0, 0.11]  \n",
       "5   [0.0, 71.43, 130.74, 50.73, 21.77, 19.38, 47.7...  \n",
       "6   [61.22, 0.0, 35.07, 36.54, 145.52, 42.44, 89.5...  \n",
       "7   [0.0, 5.0, 10.55, 0.99, 5.26, 4.16, 0.18, 4.16...  \n",
       "8   [0.0, 68.58, 51.79, 61.07, 37.02, 33.21, 23.8,...  \n",
       "9   [0.0, 5.85, 2.76, 4.39, 1.14, 1.24, 0.75, 0.89...  \n",
       "10  [0.0, 76.39, 18.19, 12.04, 11.61, 19.48, 4.17,...  \n",
       "11  [95.69, 0.0, 11.63, 36.01, 11.28, 5.79, 14.19,...  \n",
       "12  [2.54, 0.0, 1.51, 12.67, 1.47, 0.23, 1.78, 0.2...  \n",
       "13  [0.0, 2.43, 0.29, 5.2, 0.87, 1.7, 1.35, 0.0, 0...  \n",
       "14             [0.0, 1.36, 0.2, 0.86, 0.2, 0.16, 0.0]  \n",
       "15                                              [0.0]  \n",
       "16                                  [0.0, 0.22, 0.31]  \n",
       "17                                        [0.0, 0.14]  \n",
       "18                             [0.0, 0.39, 0.07, 0.0]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dict_tl_il_sw.head()\n",
    "# dict_tl_il_vb.head(50)\n",
    "# dict_tl_il_nn.head(50)\n",
    "# dict_tl_il_jj.head(50)\n",
    "# dict_tl_il_rb.head(50)\n",
    "# dict_tl_il_cc.head(50)\n",
    "# dict_tl_il_pr.head(50)\n",
    "dict_tl_il_dt.head(50)\n",
    "\n",
    "# temp_dict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the dictionary in the json file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Single Word Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved the dict_sw.json file\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dict_sw = dict_tl_il_sw.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Tagalog to Ilokano/Example-Based/dict_sw.json\", \"w\") as outfile:\n",
    "        json.dump(dict_sw, outfile)\n",
    "    print(\"successfully saved the dict_sw.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_sw.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Verb Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved the dict_vb.json file\n"
     ]
    }
   ],
   "source": [
    "dict_vb = dict_tl_il_vb.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Tagalog to Ilokano/Example-Based/dict_vb.json\", \"w\") as outfile:\n",
    "        json.dump(dict_vb, outfile)\n",
    "    print(\"successfully saved the dict_vb.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_vb.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Noun Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved the dict_nn.json file\n"
     ]
    }
   ],
   "source": [
    "dict_nn = dict_tl_il_nn.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Tagalog to Ilokano/Example-Based/dict_nn.json\", \"w\") as outfile:\n",
    "        json.dump(dict_nn, outfile)\n",
    "    print(\"successfully saved the dict_nn.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_nn.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Adjective Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved the dict_jj.json file\n"
     ]
    }
   ],
   "source": [
    "dict_jj = dict_tl_il_jj.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Tagalog to Ilokano/Example-Based/dict_jj.json\", \"w\") as outfile:\n",
    "        json.dump(dict_jj, outfile)\n",
    "    print(\"successfully saved the dict_jj.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_jj.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Adverb Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved the dict_rb.json file\n"
     ]
    }
   ],
   "source": [
    "dict_rb = dict_tl_il_rb.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Tagalog to Ilokano/Example-Based/dict_rb.json\", \"w\") as outfile:\n",
    "        json.dump(dict_rb, outfile)\n",
    "    print(\"successfully saved the dict_rb.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_rb.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Conjunction Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved the dict_cc.json file\n"
     ]
    }
   ],
   "source": [
    "dict_cc = dict_tl_il_cc.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Tagalog to Ilokano/Example-Based/dict_cc.json\", \"w\") as outfile:\n",
    "        json.dump(dict_cc, outfile)\n",
    "    print(\"successfully saved the dict_cc.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_cc.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Preposition Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_pr = dict_tl_il_pr.to_dict('records')\n",
    "\n",
    "# try:\n",
    "#     with open(\"../../src/json data/Tagalog to Ilokano/Example-Based/dict_pr.json\", \"w\") as outfile:\n",
    "#         json.dump(dict_pr, outfile)\n",
    "#     print(\"successfully saved the dict_pr.json file\")\n",
    "# except:\n",
    "#     print(\"Error in saving the dict_pr.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Determiner Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved the dict_dt.json file\n"
     ]
    }
   ],
   "source": [
    "dict_dt = dict_tl_il_dt.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Tagalog to Ilokano/Example-Based/dict_dt.json\", \"w\") as outfile:\n",
    "        json.dump(dict_dt, outfile)\n",
    "    print(\"successfully saved the dict_dt.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_dt.json file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2]]\n"
     ]
    }
   ],
   "source": [
    "temp_sen_list = []\n",
    "\n",
    "temp_sen_list.append([1])\n",
    "# temp_sen_list[0].append(1)\n",
    "temp_sen_list[0][0] += 1\n",
    "print(temp_sen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "temp_arr = ''\n",
    "\n",
    "print(len(temp_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd5e40cb983109c15fc1053f6f3e661cc97e68e07c1758cdbd2441c60186ce19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
