{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example-Based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of the Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the Tagalog Part of Speech Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents in the dataset: 17740\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the tagalog POS dataset\n",
    "il_pos_data = pd.read_json('../../src/json data/Ilokano to Tagalog/il_pos.json')\n",
    "\n",
    "il_doc_len = len(il_pos_data)\n",
    "\n",
    "print('Number of documents in the dataset: {}'.format(il_doc_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the Ilokano Part of Speech Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tokenized</th>\n",
       "      <th>Single Word</th>\n",
       "      <th>Determiner</th>\n",
       "      <th>Conjunction</th>\n",
       "      <th>Verb</th>\n",
       "      <th>Noun</th>\n",
       "      <th>Adjective</th>\n",
       "      <th>Adverb</th>\n",
       "      <th>Preposition</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GENESIS</td>\n",
       "      <td>[genesis]</td>\n",
       "      <td>[genesis]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[SW]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nilalang ng Dios ang sanglibutan.</td>\n",
       "      <td>[nilalang, ng, dios, ang, sanglibutan]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ng, ang]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[nilalang]</td>\n",
       "      <td>[dios, sanglibutan]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VB, DT, NN, DT, NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nang pasimula ay nilikha ng Dios ang langit at...</td>\n",
       "      <td>[nang, pasimula, ay, nilikha, ng, dios, ang, l...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[nang, ay, ng, ang, ang]</td>\n",
       "      <td>[at]</td>\n",
       "      <td>[nilikha]</td>\n",
       "      <td>[dios, langit, lupa]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[pasimula]</td>\n",
       "      <td>[DT, UNK, DT, VB, DT, NN, DT, NN, CC, DT, NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>At ang lupa ay walang anyo at walang laman; at...</td>\n",
       "      <td>[at, ang, lupa, ay, walang, anyo, at, walang, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ang, ay, ang, ay, sumasa, ng, ang, ng, ay, su...</td>\n",
       "      <td>[at, at, at, at]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[lupa, anyo, laman, kadiliman, kalaliman, espi...</td>\n",
       "      <td>[walang, walang]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ibabaw, ibabaw]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[CC, DT, NN, DT, JJ, NN, CC, JJ, NN, CC, DT, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>At sinabi ng Dios Magkaroon ng liwanag; at nag...</td>\n",
       "      <td>[at, sinabi, ng, dios, magkaroon, ng, liwanag,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ng, ng, ng]</td>\n",
       "      <td>[at, at]</td>\n",
       "      <td>[sinabi, magkaroon, nagkaroon]</td>\n",
       "      <td>[dios, liwanag, liwanag]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[CC, VB, DT, NN, VB, DT, NN, CC, VB, DT, NN]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  \\\n",
       "0                                            GENESIS   \n",
       "1                  Nilalang ng Dios ang sanglibutan.   \n",
       "2  Nang pasimula ay nilikha ng Dios ang langit at...   \n",
       "3  At ang lupa ay walang anyo at walang laman; at...   \n",
       "4  At sinabi ng Dios Magkaroon ng liwanag; at nag...   \n",
       "\n",
       "                                           Tokenized Single Word  \\\n",
       "0                                          [genesis]   [genesis]   \n",
       "1             [nilalang, ng, dios, ang, sanglibutan]          []   \n",
       "2  [nang, pasimula, ay, nilikha, ng, dios, ang, l...          []   \n",
       "3  [at, ang, lupa, ay, walang, anyo, at, walang, ...          []   \n",
       "4  [at, sinabi, ng, dios, magkaroon, ng, liwanag,...          []   \n",
       "\n",
       "                                          Determiner       Conjunction  \\\n",
       "0                                                 []                []   \n",
       "1                                          [ng, ang]                []   \n",
       "2                           [nang, ay, ng, ang, ang]              [at]   \n",
       "3  [ang, ay, ang, ay, sumasa, ng, ang, ng, ay, su...  [at, at, at, at]   \n",
       "4                                       [ng, ng, ng]          [at, at]   \n",
       "\n",
       "                             Verb  \\\n",
       "0                              []   \n",
       "1                      [nilalang]   \n",
       "2                       [nilikha]   \n",
       "3                              []   \n",
       "4  [sinabi, magkaroon, nagkaroon]   \n",
       "\n",
       "                                                Noun         Adjective Adverb  \\\n",
       "0                                                 []                []     []   \n",
       "1                                [dios, sanglibutan]                []     []   \n",
       "2                               [dios, langit, lupa]                []     []   \n",
       "3  [lupa, anyo, laman, kadiliman, kalaliman, espi...  [walang, walang]     []   \n",
       "4                           [dios, liwanag, liwanag]                []     []   \n",
       "\n",
       "        Preposition     Unknown  \\\n",
       "0                []          []   \n",
       "1                []          []   \n",
       "2                []  [pasimula]   \n",
       "3  [ibabaw, ibabaw]          []   \n",
       "4                []          []   \n",
       "\n",
       "                                                 POS  \n",
       "0                                               [SW]  \n",
       "1                               [VB, DT, NN, DT, NN]  \n",
       "2      [DT, UNK, DT, VB, DT, NN, DT, NN, CC, DT, NN]  \n",
       "3  [CC, DT, NN, DT, JJ, NN, CC, JJ, NN, CC, DT, N...  \n",
       "4       [CC, VB, DT, NN, VB, DT, NN, CC, VB, DT, NN]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the tagalog POS dataset\n",
    "tl_pos_data = pd.read_json('../../src/json data/Tagalog to Ilokano/tl_pos.json')\n",
    "\n",
    "tl_doc_len = len(tl_pos_data)\n",
    "\n",
    "tl_pos_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the Tagalog Part of Speech Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sen_poss = pd.DataFrame(il_pos_data['POS'])\n",
    "\n",
    "dict_sen_poss.columns = ['Ilokano POS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the Ilokano Part of Speech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ilokano POS</th>\n",
       "      <th>Tagalog POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[SW]</td>\n",
       "      <td>[SW]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[DT, VB, DT, NN, DT, NN]</td>\n",
       "      <td>[VB, DT, NN, DT, NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[DT, NN, DT, NN, VB, DT, NN, DT, DT, NN]</td>\n",
       "      <td>[DT, UNK, DT, VB, DT, NN, DT, NN, CC, DT, NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CC, DT, NN, VB, DT, DT, NN, DT, JJ, NN, CC, D...</td>\n",
       "      <td>[CC, DT, NN, DT, JJ, NN, CC, JJ, NN, CC, DT, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CC, DT, NN, VB, VB, DT, NN, CC, VB, DT, NN]</td>\n",
       "      <td>[CC, VB, DT, NN, VB, DT, NN, CC, VB, DT, NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[CC, DT, NN, VB, DT, DT, NN, JJ, CC, VB, DT, N...</td>\n",
       "      <td>[CC, VB, DT, NN, DT, NN, DT, RB, CC, VB, DT, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[CC, DT, NN, VB, DT, NN, NN, CC, DT, NN, VB, D...</td>\n",
       "      <td>[CC, VB, DT, NN, DT, NN, DT, JJ, CC, VB, NN, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[CC, DT, NN, VB, VB, DT, JJ, DT, NN, DT, PR, D...</td>\n",
       "      <td>[CC, VB, DT, NN, VB, DT, JJ, VB, DT, PR, DT, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[CC, DT, NN, VB, DT, NN, CC, VB, DT, NN, DT, V...</td>\n",
       "      <td>[CC, VB, DT, NN, DT, NN, CC, VB, DT, NN, DT, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[CC, DT, NN, VB, DT, NN, NN, CC, VB, DT, NN, D...</td>\n",
       "      <td>[CC, VB, DT, NN, DT, NN, DT, JJ, CC, VB, CC, V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[CC, DT, NN, VB, VB, DT, DT, NN, DT, VB, DT, P...</td>\n",
       "      <td>[CC, VB, DT, NN, VB, DT, NN, DT, DT, UNK, DT, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[CC, DT, NN, VB, DT, JJ, NN, CC, DT, VB, DT, N...</td>\n",
       "      <td>[CC, VB, DT, NN, DT, NN, DT, JJ, CC, DT, NN, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[CC, DT, NN, VB, VB, DT, DT, NN, DT, NN, NN, D...</td>\n",
       "      <td>[CC, VB, DT, NN, VB, DT, NN, DT, NN, NN, DT, V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[CC, VB, DT, NN, DT, NN, NN, DT, VB, NN, DT, N...</td>\n",
       "      <td>[CC, DT, NN, DT, VB, DT, NN, NN, DT, VB, UNK, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[CC, VB, DT, NN, DT, DT, NN, NN, DT, JJ]</td>\n",
       "      <td>[CC, VB, CC, VB, DT, JJ, NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[CC, DT, NN, VB, VB, DT, DT, NN, DT, NN, DT, N...</td>\n",
       "      <td>[CC, VB, DT, NN, VB, DT, DT, NN, DT, NN, DT, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[CC, VB, DT, NN, DT, NN, DT, NN, DT, NN, DT, N...</td>\n",
       "      <td>[CC, UNK, VB, DT, NN, DT, NN, CC, VB, DT, PR, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[CC, DT, NN, VB, DT, NN, DT, NN, DT, JJ, DT, N...</td>\n",
       "      <td>[CC, VB, DT, NN, DT, JJ, UNK, NN, DT, UNK, NN,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[CC, DT, NN, VB, NN, DT, NN, DT, NN, CC, VB, D...</td>\n",
       "      <td>[CC, DT, UNK, DT, NN, DT, NN, DT, NN, CC, VB, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[DT, CC, VB, DT, NN, DT, DT, NN, DT, CC, VB, D...</td>\n",
       "      <td>[CC, CC, VB, DT, NN, CC, DT, NN, CC, CC, UNK, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[CC, VB, DT, NN, DT, DT, NN, NN, DT, JJ]</td>\n",
       "      <td>[CC, VB, CC, VB, DT, JJ, DT, NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[CC, DT, NN, VB, VB, DT, DT, NN, DT, NN, DT, N...</td>\n",
       "      <td>[CC, VB, DT, NN, VB, DT, NN, DT, NN, DT, DT, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[CC, DT, NN, VB, DT, JJ, DT, NN, DT, NN, DT, N...</td>\n",
       "      <td>[CC, VB, DT, NN, DT, JJ, NN, DT, NN, CC, DT, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[CC, DT, NN, VB, NN, DT, NN, VB, DT, CC, VB, C...</td>\n",
       "      <td>[CC, DT, UNK, DT, RB, DT, VB, NN, VB, CC, VB, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[CC, VB, DT, NN, DT, DT, NN, NN, DT, JJ]</td>\n",
       "      <td>[CC, VB, CC, VB, DT, JJ, NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[CC, DT, NN, VB, VB, DT, DT, VB, DT, NN, NN, C...</td>\n",
       "      <td>[CC, VB, DT, NN, VB, DT, NN, DT, DT, NN, VB, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[CC, DT, NN, VB, DT, NN, DT, NN, CC, DT, VB, D...</td>\n",
       "      <td>[CC, VB, DT, NN, DT, NN, DT, NN, UNK, DT, NN, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[CC, DT, NN, VB, VB, DT, DT, NN, DT, NN, CC, N...</td>\n",
       "      <td>[CC, VB, DT, NN, VB, NN, DT, NN, DT, NN, NN, U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[CC, DT, NN, VB, DT, NN, DT, NN, NN, CC, DT, N...</td>\n",
       "      <td>[CC, VB, DT, NN, DT, NN, UNK, DT, NN, UNK, NN,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[CC, DT, NN, VB, NN, CC, DT, NN, VB, NN, VB, C...</td>\n",
       "      <td>[CC, UNK, VB, DT, NN, CC, DT, NN, VB, DT, NN, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[CC, DT, NN, VB, RB, VB, DT, NN, JJ, DT, JJ, D...</td>\n",
       "      <td>[CC, VB, DT, NN, UNK, UNK, UNK, DT, NN, DT, NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[DT, DT, NN, JJ, DT, RB, NN, DT, NN, DT, NN, R...</td>\n",
       "      <td>[CC, DT, NN, UNK, DT, NN, CC, DT, NN, VB, DT, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[CC, DT, NN, VB, RB, DT, RB, CC, RB, RB, NN, C...</td>\n",
       "      <td>[CC, VB, DT, NN, DT, NN, DT, NN, NN, CC, UNK, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[RB, DT, NN, CC, RB, RB, NN, RB, DT, NN, DT, NN]</td>\n",
       "      <td>[VB, DT, NN, CC, VB, DT, NN, VB, DT, NN, UNK, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[CC, VB, DT, NN, DT, DT, NN, DT, NN, DT, RB]</td>\n",
       "      <td>[CC, VB, DT, NN, CC, DT, NN, CC, DT, NN, DT, V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[CC, DT, JJ, DT, NN, DT, NN, VB, DT, NN, DT, R...</td>\n",
       "      <td>[CC, DT, JJ, NN, DT, VB, DT, NN, DT, NN, JJ, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[CC, VB, DT, NN, DT, NN, DT, JJ, CC, RB, CC, C...</td>\n",
       "      <td>[CC, VB, DT, NN, DT, JJ, NN, CC, NN, NN, VB, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[RB, VB, DT, VB, DT, NN, DT, DT, NN, DT, DT, J...</td>\n",
       "      <td>[VB, DT, NN, DT, NN, CC, DT, NN, DT, UNK, UNK,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[CC, DT, RB, DT, RB, DT, NN, DT, NN, DT, NN, C...</td>\n",
       "      <td>[CC, VB, DT, DT, JJ, VB, DT, UNK, CC, VB, UNK,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[CC, VB, DT, JJ, DT, VB, DT, NN, DT, NN, CC, V...</td>\n",
       "      <td>[CC, UNK, RB, NN, DT, VB, VB, DT, NN, CC, VB, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[CC, DT, NN, NN, VB, DT, NN, DT, NN, DT, NN, C...</td>\n",
       "      <td>[CC, VB, DT, UNK, NN, DT, NN, DT, NN, DT, NN, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[CC, DT, NN, NN, VB, DT, JJ, DT, NN, DT, NN, D...</td>\n",
       "      <td>[CC, VB, DT, UNK, NN, DT, JJ, NN, DT, NN, DT, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[CC, DT, NN, NN, VB, DT, NN, NN, DT, NN, DT, J...</td>\n",
       "      <td>[CC, VB, DT, UNK, NN, DT, NN, DT, NN, DT, UNK,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[CC, RB, DT, NN, DT, JJ, DT, NN, DT, NN, DT, N...</td>\n",
       "      <td>[CC, UNK, RB, NN, DT, VB, DT, RB, DT, VB, DT, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[DT, NN, DT, NN, NN, VB, NN, DT, NN, DT, NN, D...</td>\n",
       "      <td>[DT, NN, DT, NN, DT, NN, DT, NN, VB, DT, UNK, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[CC, DT, NN, DT, NN, DT, NN, NN]</td>\n",
       "      <td>[CC, DT, NN, DT, JJ, NN, RB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[VB, DT, DT, NN, DT, NN, DT, NN]</td>\n",
       "      <td>[UNK, RB, UNK, UNK, NN, CC, UNK, NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[DT, NN, DT, JJ, DT, NN, NN, RB, DT, NN, DT, N...</td>\n",
       "      <td>[CC, DT, NN, DT, JJ, VB, DT, NN, DT, NN, VB, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[CC, DT, NN, DT, JJ, DT, NN, NN, RB, DT, NN, D...</td>\n",
       "      <td>[CC, DT, NN, DT, JJ, VB, DT, NN, DT, NN, VB, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[CC, DT, NN, NN, VB, DT, NN, CC, VB, DT, NN, D...</td>\n",
       "      <td>[CC, VB, DT, UNK, NN, DT, NN, CC, VB, DT, NN, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Ilokano POS  \\\n",
       "0                                                [SW]   \n",
       "1                            [DT, VB, DT, NN, DT, NN]   \n",
       "2            [DT, NN, DT, NN, VB, DT, NN, DT, DT, NN]   \n",
       "3   [CC, DT, NN, VB, DT, DT, NN, DT, JJ, NN, CC, D...   \n",
       "4        [CC, DT, NN, VB, VB, DT, NN, CC, VB, DT, NN]   \n",
       "5   [CC, DT, NN, VB, DT, DT, NN, JJ, CC, VB, DT, N...   \n",
       "6   [CC, DT, NN, VB, DT, NN, NN, CC, DT, NN, VB, D...   \n",
       "7   [CC, DT, NN, VB, VB, DT, JJ, DT, NN, DT, PR, D...   \n",
       "8   [CC, DT, NN, VB, DT, NN, CC, VB, DT, NN, DT, V...   \n",
       "9   [CC, DT, NN, VB, DT, NN, NN, CC, VB, DT, NN, D...   \n",
       "10  [CC, DT, NN, VB, VB, DT, DT, NN, DT, VB, DT, P...   \n",
       "11  [CC, DT, NN, VB, DT, JJ, NN, CC, DT, VB, DT, N...   \n",
       "12  [CC, DT, NN, VB, VB, DT, DT, NN, DT, NN, NN, D...   \n",
       "13  [CC, VB, DT, NN, DT, NN, NN, DT, VB, NN, DT, N...   \n",
       "14           [CC, VB, DT, NN, DT, DT, NN, NN, DT, JJ]   \n",
       "15  [CC, DT, NN, VB, VB, DT, DT, NN, DT, NN, DT, N...   \n",
       "16  [CC, VB, DT, NN, DT, NN, DT, NN, DT, NN, DT, N...   \n",
       "17  [CC, DT, NN, VB, DT, NN, DT, NN, DT, JJ, DT, N...   \n",
       "18  [CC, DT, NN, VB, NN, DT, NN, DT, NN, CC, VB, D...   \n",
       "19  [DT, CC, VB, DT, NN, DT, DT, NN, DT, CC, VB, D...   \n",
       "20           [CC, VB, DT, NN, DT, DT, NN, NN, DT, JJ]   \n",
       "21  [CC, DT, NN, VB, VB, DT, DT, NN, DT, NN, DT, N...   \n",
       "22  [CC, DT, NN, VB, DT, JJ, DT, NN, DT, NN, DT, N...   \n",
       "23  [CC, DT, NN, VB, NN, DT, NN, VB, DT, CC, VB, C...   \n",
       "24           [CC, VB, DT, NN, DT, DT, NN, NN, DT, JJ]   \n",
       "25  [CC, DT, NN, VB, VB, DT, DT, VB, DT, NN, NN, C...   \n",
       "26  [CC, DT, NN, VB, DT, NN, DT, NN, CC, DT, VB, D...   \n",
       "27  [CC, DT, NN, VB, VB, DT, DT, NN, DT, NN, CC, N...   \n",
       "28  [CC, DT, NN, VB, DT, NN, DT, NN, NN, CC, DT, N...   \n",
       "29  [CC, DT, NN, VB, NN, CC, DT, NN, VB, NN, VB, C...   \n",
       "30  [CC, DT, NN, VB, RB, VB, DT, NN, JJ, DT, JJ, D...   \n",
       "31  [DT, DT, NN, JJ, DT, RB, NN, DT, NN, DT, NN, R...   \n",
       "32  [CC, DT, NN, VB, RB, DT, RB, CC, RB, RB, NN, C...   \n",
       "33   [RB, DT, NN, CC, RB, RB, NN, RB, DT, NN, DT, NN]   \n",
       "34       [CC, VB, DT, NN, DT, DT, NN, DT, NN, DT, RB]   \n",
       "35  [CC, DT, JJ, DT, NN, DT, NN, VB, DT, NN, DT, R...   \n",
       "36  [CC, VB, DT, NN, DT, NN, DT, JJ, CC, RB, CC, C...   \n",
       "37  [RB, VB, DT, VB, DT, NN, DT, DT, NN, DT, DT, J...   \n",
       "38  [CC, DT, RB, DT, RB, DT, NN, DT, NN, DT, NN, C...   \n",
       "39  [CC, VB, DT, JJ, DT, VB, DT, NN, DT, NN, CC, V...   \n",
       "40  [CC, DT, NN, NN, VB, DT, NN, DT, NN, DT, NN, C...   \n",
       "41  [CC, DT, NN, NN, VB, DT, JJ, DT, NN, DT, NN, D...   \n",
       "42  [CC, DT, NN, NN, VB, DT, NN, NN, DT, NN, DT, J...   \n",
       "43  [CC, RB, DT, NN, DT, JJ, DT, NN, DT, NN, DT, N...   \n",
       "44  [DT, NN, DT, NN, NN, VB, NN, DT, NN, DT, NN, D...   \n",
       "45                   [CC, DT, NN, DT, NN, DT, NN, NN]   \n",
       "46                   [VB, DT, DT, NN, DT, NN, DT, NN]   \n",
       "47  [DT, NN, DT, JJ, DT, NN, NN, RB, DT, NN, DT, N...   \n",
       "48  [CC, DT, NN, DT, JJ, DT, NN, NN, RB, DT, NN, D...   \n",
       "49  [CC, DT, NN, NN, VB, DT, NN, CC, VB, DT, NN, D...   \n",
       "\n",
       "                                          Tagalog POS  \n",
       "0                                                [SW]  \n",
       "1                                [VB, DT, NN, DT, NN]  \n",
       "2       [DT, UNK, DT, VB, DT, NN, DT, NN, CC, DT, NN]  \n",
       "3   [CC, DT, NN, DT, JJ, NN, CC, JJ, NN, CC, DT, N...  \n",
       "4        [CC, VB, DT, NN, VB, DT, NN, CC, VB, DT, NN]  \n",
       "5   [CC, VB, DT, NN, DT, NN, DT, RB, CC, VB, DT, N...  \n",
       "6   [CC, VB, DT, NN, DT, NN, DT, JJ, CC, VB, NN, D...  \n",
       "7   [CC, VB, DT, NN, VB, DT, JJ, VB, DT, PR, DT, N...  \n",
       "8   [CC, VB, DT, NN, DT, NN, CC, VB, DT, NN, DT, D...  \n",
       "9   [CC, VB, DT, NN, DT, NN, DT, JJ, CC, VB, CC, V...  \n",
       "10  [CC, VB, DT, NN, VB, DT, NN, DT, DT, UNK, DT, ...  \n",
       "11  [CC, VB, DT, NN, DT, NN, DT, JJ, CC, DT, NN, D...  \n",
       "12  [CC, VB, DT, NN, VB, DT, NN, DT, NN, NN, DT, V...  \n",
       "13  [CC, DT, NN, DT, VB, DT, NN, NN, DT, VB, UNK, ...  \n",
       "14                       [CC, VB, CC, VB, DT, JJ, NN]  \n",
       "15  [CC, VB, DT, NN, VB, DT, DT, NN, DT, NN, DT, N...  \n",
       "16  [CC, UNK, VB, DT, NN, DT, NN, CC, VB, DT, PR, ...  \n",
       "17  [CC, VB, DT, NN, DT, JJ, UNK, NN, DT, UNK, NN,...  \n",
       "18  [CC, DT, UNK, DT, NN, DT, NN, DT, NN, CC, VB, ...  \n",
       "19  [CC, CC, VB, DT, NN, CC, DT, NN, CC, CC, UNK, ...  \n",
       "20                   [CC, VB, CC, VB, DT, JJ, DT, NN]  \n",
       "21  [CC, VB, DT, NN, VB, DT, NN, DT, NN, DT, DT, N...  \n",
       "22  [CC, VB, DT, NN, DT, JJ, NN, DT, NN, CC, DT, N...  \n",
       "23  [CC, DT, UNK, DT, RB, DT, VB, NN, VB, CC, VB, ...  \n",
       "24                       [CC, VB, CC, VB, DT, JJ, NN]  \n",
       "25  [CC, VB, DT, NN, VB, DT, NN, DT, DT, NN, VB, D...  \n",
       "26  [CC, VB, DT, NN, DT, NN, DT, NN, UNK, DT, NN, ...  \n",
       "27  [CC, VB, DT, NN, VB, NN, DT, NN, DT, NN, NN, U...  \n",
       "28  [CC, VB, DT, NN, DT, NN, UNK, DT, NN, UNK, NN,...  \n",
       "29  [CC, UNK, VB, DT, NN, CC, DT, NN, VB, DT, NN, ...  \n",
       "30  [CC, VB, DT, NN, UNK, UNK, UNK, DT, NN, DT, NN...  \n",
       "31  [CC, DT, NN, UNK, DT, NN, CC, DT, NN, VB, DT, ...  \n",
       "32  [CC, VB, DT, NN, DT, NN, DT, NN, NN, CC, UNK, ...  \n",
       "33  [VB, DT, NN, CC, VB, DT, NN, VB, DT, NN, UNK, ...  \n",
       "34  [CC, VB, DT, NN, CC, DT, NN, CC, DT, NN, DT, V...  \n",
       "35  [CC, DT, JJ, NN, DT, VB, DT, NN, DT, NN, JJ, N...  \n",
       "36  [CC, VB, DT, NN, DT, JJ, NN, CC, NN, NN, VB, N...  \n",
       "37  [VB, DT, NN, DT, NN, CC, DT, NN, DT, UNK, UNK,...  \n",
       "38  [CC, VB, DT, DT, JJ, VB, DT, UNK, CC, VB, UNK,...  \n",
       "39  [CC, UNK, RB, NN, DT, VB, VB, DT, NN, CC, VB, ...  \n",
       "40  [CC, VB, DT, UNK, NN, DT, NN, DT, NN, DT, NN, ...  \n",
       "41  [CC, VB, DT, UNK, NN, DT, JJ, NN, DT, NN, DT, ...  \n",
       "42  [CC, VB, DT, UNK, NN, DT, NN, DT, NN, DT, UNK,...  \n",
       "43  [CC, UNK, RB, NN, DT, VB, DT, RB, DT, VB, DT, ...  \n",
       "44  [DT, NN, DT, NN, DT, NN, DT, NN, VB, DT, UNK, ...  \n",
       "45                       [CC, DT, NN, DT, JJ, NN, RB]  \n",
       "46               [UNK, RB, UNK, UNK, NN, CC, UNK, NN]  \n",
       "47  [CC, DT, NN, DT, JJ, VB, DT, NN, DT, NN, VB, D...  \n",
       "48  [CC, DT, NN, DT, JJ, VB, DT, NN, DT, NN, VB, D...  \n",
       "49  [CC, VB, DT, UNK, NN, DT, NN, CC, VB, DT, NN, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_sen_poss['Tagalog POS'] = tl_pos_data['POS']\n",
    "\n",
    "dict_sen_poss.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagalog to Ilokano Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_sen_poss_list = dict_sen_poss['Tagalog POS']\n",
    "il_sen_poss_list = dict_sen_poss['Ilokano POS']\n",
    "\"\"\"\n",
    "putting the POS of the sentences in a list object\n",
    "\"\"\"\n",
    "\n",
    "dict_il_tl_sw = pd.DataFrame(columns=['Ilokano Single Words', 'Tagalog Single Words'])\n",
    "dict_il_tl_vb = pd.DataFrame(columns=['Ilokano Verb', 'Tagalog Verb'])\n",
    "dict_il_tl_nn = pd.DataFrame(columns=['Ilokano Noun', 'Tagalog Noun'])\n",
    "dict_il_tl_jj = pd.DataFrame(columns=['Ilokano Adjective', 'Tagalog Adjective'])\n",
    "dict_il_tl_rb = pd.DataFrame(columns=['Ilokano Adverb', 'Tagalog Adverb'])\n",
    "dict_il_tl_cc = pd.DataFrame(columns=['Ilokano Conjunction', 'Tagalog Conjunction'])\n",
    "dict_il_tl_pr = pd.DataFrame(columns=['Ilokano Preposition', 'Tagalog Preposition'])\n",
    "dict_il_tl_dt = pd.DataFrame(columns=['Ilokano Determiner', 'Tagalog Determiner'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending in the List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Verb List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_vb_list(il_verb, il_verb_list, tl_verb, tl_verb_list, curr_tl_pos, prev_tl_pos,prev2_tl_pos, next_tl_pos, next2_tl_pos, matched, sp_index, wp_index, tl_verb_count_list, tl_verb_count, il_verb_count_list, il_verb_count, il_verb_term_count, il_verb_sen, il_verb_count_list_tf, il_sen_len, tl_verb_sen, tl_verb_count_list_idf, tl_verb_count_list_tf, tl_verb_count_tf, tl_sen_len):\n",
    "    \n",
    "    if il_verb not in il_verb_list: # il_verb_list = json ftle of verbs\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        il_verb_list.append(il_verb)\n",
    "        il_verb_count.append(1) \n",
    "        il_verb_term_count.append(il_verb_count) # not necessary\n",
    "        \n",
    "        if il_verb not in il_verb_sen: # il_verb_sen - list of verbs in a single sentence\n",
    "            il_verb_sen.append(il_verb)\n",
    "            il_verb_count_list.append(1)\n",
    "            il_verb_count_list_tf.append([1/il_sen_len])\n",
    "\n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = il_verb_list.index(il_verb)\n",
    "        \n",
    "        temp_verb_index = il_verb_list[temp_index].index(il_verb[0]) # not necessary\n",
    "        il_verb_term_count[temp_index][temp_verb_index] += 1\n",
    "\n",
    "        if il_verb not in il_verb_sen:\n",
    "            il_verb_sen.append(il_verb)\n",
    "            il_verb_count_list[temp_index] += 1\n",
    "            il_verb_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        else:\n",
    "            try:\n",
    "                il_verb_count_list_tf[temp_index][sp_index] += (1/il_sen_len)\n",
    "            except:\n",
    "                il_verb_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        \n",
    "        inDict = True\n",
    "\n",
    "    \"\"\"\n",
    "    append the the verb in the tagalog verb\n",
    "    \"\"\"\n",
    "    \n",
    " \n",
    "\n",
    "    if curr_tl_pos == 'VB' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if VB : VB\n",
    "        if the tlokano POS is a verb\n",
    "        \"\"\"\n",
    "        temp_verb = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        tl_verb.append(temp_verb)\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "    elif curr_tl_pos == 'NN' and prev_tl_pos == 'DT' and prev2_tl_pos == 'VB' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if VB : VB DT NN\n",
    "        if the tlokano POS is a verb\n",
    "        \"\"\"\n",
    "        temp_verb = tl_pos_data['Tokenized'][sp_index][wp_index -2]\n",
    "        tl_verb.append(temp_verb)\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "    elif curr_tl_pos == 'NN' and next_tl_pos == 'DT' and next2_tl_pos == 'VB' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if VB : VB DT NN\n",
    "        if the tlokano POS is a verb\n",
    "        \"\"\"\n",
    "        temp_verb = tl_pos_data['Tokenized'][sp_index][wp_index + 2]\n",
    "        tl_verb.append(temp_verb)\n",
    "        matched.append(wp_index + 2)\n",
    "        \n",
    "    elif curr_tl_pos == 'DT' and prev_tl_pos == 'VB' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if VB : VB DT\n",
    "        if the tlokano POS is a verb\n",
    "        \"\"\"\n",
    "        temp_verb = tl_pos_data['Tokenized'][sp_index][wp_index-1]\n",
    "        tl_verb.append(temp_verb)\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "    elif curr_tl_pos == 'NN' and next_tl_pos == 'VB'and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if VB : NN VB\n",
    "        if the tlokano POS is a verb\n",
    "        \"\"\"\n",
    "        temp_verb = tl_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        tl_verb.append(temp_verb)\n",
    "        matched.append(wp_index + 1)\n",
    "        \n",
    "    elif curr_tl_pos == 'DT' and next_tl_pos == 'VB' and wp_index not in matched:    \n",
    "        \"\"\"\n",
    "        if VB : DT VB\n",
    "        if the tlokano POS is a determiner and the next POS is a verb\n",
    "        eg. Ntlalang : ti Aramid\n",
    "        \"\"\"\n",
    "        temp_verb = tl_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        tl_verb.append(temp_verb)\n",
    "        matched.append(wp_index)\n",
    "        matched.append(wp_index + 1) \n",
    "\n",
    "    elif curr_tl_pos == 'NN' and next_tl_pos == 'VB' and wp_index not in matched:    \n",
    "        \"\"\"\n",
    "        if VB : NN VB\n",
    "        if the tlokano POS is a determiner and the next POS is a verb\n",
    "        \"\"\"\n",
    "        temp_verb = tl_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        tl_verb.append(temp_verb)\n",
    "        matched.append(wp_index + 1)\n",
    "        \n",
    "    elif curr_tl_pos == 'CC' and next_tl_pos == 'VB' and wp_index not in matched:    \n",
    "        \"\"\"\n",
    "        if VB : CC VB\n",
    "        if the tlokano POS is a determiner and the next POS is a verb\n",
    "        \"\"\"\n",
    "        temp_verb = tl_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        tl_verb.append(temp_verb)\n",
    "        matched.append(wp_index + 1)\n",
    "        \n",
    "    elif curr_tl_pos == 'UNK' and next_tl_pos == 'VB' and wp_index not in matched:    \n",
    "        \"\"\"\n",
    "        if VB : UNK VB\n",
    "        if the tlokano POS is a determiner and the next POS is a verb\n",
    "        \"\"\"\n",
    "        temp_verb = tl_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        tl_verb.append(temp_verb)\n",
    "        matched.append(wp_index + 1)\n",
    "        \n",
    "    elif curr_tl_pos == 'UNK' and prev_tl_pos == 'VB' and wp_index not in matched:    \n",
    "        \"\"\"\n",
    "        if VB : UNK VB\n",
    "        if the tlokano POS is a determiner and the next POS is a verb\n",
    "        \"\"\"\n",
    "        temp_verb = tl_pos_data['Tokenized'][sp_index][wp_index - 1]\n",
    "        tl_verb.append(temp_verb)\n",
    "        matched.append(wp_index - 1)\n",
    "        \n",
    "    elif curr_tl_pos == 'DT' and next_tl_pos == 'NN' and next2_tl_pos == 'VB' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if VB DT NN : DT NN VB\n",
    "        if the tlokano POS is a determiner and the next POS is a verb\n",
    "        \"\"\"\n",
    "        temp_verb = tl_pos_data['Tokenized'][sp_index][wp_index + 2]\n",
    "        tl_verb.append(temp_verb)\n",
    "        matched.append(wp_index + 2)\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if VB : Other POS\n",
    "        if the tlokano POS is not a verb\n",
    "        \"\"\"\n",
    "        tl_verb.append('None')\n",
    "        matched.append(wp_index)\n",
    "\n",
    "    if not inDict:\n",
    "        tl_verb_list.append(tl_verb)\n",
    "        if tl_verb[0] == 'None':\n",
    "            tl_verb_count.append(0)\n",
    "            tl_verb_count_tf.append(round((0/tl_sen_len), 6))\n",
    "        else:\n",
    "            tl_verb_count.append(1)\n",
    "            tl_verb_count_tf.append(round((1/tl_sen_len), 6))\n",
    "        tl_verb_count_list.append(tl_verb_count)\n",
    "        tl_verb_count_list_tf.append(tl_verb_count_tf)\n",
    "        \n",
    "        if tl_verb[0] not in tl_verb_sen:\n",
    "            tl_verb_sen.append(tl_verb[0])\n",
    "            if tl_verb[0] == 'None':\n",
    "                tl_verb_count_list_idf.append([0])\n",
    "            else:\n",
    "                tl_verb_count_list_idf.append([1])\n",
    "        else:\n",
    "            tl_verb_count_list_idf.append([0])\n",
    "            \n",
    "    else:\n",
    "        if tl_verb[0] not in tl_verb_list[temp_index]:\n",
    "            tl_verb_list[temp_index].append(tl_verb[0]) # temp_index = row index of the verb\n",
    "            if tl_verb[0] == 'None':\n",
    "                tl_verb_count_list[temp_index].append(0)\n",
    "                tl_verb_count_list_tf[temp_index].append(round((0/tl_sen_len), 6))\n",
    "            else:\n",
    "                tl_verb_count_list[temp_index].append(1)\n",
    "                tl_verb_count_list_tf[temp_index].append(round((1/tl_sen_len), 6)) \n",
    "            \n",
    "            if tl_verb[0] not in tl_verb_sen: # tl_verb_sen = list of verbs in  a single sentence\n",
    "                tl_verb_sen.append(tl_verb[0])\n",
    "                if tl_verb[0] == 'None':\n",
    "                    tl_verb_count_list_idf[temp_index].append(0)\n",
    "                else:\n",
    "                    tl_verb_count_list_idf[temp_index].append(1)\n",
    "            else:\n",
    "                tl_verb_count_list_idf[temp_index].append(0)\n",
    "            \n",
    "        else: # if the verb is already in tl_verb_list\n",
    "            temp_verb_index = tl_verb_list[temp_index].index(tl_verb[0])\n",
    "            if tl_verb[0] == 'None':\n",
    "                tl_verb_count_list[temp_index][temp_verb_index] += 0\n",
    "                tl_verb_count_list_tf[temp_index][temp_verb_index] += (0/tl_sen_len)\n",
    "            else:\n",
    "                tl_verb_count_list[temp_index][temp_verb_index] += 1\n",
    "                tl_verb_count_list_tf[temp_index][temp_verb_index] += (1/tl_sen_len)\n",
    "            tl_verb_count_list_tf[temp_index][temp_verb_index] = round(tl_verb_count_list_tf[temp_index][temp_verb_index], 6)\n",
    "            \n",
    "            if tl_verb[0] not in tl_verb_sen:\n",
    "                tl_verb_sen.append(tl_verb[0])\n",
    "                if tl_verb[0] == 'None':\n",
    "                    tl_verb_count_list_idf[temp_index][temp_verb_index] += 0\n",
    "                else:\n",
    "                    tl_verb_count_list_idf[temp_index][temp_verb_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Noun List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_nn_list(il_noun, il_noun_list, tl_noun, tl_noun_list, curr_tl_pos, prev_tl_pos, prev2_tl_pos, next_tl_pos, next2_tl_pos, matched, sp_index, wp_index, tl_noun_count_list, tl_noun_count, il_noun_count_list, il_noun_count, il_noun_term_count, il_noun_sen, il_noun_count_list_tf, il_sen_len, tl_noun_sen, tl_noun_count_list_idf, tl_noun_count_list_tf, tl_noun_count_tf, tl_sen_len):\n",
    "    \n",
    "    if il_noun not in il_noun_list:\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        il_noun_list.append(il_noun)\n",
    "        il_noun_count.append(1) \n",
    "        il_noun_term_count.append(il_noun_count)\n",
    "        \n",
    "        if il_noun not in il_noun_sen:\n",
    "            il_noun_sen.append(il_noun)\n",
    "            il_noun_count_list.append(1)\n",
    "            il_noun_count_list_tf.append([1/il_sen_len])\n",
    "\n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = il_noun_list.index(il_noun)\n",
    "\n",
    "        temp_noun_index = il_noun_list[temp_index].index(il_noun[0])\n",
    "        il_noun_term_count[temp_index][temp_noun_index] += 1\n",
    "        \n",
    "        if il_noun not in il_noun_sen:\n",
    "            il_noun_sen.append(il_noun)\n",
    "            il_noun_count_list[temp_index] += 1\n",
    "            il_noun_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        else:\n",
    "            try:\n",
    "                il_noun_count_list_tf[temp_index][sp_index] += (1/il_sen_len)\n",
    "            except:\n",
    "                il_noun_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        \n",
    "        inDict = True\n",
    "\n",
    "    \"\"\"\n",
    "    append the the noun in the tagalog noun\n",
    "    \"\"\"\n",
    "\n",
    "    if curr_tl_pos == 'NN' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if NN : NN\n",
    "        if the tlokano POS is a noun\n",
    "        \"\"\"\n",
    "        temp_noun = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        tl_noun.append(temp_noun)\n",
    "        matched.append(wp_index)\n",
    "\n",
    "        \n",
    "        \n",
    "    elif curr_tl_pos == 'DT' and prev_tl_pos == 'NN' and wp_index not in matched:    \n",
    "        \"\"\"\n",
    "        if NN : DT NN\n",
    "        if the tlokano POS is a determiner and the next POS is a noun\n",
    "        \"\"\"\n",
    "        temp_next_noun = tl_pos_data['Tokenized'][sp_index][wp_index - 1]\n",
    "        tl_noun.append(temp_next_noun) \n",
    "        matched.append(wp_index - 1)\n",
    "        \n",
    "    elif curr_tl_pos == 'VB' and prev_tl_pos == 'NN' and wp_index not in matched:    \n",
    "        \"\"\"\n",
    "        if NN : VB NN\n",
    "        if the tlokano POS is a determiner and the next POS is a noun\n",
    "        \"\"\"\n",
    "        temp_next_noun = tl_pos_data['Tokenized'][sp_index][wp_index - 1]\n",
    "        tl_noun.append(temp_next_noun) \n",
    "        matched.append(wp_index - 1)\n",
    "        \n",
    "    elif curr_tl_pos == ' ' and prev_tl_pos == 'NN' and wp_index not in matched:    \n",
    "        \"\"\"\n",
    "        if NN : NN []\n",
    "        if the tlokano POS is a determiner and the next POS is a noun\n",
    "        \"\"\"\n",
    "        temp_next_noun = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        tl_noun.append(temp_next_noun) \n",
    "        matched.append(wp_index)\n",
    "        \n",
    "        \n",
    "        \n",
    "    elif curr_tl_pos == 'DT' and next_tl_pos == 'NN' and wp_index not in matched:    \n",
    "        \"\"\"\n",
    "        if NN : DT NN\n",
    "        if the tlokano POS is a determiner and the next POS is a noun\n",
    "        \"\"\"\n",
    "        temp_next_noun = tl_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        tl_noun.append(temp_next_noun) \n",
    "        matched.append(wp_index + 1)\n",
    "        \n",
    "    elif curr_tl_pos == 'VB' and next_tl_pos == 'DT' and next2_tl_pos == 'NN' and wp_index not in matched:    \n",
    "        \"\"\"\n",
    "        if NN : VB DT NN\n",
    "        if the tlokano POS is a determiner and the next POS is a noun\n",
    "        \"\"\"\n",
    "        temp_next_noun = tl_pos_data['Tokenized'][sp_index][wp_index + 2]\n",
    "        tl_noun.append(temp_next_noun) \n",
    "        matched.append(wp_index + 2)\n",
    "        \n",
    "    elif curr_tl_pos == 'VB' and prev_tl_pos == 'DT' and prev2_tl_pos == 'NN' and wp_index not in matched:    \n",
    "        \"\"\"\n",
    "        if NN : VB DT NN\n",
    "        if the tlokano POS is a determiner and the next POS is a noun\n",
    "        \"\"\"\n",
    "        temp_next_noun = tl_pos_data['Tokenized'][sp_index][wp_index - 2]\n",
    "        tl_noun.append(temp_next_noun) \n",
    "        matched.append(wp_index - 2)\n",
    "        \n",
    "    \n",
    "          \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if NN : Other POS\n",
    "        if the tlokano POS is not a noun\n",
    "        \"\"\"\n",
    "        tl_noun.append('None')\n",
    "        matched.append(wp_index)\n",
    "\n",
    "    if not inDict:\n",
    "        tl_noun_list.append(tl_noun)\n",
    "        if tl_noun[0] == 'None':\n",
    "            tl_noun_count.append(0)\n",
    "            tl_noun_count_tf.append(round((0/tl_sen_len), 6))\n",
    "        else:\n",
    "            tl_noun_count.append(1)\n",
    "            tl_noun_count_tf.append(round((1/tl_sen_len), 6))\n",
    "        tl_noun_count_list.append(tl_noun_count)\n",
    "        tl_noun_count_list_tf.append(tl_noun_count_tf)\n",
    "        \n",
    "        if tl_noun[0] not in tl_noun_sen:\n",
    "            tl_noun_sen.append(tl_noun[0])\n",
    "            if tl_noun[0] == 'None':\n",
    "                tl_noun_count_list_idf.append([0])\n",
    "            else:\n",
    "                tl_noun_count_list_idf.append([1])\n",
    "        else:\n",
    "            tl_noun_count_list_idf.append([0])\n",
    "            \n",
    "    else:\n",
    "        if tl_noun[0] not in tl_noun_list[temp_index]:\n",
    "            tl_noun_list[temp_index].append(tl_noun[0]) # temp_index = row index of the noun\n",
    "            if tl_noun[0] == 'None':\n",
    "                tl_noun_count_list[temp_index].append(0)\n",
    "                tl_noun_count_list_tf[temp_index].append(round((0/tl_sen_len), 6))\n",
    "            else:\n",
    "                tl_noun_count_list[temp_index].append(1)\n",
    "                tl_noun_count_list_tf[temp_index].append(round((1/tl_sen_len), 6)) \n",
    "            \n",
    "            if tl_noun[0] not in tl_noun_sen: # tl_noun_sen = list of nouns in  a single sentence\n",
    "                tl_noun_sen.append(tl_noun[0])\n",
    "                if tl_noun[0] == 'None':\n",
    "                    tl_noun_count_list_idf[temp_index].append(0)\n",
    "                else:\n",
    "                    tl_noun_count_list_idf[temp_index].append(1)\n",
    "            else:\n",
    "                tl_noun_count_list_idf[temp_index].append(0)\n",
    "            \n",
    "        else: # if the noun is already in tl_noun_list\n",
    "            temp_noun_index = tl_noun_list[temp_index].index(tl_noun[0])\n",
    "            if tl_noun[0] == 'None':\n",
    "                tl_noun_count_list[temp_index][temp_noun_index] += 0\n",
    "                tl_noun_count_list_tf[temp_index][temp_noun_index] += (0/tl_sen_len)\n",
    "            else:\n",
    "                tl_noun_count_list[temp_index][temp_noun_index] += 1\n",
    "                tl_noun_count_list_tf[temp_index][temp_noun_index] += (1/tl_sen_len)\n",
    "            tl_noun_count_list_tf[temp_index][temp_noun_index] = round(tl_noun_count_list_tf[temp_index][temp_noun_index], 6)\n",
    "            \n",
    "            if tl_noun[0] not in tl_noun_sen:\n",
    "                tl_noun_sen.append(tl_noun[0])\n",
    "                if tl_noun[0] == 'None':\n",
    "                    tl_noun_count_list_idf[temp_index][temp_noun_index] += 0\n",
    "                else:\n",
    "                    tl_noun_count_list_idf[temp_index][temp_noun_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Adjective List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_jj_list(il_adj, il_adj_list, tl_adj, tl_adj_list, curr_tl_pos, prev_tl_pos, prev2_tl_pos, next_tl_pos, next2_tl_pos, matched, sp_index, wp_index, tl_adj_count_list, tl_adj_count, il_adj_count_list, il_adj_count, il_adj_term_count, il_adj_sen, il_adj_count_list_tf, il_sen_len, tl_adj_sen, tl_adj_count_list_idf, tl_adj_count_list_tf, tl_adj_count_tf, tl_sen_len):\n",
    "    \n",
    "    if il_adj not in il_adj_list:\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        il_adj_list.append(il_adj)\n",
    "        il_adj_count.append(1) \n",
    "        il_adj_term_count.append(il_adj_count)\n",
    "        \n",
    "        if il_adj not in il_adj_sen:\n",
    "            il_adj_sen.append(il_adj)\n",
    "            il_adj_count_list.append(1)\n",
    "            il_adj_count_list_tf.append([1/il_sen_len])\n",
    "\n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = il_adj_list.index(il_adj)\n",
    "\n",
    "        temp_adj_index = il_adj_list[temp_index].index(il_adj[0])\n",
    "        il_adj_term_count[temp_index][temp_adj_index] += 1\n",
    "        \n",
    "        if il_adj not in il_adj_sen:\n",
    "            il_adj_sen.append(il_adj)\n",
    "            il_adj_count_list[temp_index] += 1\n",
    "            il_adj_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        else:\n",
    "            try:\n",
    "                il_adj_count_list_tf[temp_index][sp_index] += (1/il_sen_len)\n",
    "            except:\n",
    "                il_adj_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        \n",
    "        inDict = True\n",
    "\n",
    "    \"\"\"\n",
    "    append the the adj in the tagalog adj\n",
    "    \"\"\"\n",
    "\n",
    "    if curr_tl_pos == 'JJ' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if JJ : JJ\n",
    "        if the tlokano POS is an adj\n",
    "        \"\"\"\n",
    "        temp_adj = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        tl_adj.append(temp_adj)\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "    elif curr_tl_pos == 'UNK' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if JJ : UNK\n",
    "        if the tlokano POS is an adj\n",
    "        \"\"\"\n",
    "        temp_adj = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        tl_adj.append(temp_adj)\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "    elif curr_tl_pos == 'DT' and next_tl_pos == 'JJ' and wp_index not in matched:    \n",
    "        \"\"\"\n",
    "        if JJ : DT JJ\n",
    "        if the tlokano POS is a determiner and the next POS is an adj\n",
    "        eg. mabubuting : ken naimbag\n",
    "        \"\"\"\n",
    "        temp_next_adj = tl_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        tl_adj.append(temp_next_adj) \n",
    "        matched.append(wp_index + 1)\n",
    "        \n",
    "    elif curr_tl_pos == 'NN' and prev_tl_pos == 'JJ' and wp_index not in matched:    \n",
    "        \"\"\"\n",
    "        if JJ :  NN DT JJ\n",
    "        if the tlokano POS is a determiner and the next POS is an adj\n",
    "        eg. mabubuting : ken naimbag\n",
    "        \"\"\"\n",
    "        temp_next_adj = tl_pos_data['Tokenized'][sp_index][wp_index - 1]\n",
    "        tl_adj.append(temp_next_adj) \n",
    "        matched.append(wp_index - 1)\n",
    "        \n",
    "    elif curr_tl_pos == 'CC' and prev_tl_pos == 'NN' and prev2_tl_pos == 'JJ' and wp_index not in matched:    \n",
    "        \"\"\"\n",
    "        if JJ :  NN DT JJ\n",
    "        if the tlokano POS is a determiner and the next POS is an adj\n",
    "        eg. mabubuting : ken naimbag\n",
    "        \"\"\"\n",
    "        temp_next_adj = tl_pos_data['Tokenized'][sp_index][wp_index - 2]\n",
    "        tl_adj.append(temp_next_adj) \n",
    "        matched.append(wp_index - 2)\n",
    "    \n",
    "    elif curr_tl_pos == 'NN' and next_tl_pos == 'DT' and next2_tl_pos == 'JJ' and wp_index not in matched:   \n",
    "        \"\"\"\n",
    "        if JJ : NN DT JJ\n",
    "        if the tlokano POS is a determiner and the next POS is an adj\n",
    "        eg. mabubuting : ken naimbag\n",
    "        \"\"\"\n",
    "        temp_curr_adj = tl_pos_data['Tokenized'][sp_index][wp_index + 2]\n",
    "        tl_adj.append(temp_curr_adj) \n",
    "        matched.append(wp_index + 2)\n",
    "\n",
    "    \n",
    "        \n",
    "    elif curr_tl_pos == 'JJ' and next_tl_pos == 'DT' and next2_tl_pos == 'NN' and wp_index not in matched:   \n",
    "        \"\"\"\n",
    "        if JJ : JJ NN\n",
    "        if the tlokano POS is a determiner and the next POS is an adj\n",
    "        eg. mabubuting : ken naimbag\n",
    "        \"\"\"\n",
    "        temp_curr_adj = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        tl_adj.append(temp_curr_adj) \n",
    "        matched.append(wp_index + 1)\n",
    "\n",
    "    else:\n",
    "        \"\"\"\n",
    "        if JJ : Other POS\n",
    "        if the tlokano POS is not an adj\n",
    "        \"\"\"\n",
    "        tl_adj.append('None')\n",
    "        matched.append(wp_index)\n",
    "\n",
    "    if not inDict:\n",
    "        tl_adj_list.append(tl_adj)\n",
    "        if tl_adj[0] == 'None':\n",
    "            tl_adj_count.append(0)\n",
    "            tl_adj_count_tf.append(round((0/tl_sen_len), 6))\n",
    "        else:\n",
    "            tl_adj_count.append(1)\n",
    "            tl_adj_count_tf.append(round((1/tl_sen_len), 6))\n",
    "        tl_adj_count_list.append(tl_adj_count)\n",
    "        tl_adj_count_list_tf.append(tl_adj_count_tf)\n",
    "        \n",
    "        if tl_adj[0] not in tl_adj_sen:\n",
    "            tl_adj_sen.append(tl_adj[0])\n",
    "            if tl_adj[0] == 'None':\n",
    "                tl_adj_count_list_idf.append([0])\n",
    "            else:\n",
    "                tl_adj_count_list_idf.append([1])\n",
    "        else:\n",
    "            tl_adj_count_list_idf.append([0])\n",
    "            \n",
    "    else:\n",
    "        if tl_adj[0] not in tl_adj_list[temp_index]:\n",
    "            tl_adj_list[temp_index].append(tl_adj[0]) # temp_index = row index of the adj\n",
    "            if tl_adj[0] == 'None':\n",
    "                tl_adj_count_list[temp_index].append(0)\n",
    "                tl_adj_count_list_tf[temp_index].append(round((0/tl_sen_len), 6))\n",
    "            else:\n",
    "                tl_adj_count_list[temp_index].append(1)\n",
    "                tl_adj_count_list_tf[temp_index].append(round((1/tl_sen_len), 6)) \n",
    "            \n",
    "            if tl_adj[0] not in tl_adj_sen: # tl_adj_sen = list of adjs in  a single sentence\n",
    "                tl_adj_sen.append(tl_adj[0])\n",
    "                if tl_adj[0] == 'None':\n",
    "                    tl_adj_count_list_idf[temp_index].append(0)\n",
    "                else:\n",
    "                    tl_adj_count_list_idf[temp_index].append(1)\n",
    "            else:\n",
    "                tl_adj_count_list_idf[temp_index].append(0)\n",
    "            \n",
    "        else: # if the adj is already in tl_adj_list\n",
    "            temp_adj_index = tl_adj_list[temp_index].index(tl_adj[0])\n",
    "            if tl_adj[0] == 'None':\n",
    "                tl_adj_count_list[temp_index][temp_adj_index] += 0\n",
    "                tl_adj_count_list_tf[temp_index][temp_adj_index] += (0/tl_sen_len)\n",
    "            else:\n",
    "                tl_adj_count_list[temp_index][temp_adj_index] += 1\n",
    "                tl_adj_count_list_tf[temp_index][temp_adj_index] += (1/tl_sen_len)\n",
    "            tl_adj_count_list_tf[temp_index][temp_adj_index] = round(tl_adj_count_list_tf[temp_index][temp_adj_index], 6)\n",
    "            \n",
    "            if tl_adj[0] not in tl_adj_sen:\n",
    "                tl_adj_sen.append(tl_adj[0])\n",
    "                if tl_adj[0] == 'None':\n",
    "                    tl_adj_count_list_idf[temp_index][temp_adj_index] += 0\n",
    "                else:\n",
    "                    tl_adj_count_list_idf[temp_index][temp_adj_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Adverb List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_rb_list(il_adv, il_adv_list, tl_adv, tl_adv_list, curr_tl_pos, next_tl_pos, next2_tl_pos, next3_tl_pos, prev_tl_pos, matched, sp_index, wp_index, tl_adv_count_list, tl_adv_count, il_adv_count_list, il_adv_count, il_adv_term_count, il_adv_sen, il_adv_count_list_tf, il_sen_len, tl_adv_sen, tl_adv_count_list_idf, tl_adv_count_list_tf, tl_adv_count_tf, tl_sen_len):\n",
    "    \n",
    "    if il_adv not in il_adv_list:\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        il_adv_list.append(il_adv)\n",
    "        il_adv_count.append(1) \n",
    "        il_adv_term_count.append(il_adv_count)\n",
    "        \n",
    "        if il_adv not in il_adv_sen:\n",
    "            il_adv_sen.append(il_adv)\n",
    "            il_adv_count_list.append(1)\n",
    "            il_adv_count_list_tf.append([1/il_sen_len])\n",
    "\n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = il_adv_list.index(il_adv)\n",
    "\n",
    "        temp_adv_index = il_adv_list[temp_index].index(il_adv[0])\n",
    "        il_adv_term_count[temp_index][temp_adv_index] += 1\n",
    "        \n",
    "        if il_adv not in il_adv_sen:\n",
    "            il_adv_sen.append(il_adv)\n",
    "            il_adv_count_list[temp_index] += 1\n",
    "            il_adv_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        else:\n",
    "            try:\n",
    "                il_adv_count_list_tf[temp_index][sp_index] += (1/il_sen_len)\n",
    "            except:\n",
    "                il_adv_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        \n",
    "        inDict = True\n",
    "\n",
    "    \"\"\"\n",
    "    append the the verb in the tagalog verb\n",
    "    \"\"\"\n",
    "\n",
    "    if curr_tl_pos == 'RB' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if RB : RB\n",
    "        if the tlokano POS is a adverb\n",
    "        \"\"\"\n",
    "        temp_adverb = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        tl_adv.append(temp_adverb)\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "    elif curr_tl_pos == 'DT' and next_tl_pos == 'RB' and wp_index not in matched:    \n",
    "        \"\"\"\n",
    "        if RB : DT RB\n",
    "        \"\"\"\n",
    "        temp_next_adverb = tl_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        tl_adv.append(temp_next_adverb) \n",
    "        matched.append(wp_index + 1)\n",
    "  \n",
    "        \n",
    "    elif curr_tl_pos == 'DT' and next_tl_pos == 'NN' and next2_tl_pos == 'DT' and next3_tl_pos == 'RB' and wp_index not in matched:  \n",
    "        \"\"\"\n",
    "        if RB : DT NN DT RB\n",
    "        \n",
    "        \"\"\"\n",
    "        temp_adverb = tl_pos_data['Tokenized'][sp_index][wp_index + 3]\n",
    "        tl_adv.append(temp_adverb)\n",
    "        matched.append(wp_index + 3)\n",
    "        \n",
    "    elif curr_tl_pos == 'NN' and next_tl_pos == 'RB' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if RB : DT RB\n",
    "        \n",
    "        \"\"\"\n",
    "        temp_adverb = tl_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        tl_adv.append(temp_adverb)\n",
    "        matched.append(wp_index + 1)\n",
    "        \n",
    "    elif curr_tl_pos == 'UNK' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if RB : UNK\n",
    "        \n",
    "        \"\"\"\n",
    "        temp_adverb = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        tl_adv.append(temp_adverb)\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "        \n",
    "    elif curr_tl_pos == 'DT' and prev_tl_pos == 'RB' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if RB : DT RB\n",
    "        \n",
    "        \"\"\"\n",
    "        temp_adverb = tl_pos_data['Tokenized'][sp_index][wp_index - 1]\n",
    "        tl_adv.append(temp_adverb)\n",
    "        matched.append(wp_index - 1)\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if RB : Other POS\n",
    "        if the tlokano POS is not a adverb\n",
    "        \"\"\"\n",
    "        tl_adv.append('None')\n",
    "        matched.append(wp_index)\n",
    "\n",
    "    if not inDict:\n",
    "        tl_adv_list.append(tl_adv)\n",
    "        if tl_adv[0] == 'None':\n",
    "            tl_adv_count.append(0)\n",
    "            tl_adv_count_tf.append(round((0/tl_sen_len), 6))\n",
    "        else:\n",
    "            tl_adv_count.append(1)\n",
    "            tl_adv_count_tf.append(round((1/tl_sen_len), 6))\n",
    "        tl_adv_count_list.append(tl_adv_count)\n",
    "        tl_adv_count_list_tf.append(tl_adv_count_tf)\n",
    "        \n",
    "        if tl_adv[0] not in tl_adv_sen:\n",
    "            tl_adv_sen.append(tl_adv[0])\n",
    "            if tl_adv[0] == 'None':\n",
    "                tl_adv_count_list_idf.append([0])\n",
    "            else:\n",
    "                tl_adv_count_list_idf.append([1])\n",
    "        else:\n",
    "            tl_adv_count_list_idf.append([0])\n",
    "            \n",
    "    else:\n",
    "        if tl_adv[0] not in tl_adv_list[temp_index]:\n",
    "            tl_adv_list[temp_index].append(tl_adv[0]) # temp_index = row index of the adv\n",
    "            if tl_adv[0] == 'None':\n",
    "                tl_adv_count_list[temp_index].append(0)\n",
    "                tl_adv_count_list_tf[temp_index].append(round((0/tl_sen_len), 6))\n",
    "            else:\n",
    "                tl_adv_count_list[temp_index].append(1)\n",
    "                tl_adv_count_list_tf[temp_index].append(round((1/tl_sen_len), 6)) \n",
    "            \n",
    "            if tl_adv[0] not in tl_adv_sen: # tl_adv_sen = list of advs in  a single sentence\n",
    "                tl_adv_sen.append(tl_adv[0])\n",
    "                if tl_adv[0] == 'None':\n",
    "                    tl_adv_count_list_idf[temp_index].append(0)\n",
    "                else:\n",
    "                    tl_adv_count_list_idf[temp_index].append(1)\n",
    "            else:\n",
    "                tl_adv_count_list_idf[temp_index].append(0)\n",
    "            \n",
    "        else: # if the adv is already in tl_adv_list\n",
    "            temp_adv_index = tl_adv_list[temp_index].index(tl_adv[0])\n",
    "            if tl_adv[0] == 'None':\n",
    "                tl_adv_count_list[temp_index][temp_adv_index] += 0\n",
    "                tl_adv_count_list_tf[temp_index][temp_adv_index] += (0/tl_sen_len)\n",
    "            else:\n",
    "                tl_adv_count_list[temp_index][temp_adv_index] += 1\n",
    "                tl_adv_count_list_tf[temp_index][temp_adv_index] += (1/tl_sen_len)\n",
    "            tl_adv_count_list_tf[temp_index][temp_adv_index] = round(tl_adv_count_list_tf[temp_index][temp_adv_index], 6)\n",
    "            \n",
    "            if tl_adv[0] not in tl_adv_sen:\n",
    "                tl_adv_sen.append(tl_adv[0])\n",
    "                if tl_adv[0] == 'None':\n",
    "                    tl_adv_count_list_idf[temp_index][temp_adv_index] += 0\n",
    "                else:\n",
    "                    tl_adv_count_list_idf[temp_index][temp_adv_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Conjunction List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_cc_list(il_conj, il_conj_list, tl_conj, tl_conj_list, curr_tl_pos, matched, sp_index, wp_index, tl_conj_count_list, tl_conj_count, il_conj_count_list, il_conj_count, il_conj_term_count, il_conj_sen, il_conj_count_list_tf, il_sen_len, tl_conj_sen, tl_conj_count_list_idf, tl_conj_count_list_tf, tl_conj_count_tf, tl_sen_len):\n",
    "    \n",
    "    if il_conj not in il_conj_list: # il_conj_list = json ftle of verbs\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        il_conj_list.append(il_conj)\n",
    "        il_conj_count.append(1) \n",
    "        il_conj_term_count.append(il_conj_count)\n",
    "        \n",
    "        if il_conj not in il_conj_sen:\n",
    "            il_conj_sen.append(il_conj)\n",
    "            il_conj_count_list.append(1)\n",
    "            il_conj_count_list_tf.append([1/il_sen_len])\n",
    "\n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = il_conj_list.index(il_conj)\n",
    "\n",
    "        temp_conj_index = il_conj_list[temp_index].index(il_conj[0])\n",
    "        il_conj_term_count[temp_index][temp_conj_index] += 1\n",
    "        \n",
    "        if il_conj not in il_conj_sen:\n",
    "            il_conj_sen.append(il_conj)\n",
    "            il_conj_count_list[temp_index] += 1\n",
    "            il_conj_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        else:\n",
    "            try:\n",
    "                il_conj_count_list_tf[temp_index][sp_index] += (1/il_sen_len)\n",
    "            except:\n",
    "                il_conj_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        \n",
    "        inDict = True\n",
    "\n",
    "    \"\"\"\n",
    "    append the the conj in the tagalog conj\n",
    "    \"\"\"\n",
    "\n",
    "    if curr_tl_pos == 'CC':\n",
    "        \"\"\"\n",
    "        if CC : CC\n",
    "        if the tlokano POS is a conj\n",
    "        \"\"\"\n",
    "        temp_conj = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        tl_conj.append(temp_conj)\n",
    "        matched.append(wp_index)\n",
    "          \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if CC : Other POS\n",
    "        if the tlokano POS is not a conj\n",
    "        \"\"\"\n",
    "        tl_conj.append('None')\n",
    "        matched.append(wp_index)\n",
    "\n",
    "    if not inDict:\n",
    "        tl_conj_list.append(tl_conj)\n",
    "        if tl_conj[0] == 'None':\n",
    "            tl_conj_count.append(0)\n",
    "            tl_conj_count_tf.append(round((0/tl_sen_len), 6))\n",
    "        else:\n",
    "            tl_conj_count.append(1)\n",
    "            tl_conj_count_tf.append(round((1/tl_sen_len), 6))\n",
    "        tl_conj_count_list.append(tl_conj_count)\n",
    "        tl_conj_count_list_tf.append(tl_conj_count_tf)\n",
    "        \n",
    "        if tl_conj[0] not in tl_conj_sen:\n",
    "            tl_conj_sen.append(tl_conj[0])\n",
    "            if tl_conj[0] == 'None':\n",
    "                tl_conj_count_list_idf.append([0])\n",
    "            else:\n",
    "                tl_conj_count_list_idf.append([1])\n",
    "        else:\n",
    "            tl_conj_count_list_idf.append([0])\n",
    "            \n",
    "    else:\n",
    "        if tl_conj[0] not in tl_conj_list[temp_index]:\n",
    "            tl_conj_list[temp_index].append(tl_conj[0]) # temp_index = row index of the conj\n",
    "            if tl_conj[0] == 'None':\n",
    "                tl_conj_count_list[temp_index].append(0)\n",
    "                tl_conj_count_list_tf[temp_index].append(round((0/tl_sen_len), 6))\n",
    "            else:\n",
    "                tl_conj_count_list[temp_index].append(1)\n",
    "                tl_conj_count_list_tf[temp_index].append(round((1/tl_sen_len), 6)) \n",
    "            \n",
    "            if tl_conj[0] not in tl_conj_sen: # tl_conj_sen = list of conjs in  a single sentence\n",
    "                tl_conj_sen.append(tl_conj[0])\n",
    "                if tl_conj[0] == 'None':\n",
    "                    tl_conj_count_list_idf[temp_index].append(0)\n",
    "                else:\n",
    "                    tl_conj_count_list_idf[temp_index].append(1)\n",
    "            else:\n",
    "                tl_conj_count_list_idf[temp_index].append(0)\n",
    "            \n",
    "        else: # if the conj is already in tl_conj_list\n",
    "            temp_conj_index = tl_conj_list[temp_index].index(tl_conj[0])\n",
    "            if tl_conj[0] == 'None':\n",
    "                tl_conj_count_list[temp_index][temp_conj_index] += 0\n",
    "                tl_conj_count_list_tf[temp_index][temp_conj_index] += (0/tl_sen_len)\n",
    "            else:\n",
    "                tl_conj_count_list[temp_index][temp_conj_index] += 1\n",
    "                tl_conj_count_list_tf[temp_index][temp_conj_index] += (1/tl_sen_len)\n",
    "            tl_conj_count_list_tf[temp_index][temp_conj_index] = round(tl_conj_count_list_tf[temp_index][temp_conj_index], 6)\n",
    "            \n",
    "            if tl_conj[0] not in tl_conj_sen:\n",
    "                tl_conj_sen.append(tl_conj[0])\n",
    "                if tl_conj[0] == 'None':\n",
    "                    tl_conj_count_list_idf[temp_index][temp_conj_index] += 0\n",
    "                else:\n",
    "                    tl_conj_count_list_idf[temp_index][temp_conj_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Preposition List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_pr_list(il_prepo, il_prepo_list, tl_prepo, tl_prepo_list, curr_tl_pos, next_tl_pos, next2_tl_pos, matched, sp_index, wp_index, tl_prepo_count_list, tl_prepo_count, il_prepo_count_list, il_prepo_count, il_prepo_term_count, il_prepo_sen, il_prepo_count_list_tf, il_sen_len, tl_prepo_sen, tl_prepo_count_list_idf, tl_prepo_count_list_tf, tl_prepo_count_tf, tl_sen_len):\n",
    "    \n",
    "    if il_prepo not in il_prepo_list: # il_prepo_list = json ftle of verbs\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        il_prepo_list.append(il_prepo)\n",
    "        il_prepo_count.append(1) \n",
    "        il_prepo_term_count.append(il_prepo_count)\n",
    "        \n",
    "        if il_prepo not in il_prepo_sen:\n",
    "            il_prepo_sen.append(il_prepo)\n",
    "            il_prepo_count_list.append(1)\n",
    "            il_prepo_count_list_tf.append([1/il_sen_len])\n",
    "\n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = il_prepo_list.index(il_prepo)\n",
    "\n",
    "        temp_prepo_index = il_prepo_list[temp_index].index(il_prepo[0])\n",
    "        il_prepo_term_count[temp_index][temp_prepo_index] += 1\n",
    "        \n",
    "        if il_prepo not in il_prepo_sen:\n",
    "            il_prepo_sen.append(il_prepo)\n",
    "            il_prepo_count_list[temp_index] += 1\n",
    "            il_prepo_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        else:\n",
    "            try:\n",
    "                il_prepo_count_list_tf[temp_index][sp_index] += (1/il_sen_len)\n",
    "            except:\n",
    "                il_prepo_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        \n",
    "        inDict = True\n",
    "    \n",
    "    \"\"\"\n",
    "    append the the verb in the tagalog verb\n",
    "    \"\"\"\n",
    "    \n",
    "    if curr_tl_pos == 'PR' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if PR : PR\n",
    "        if the tlokano POS is a verb\n",
    "        \"\"\"\n",
    "        temp_prepo = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        tl_prepo.append(temp_prepo)\n",
    "        matched.append(wp_index)\n",
    "    if curr_tl_pos == 'DT' and next_tl_pos == 'PR' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if PR : PR\n",
    "        if the tlokano POS is a verb\n",
    "        \"\"\"\n",
    "        temp_prepo = tl_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        tl_prepo.append(temp_prepo)\n",
    "        matched.append(wp_index + 1)\n",
    "    if curr_tl_pos == 'DT' and next_tl_pos == 'PR' and next2_tl_pos == 'DT' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if PR : DT PR DT\n",
    "        if the tlokano prepo is sandwiched between 2 determiners\n",
    "        \"\"\"\n",
    "        temp_prepo = tl_pos_data['Tokenized'][sp_index][wp_index + 1]\n",
    "        tl_prepo.append(temp_prepo)\n",
    "        matched.append(wp_index + 1)\n",
    "    if curr_tl_pos == 'PR' and next_tl_pos == 'DT' and next2_tl_pos == 'NN' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if PR : DT PR DT\n",
    "        if the tlokano prepo is sandwiched between 2 determiners\n",
    "        \"\"\"\n",
    "        temp_prepo = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        tl_prepo.append(temp_prepo)\n",
    "        matched.append(wp_index)\n",
    "    \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if VB : Other POS\n",
    "        if the tlokano POS is not a verb\n",
    "        \"\"\"\n",
    "        tl_prepo.append('None')\n",
    "        matched.append(wp_index)\n",
    "    \n",
    "    if not inDict:\n",
    "        tl_prepo_list.append(tl_prepo)\n",
    "        if tl_prepo[0] == 'None':\n",
    "            tl_prepo_count.append(0)\n",
    "            tl_prepo_count_tf.append(round((0/tl_sen_len), 6))\n",
    "        else:\n",
    "            tl_prepo_count.append(1)\n",
    "            tl_prepo_count_tf.append(round((1/tl_sen_len), 6))\n",
    "        tl_prepo_count_list.append(tl_prepo_count)\n",
    "        tl_prepo_count_list_tf.append(tl_prepo_count_tf)\n",
    "        \n",
    "        if tl_prepo[0] not in tl_prepo_sen:\n",
    "            tl_prepo_sen.append(tl_prepo[0])\n",
    "            if tl_prepo[0] == 'None':\n",
    "                tl_prepo_count_list_idf.append([0])\n",
    "            else:\n",
    "                tl_prepo_count_list_idf.append([1])\n",
    "        else:\n",
    "            tl_prepo_count_list_idf.append([0])\n",
    "            \n",
    "    else:\n",
    "        if tl_prepo[0] not in tl_prepo_list[temp_index]:\n",
    "            tl_prepo_list[temp_index].append(tl_prepo[0]) # temp_index = row index of the prepo\n",
    "            if tl_prepo[0] == 'None':\n",
    "                tl_prepo_count_list[temp_index].append(0)\n",
    "                tl_prepo_count_list_tf[temp_index].append(round((0/tl_sen_len), 6))\n",
    "            else:\n",
    "                tl_prepo_count_list[temp_index].append(1)\n",
    "                tl_prepo_count_list_tf[temp_index].append(round((1/tl_sen_len), 6)) \n",
    "            \n",
    "            if tl_prepo[0] not in tl_prepo_sen: # tl_prepo_sen = list of prepos in  a single sentence\n",
    "                tl_prepo_sen.append(tl_prepo[0])\n",
    "                if tl_prepo[0] == 'None':\n",
    "                    tl_prepo_count_list_idf[temp_index].append(0)\n",
    "                else:\n",
    "                    tl_prepo_count_list_idf[temp_index].append(1)\n",
    "            else:\n",
    "                tl_prepo_count_list_idf[temp_index].append(0)\n",
    "            \n",
    "        else: # if the prepo is already in tl_prepo_list\n",
    "            temp_prepo_index = tl_prepo_list[temp_index].index(tl_prepo[0])\n",
    "            if tl_prepo[0] == 'None':\n",
    "                tl_prepo_count_list[temp_index][temp_prepo_index] += 0\n",
    "                tl_prepo_count_list_tf[temp_index][temp_prepo_index] += (0/tl_sen_len)\n",
    "            else:\n",
    "                tl_prepo_count_list[temp_index][temp_prepo_index] += 1\n",
    "                tl_prepo_count_list_tf[temp_index][temp_prepo_index] += (1/tl_sen_len)\n",
    "            tl_prepo_count_list_tf[temp_index][temp_prepo_index] = round(tl_prepo_count_list_tf[temp_index][temp_prepo_index], 6)\n",
    "            \n",
    "            if tl_prepo[0] not in tl_prepo_sen:\n",
    "                tl_prepo_sen.append(tl_prepo[0])\n",
    "                if tl_prepo[0] == 'None':\n",
    "                    tl_prepo_count_list_idf[temp_index][temp_prepo_index] += 0\n",
    "                else:\n",
    "                    tl_prepo_count_list_idf[temp_index][temp_prepo_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Determiner List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_dt_list(il_dt, il_dt_list, tl_dt, tl_dt_list, curr_tl_pos, next_tl_pos, next2_tl_pos, matched, sp_index, wp_index, tl_dt_count_list, tl_dt_count, il_dt_count_list, il_dt_count, il_dt_term_count, il_dt_sen, il_dt_count_list_tf, il_sen_len, tl_dt_sen, tl_dt_count_list_idf, tl_dt_count_list_tf, tl_dt_count_tf, tl_sen_len):\n",
    "    \n",
    "    if il_dt not in il_dt_list: # il_dt_list = json ftle of verbs\n",
    "        \"\"\"\n",
    "        if the verb is not in the list\n",
    "        \"\"\"\n",
    "        il_dt_list.append(il_dt)\n",
    "        il_dt_count.append(1) \n",
    "        il_dt_term_count.append(il_dt_count)\n",
    "        \n",
    "        if il_dt not in il_dt_sen:\n",
    "            il_dt_sen.append(il_dt)\n",
    "            il_dt_count_list.append(1)\n",
    "            il_dt_count_list_tf.append([1/il_sen_len])\n",
    "\n",
    "        inDict = False\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if the verb is in the list\n",
    "        \"\"\"\n",
    "        temp_index = il_dt_list.index(il_dt)\n",
    "\n",
    "        temp_dt_index = il_dt_list[temp_index].index(il_dt[0])\n",
    "        il_dt_term_count[temp_index][temp_dt_index] += 1\n",
    "        \n",
    "        if il_dt not in il_dt_sen:\n",
    "            il_dt_sen.append(il_dt)\n",
    "            il_dt_count_list[temp_index] += 1\n",
    "            il_dt_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        else:\n",
    "            try:\n",
    "                il_dt_count_list_tf[temp_index][sp_index] += (1/il_sen_len)\n",
    "            except:\n",
    "                il_dt_count_list_tf[temp_index].append(1/il_sen_len)\n",
    "        \n",
    "        inDict = True\n",
    "    \n",
    "    \"\"\"\n",
    "    append the the verb in the tagalog verb\n",
    "    \"\"\"\n",
    "    \n",
    "    if curr_tl_pos == 'DT' and wp_index not in matched:\n",
    "        \"\"\"\n",
    "        if PR : PR\n",
    "        if the tlokano POS is a verb\n",
    "        \"\"\"\n",
    "        temp_prepo = tl_pos_data['Tokenized'][sp_index][wp_index]\n",
    "        tl_dt.append(temp_prepo)\n",
    "        matched.append(wp_index)\n",
    "    \n",
    "    else:\n",
    "        \"\"\"\n",
    "        if VB : Other POS\n",
    "        if the tlokano POS is not a verb\n",
    "        \"\"\"\n",
    "        tl_dt.append('None')\n",
    "        matched.append(wp_index)\n",
    "        \n",
    "    if not inDict:\n",
    "        tl_dt_list.append(tl_dt)\n",
    "        if tl_dt[0] == 'None':\n",
    "            tl_dt_count.append(0)\n",
    "            tl_dt_count_tf.append(round((0/tl_sen_len), 6))\n",
    "        else:\n",
    "            tl_dt_count.append(1)\n",
    "            tl_dt_count_tf.append(round((1/tl_sen_len), 6))\n",
    "        tl_dt_count_list.append(tl_dt_count)\n",
    "        tl_dt_count_list_tf.append(tl_dt_count_tf)\n",
    "        \n",
    "        if tl_dt[0] not in tl_dt_sen:\n",
    "            tl_dt_sen.append(tl_dt[0])\n",
    "            if tl_dt[0] == 'None':\n",
    "                tl_dt_count_list_idf.append([0])\n",
    "            else:\n",
    "                tl_dt_count_list_idf.append([1])\n",
    "        else:\n",
    "            tl_dt_count_list_idf.append([0])\n",
    "            \n",
    "    else:\n",
    "        if tl_dt[0] not in tl_dt_list[temp_index]:\n",
    "            tl_dt_list[temp_index].append(tl_dt[0]) # temp_index = row index of the dt\n",
    "            if tl_dt[0] == 'None':\n",
    "                tl_dt_count_list[temp_index].append(0)\n",
    "                tl_dt_count_list_tf[temp_index].append(round((0/tl_sen_len), 6))\n",
    "            else:\n",
    "                tl_dt_count_list[temp_index].append(1)\n",
    "                tl_dt_count_list_tf[temp_index].append(round((1/tl_sen_len), 6)) \n",
    "            \n",
    "            if tl_dt[0] not in tl_dt_sen: # tl_dt_sen = list of dts in  a single sentence\n",
    "                tl_dt_sen.append(tl_dt[0])\n",
    "                if tl_dt[0] == 'None':\n",
    "                    tl_dt_count_list_idf[temp_index].append(0)\n",
    "                else:\n",
    "                    tl_dt_count_list_idf[temp_index].append(1)\n",
    "            else:\n",
    "                tl_dt_count_list_idf[temp_index].append(0)\n",
    "            \n",
    "        else: # if the dt is already in tl_dt_list\n",
    "            temp_dt_index = tl_dt_list[temp_index].index(tl_dt[0])\n",
    "            if tl_dt[0] == 'None':\n",
    "                tl_dt_count_list[temp_index][temp_dt_index] += 0\n",
    "                tl_dt_count_list_tf[temp_index][temp_dt_index] += (0/tl_sen_len)\n",
    "            else:\n",
    "                tl_dt_count_list[temp_index][temp_dt_index] += 1\n",
    "                tl_dt_count_list_tf[temp_index][temp_dt_index] += (1/tl_sen_len)\n",
    "            tl_dt_count_list_tf[temp_index][temp_dt_index] = round(tl_dt_count_list_tf[temp_index][temp_dt_index], 6)\n",
    "            \n",
    "            if tl_dt[0] not in tl_dt_sen:\n",
    "                tl_dt_sen.append(tl_dt[0])\n",
    "                if tl_dt[0] == 'None':\n",
    "                    tl_dt_count_list_idf[temp_index][temp_dt_index] += 0\n",
    "                else:\n",
    "                    tl_dt_count_list_idf[temp_index][temp_dt_index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_idf(tl_count_list):\n",
    "    tl_idf = []\n",
    "    for tl_count in tl_count_list:\n",
    "        temp_quo = tl_doc_len/tl_count\n",
    "        tl_idf.append(abs(math.log10(temp_quo)))\n",
    "        \n",
    "    return tl_idf\n",
    "# end of get_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf_il(il_verb_count_list_idf):\n",
    "    il_idf_list = []\n",
    "    for il_count_list in il_verb_count_list_idf:\n",
    "        il_idf = []\n",
    "        for il_count in il_count_list:\n",
    "            try:\n",
    "                temp_quo = il_doc_len/il_count\n",
    "                il_idf.append(round(abs(math.log10(temp_quo)), 6))\n",
    "            except:\n",
    "                temp_quo = 0\n",
    "                il_idf.append(0)\n",
    "                \n",
    "        il_idf_list.append(il_idf)\n",
    "    return il_idf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_il(il_count_sen_list, il_verb_count_list_tf):\n",
    "    il_tf_list = []\n",
    "    \n",
    "    for il_count_list in il_verb_count_list_tf:\n",
    "        il_tf = []\n",
    "\n",
    "        for il_count_sen in il_count_sen_list:\n",
    "            temp_sum = 0\n",
    "            \n",
    "            for il_count in il_count_sen:\n",
    "                temp_sum += il_count\n",
    "                \n",
    "            temp_len = len(il_count_sen)\n",
    "            temp_quo = temp_sum/temp_len\n",
    "            il_tf.append(round(temp_quo, 6))\n",
    "        \n",
    "    return il_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf(tl_count_sen_list):\n",
    "    tl_tf = []\n",
    "\n",
    "    for tl_count_sen in tl_count_sen_list:\n",
    "        temp_sum = 0\n",
    "        \n",
    "        for tl_count in tl_count_sen:\n",
    "            temp_sum += tl_count\n",
    "            \n",
    "        temp_len = len(tl_count_sen)\n",
    "        temp_quo = temp_sum/temp_len\n",
    "        tl_tf.append(round(temp_quo, 6))\n",
    "        \n",
    "    return tl_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf(tl_tf, tl_idf):\n",
    "    tf_idf_tl = []\n",
    "    \n",
    "    for i in range(len(tl_tf)):\n",
    "        temp_score = tl_tf[i] * tl_idf[i]\n",
    "        tf_idf_tl.append(round(temp_score, 2))\n",
    "        \n",
    "    return tf_idf_tl\n",
    "# end of get_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_idf_il(il_tf_list, il_idf_list):\n",
    "    il_tf_idf_list = []\n",
    "    \n",
    "    for i in range(len(il_tf_list)):\n",
    "        il_tf_idf = []\n",
    "        for j in range(len(il_tf_list[i])):\n",
    "            temp_score = il_tf_list[i][j] * il_idf_list[i][j]\n",
    "            il_tf_idf.append(round(temp_score, 2))\n",
    "            \n",
    "        il_tf_idf_list.append(il_tf_idf)\n",
    "        \n",
    "    return il_tf_idf_list\n",
    "# end of get_tf_idf_il"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tagalog to Ilokano Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "wp_index = None # word position index\n",
    "\n",
    "\"\"\"\n",
    "instantiating the verb lists\n",
    "\"\"\"\n",
    "\n",
    "def match_il_tl_pos():\n",
    "    \"\"\"\n",
    "    This function matches the POS of the sentences in the Tagalog and Ilokano datasets\n",
    "    \"\"\"\n",
    "    sp_index = 0\n",
    "    \n",
    "    il_sw_list = []\n",
    "    tl_sw_list = []\n",
    "    il_verb_list = []\n",
    "    tl_verb_list = []\n",
    "    il_noun_list = []\n",
    "    tl_noun_list = []\n",
    "    il_adj_list = []\n",
    "    tl_adj_list = []\n",
    "    il_adv_list = []\n",
    "    tl_adv_list = []\n",
    "    il_conj_list = []\n",
    "    tl_conj_list = []\n",
    "    il_prepo_list = []\n",
    "    tl_prepo_list = []\n",
    "    il_dt_list = []\n",
    "    tl_dt_list = []\n",
    "    il_to_tl_verb_list = []\n",
    "    \"\"\"\n",
    "    instantiating the verb lists\n",
    "    \"\"\"\n",
    "    \n",
    "    tl_verb_count_list = []\n",
    "    tl_noun_count_list = []\n",
    "    tl_adj_count_list = []\n",
    "    tl_adv_count_list = []\n",
    "    tl_conj_count_list = []\n",
    "    tl_prepo_count_list = []\n",
    "    tl_dt_count_list = []\n",
    "    \n",
    "    il_verb_count_list = []\n",
    "    il_noun_count_list = []\n",
    "    il_adj_count_list = []\n",
    "    il_adv_count_list = []\n",
    "    il_conj_count_list = []\n",
    "    il_prepo_count_list = []\n",
    "    il_dt_count_list = []\n",
    "\n",
    "    il_verb_count_list_tf = []\n",
    "    il_noun_count_list_tf = []\n",
    "    il_adj_count_list_tf = []\n",
    "    il_adv_count_list_tf = []\n",
    "    il_conj_count_list_tf = []\n",
    "    il_prepo_count_list_tf = []\n",
    "    il_dt_count_list_tf = []\n",
    "\n",
    "    tl_verb_count_list_tf = []\n",
    "    tl_noun_count_list_tf = []\n",
    "    tl_adj_count_list_tf = []\n",
    "    tl_adv_count_list_tf = []\n",
    "    tl_conj_count_list_tf = []\n",
    "    tl_prepo_count_list_tf = []\n",
    "    tl_dt_count_list_tf = []\n",
    "\n",
    "    il_verb_term_count = []\n",
    "    il_noun_term_count = []\n",
    "    il_adj_term_count = []\n",
    "    il_adv_term_count = []\n",
    "    il_conj_term_count = []\n",
    "    il_prepo_term_count = []\n",
    "    il_dt_term_count = []\n",
    "    \n",
    "    il_sen_len_list = []\n",
    "    tl_sen_len_list = []\n",
    "    \n",
    "    tl_verb_count_list_idf = []\n",
    "    tl_noun_count_list_idf = []\n",
    "    tl_adj_count_list_idf = []\n",
    "    tl_adv_count_list_idf = []\n",
    "    tl_conj_count_list_idf = []\n",
    "    tl_prepo_count_list_idf = []\n",
    "    tl_dt_count_list_idf = []\n",
    "    \n",
    "    tl_verb_count_list_tf = []\n",
    "    tl_noun_count_list_tf = []\n",
    "    tl_adj_count_list_tf = []\n",
    "    tl_adv_count_list_tf = []\n",
    "    tl_conj_count_list_tf = []\n",
    "    tl_prepo_count_list_tf = []\n",
    "    tl_dt_count_list_tf = []\n",
    "    \n",
    "    for il_sen_pos in il_sen_poss_list:\n",
    "        # loop for getting the pos structure of every sentence\n",
    "        \"\"\"\n",
    "        il_sen is a list of POS of a sentence\n",
    "        eg. ['VB', 'DT', 'NN', 'DT', 'NN']\n",
    "        \"\"\"\n",
    "        matched = []\n",
    "        tl_sen = tl_sen_poss_list[sp_index]\n",
    "        tl_sen_len = len(tl_sen)\n",
    "        il_sen_len = len(il_sen_pos)\n",
    "        tl_sen_len = len(tl_sen)\n",
    "        \n",
    "        il_sen_len_list.append(il_sen_len)\n",
    "        tl_sen_len_list.append(tl_sen_len)\n",
    "        \n",
    "        wp_index = 0\n",
    "        \"\"\"\n",
    "        instantiating the variables\n",
    "        \"\"\"\n",
    "        \n",
    "        il_verb_sen = []\n",
    "        il_noun_sen = []\n",
    "        il_adj_sen = []\n",
    "        il_adv_sen = []\n",
    "        il_conj_sen = []\n",
    "        il_prepo_sen = []\n",
    "        il_dt_sen = []\n",
    "        \n",
    "        tl_verb_sen = []\n",
    "        tl_noun_sen = []\n",
    "        tl_adj_sen = []\n",
    "        tl_adv_sen = []\n",
    "        tl_conj_sen = []\n",
    "        tl_prepo_sen = []\n",
    "        tl_dt_sen = []\n",
    "        \n",
    "        for il_word_pos in il_sen_pos:\n",
    "            # loop for eail pos in a sentence\n",
    "            \"\"\"\n",
    "            il_word_pos is a POS of a word\n",
    "            eg. 'VB'\n",
    "            \"\"\"\n",
    "            \n",
    "            tl_verb = []\n",
    "            tl_noun = []\n",
    "            tl_adj = []\n",
    "            tl_adv = []\n",
    "            tl_conj = []\n",
    "            tl_prepo = []\n",
    "            tl_dt = []\n",
    "            \n",
    "            tl_verb_count = []\n",
    "            tl_noun_count = []\n",
    "            tl_adj_count = []\n",
    "            tl_adv_count = []\n",
    "            tl_conj_count = []\n",
    "            tl_prepo_count = []\n",
    "            tl_dt_count = []\n",
    "            \n",
    "            tl_verb_count_tf = []\n",
    "            tl_noun_count_tf = []\n",
    "            tl_adj_count_tf = []\n",
    "            tl_adv_count_tf = []\n",
    "            tl_conj_count_tf = []\n",
    "            tl_prepo_count_tf = []\n",
    "            tl_dt_count_tf = []\n",
    "\n",
    "            il_verb_count = []\n",
    "            il_noun_count = []\n",
    "            il_adj_count = []\n",
    "            il_adv_count = []\n",
    "            il_conj_count = []\n",
    "            il_prepo_count = []\n",
    "            il_dt_count = []\n",
    "            \n",
    "            \n",
    "            il_word = il_pos_data['Tokenized'][sp_index][wp_index]\n",
    "            # gets the word in every sentence\n",
    "            \n",
    "            try:\n",
    "                curr_tl_pos = tl_sen[wp_index] # ti\n",
    "            except IndexError:\n",
    "                curr_tl_pos = 'None'\n",
    "            try:\n",
    "                next_tl_pos = tl_sen[wp_index + 1]\n",
    "            except IndexError:\n",
    "                next_tl_pos = 'None'\n",
    "            try:\n",
    "                next2_tl_pos = tl_sen[wp_index + 2]\n",
    "            except IndexError:\n",
    "                next2_tl_pos = 'None'\n",
    "            try:\n",
    "                next3_tl_pos = tl_sen[wp_index + 3]\n",
    "            except IndexError:\n",
    "                next3_tl_pos = 'None'\n",
    "            try:\n",
    "                prev_tl_pos = tl_sen[wp_index - 1]\n",
    "                if (wp_index - 1) < 0:\n",
    "                    prev_tl_pos = 'None'\n",
    "            except IndexError:\n",
    "                prev_tl_pos = 'None'\n",
    "            try:\n",
    "                prev2_tl_pos = tl_sen[wp_index - 2]\n",
    "                if (wp_index - 2) < 0:\n",
    "                    prev2_tl_pos = 'None'\n",
    "            except IndexError:\n",
    "                prev2_tl_pos = 'None'\n",
    "            \"\"\"\n",
    "            getting the current, next, and previous POS in the sentence\n",
    "            \"\"\"\n",
    "            \n",
    "            # matching Conditions\n",
    "            \n",
    "            # 1. SW\n",
    "            if il_word_pos == 'SW':\n",
    "                \"\"\"\n",
    "                if SW : SW\n",
    "                if the Tagalog POS is a SW\n",
    "                \"\"\"\n",
    "                tl_word = tl_pos_data['Tokenized'][sp_index]\n",
    "                il_sw_list.append(il_word)\n",
    "                tl_sw_list.append(tl_word)\n",
    "            \n",
    "            # 2. VB\n",
    "            if il_word_pos == 'VB':\n",
    "                \"\"\"\n",
    "                Verb matching\n",
    "                if the POS is a verb, append the index of the verb to the verb list\n",
    "                \"\"\"\n",
    "                \n",
    "                append_vb_list(il_word, il_verb_list, tl_verb, tl_verb_list, curr_tl_pos, prev_tl_pos, prev2_tl_pos, next_tl_pos, next2_tl_pos, matched, sp_index, wp_index, tl_verb_count_list, tl_verb_count, il_verb_count_list, il_verb_count, il_verb_term_count, il_verb_sen, il_verb_count_list_tf, il_sen_len, tl_verb_sen, tl_verb_count_list_idf, tl_verb_count_list_tf, tl_verb_count_tf, tl_sen_len)\n",
    "                \n",
    "            # 3. NN\n",
    "            if il_word_pos == 'NN':\n",
    "                \"\"\"\n",
    "                Noun matching\n",
    "                if the POS is a noun, append the index of the noun to the noun list\n",
    "                \"\"\"\n",
    "                append_nn_list(il_word, il_noun_list, tl_noun, tl_noun_list, curr_tl_pos, prev_tl_pos, prev2_tl_pos, next_tl_pos, next2_tl_pos, matched, sp_index, wp_index, tl_noun_count_list, tl_noun_count, il_noun_count_list, il_noun_count, il_noun_term_count, il_noun_sen, il_noun_count_list_tf, il_sen_len, tl_noun_sen, tl_noun_count_list_idf, tl_noun_count_list_tf, tl_noun_count_tf, tl_sen_len)\n",
    "\n",
    "            # 4. JJ\n",
    "            if il_word_pos == 'JJ':\n",
    "                \"\"\"\n",
    "                Adj matching\n",
    "                if the POS is a adj, append the index of the adj to the adj list\n",
    "                \"\"\"\n",
    "                append_jj_list(il_word, il_adj_list, tl_adj, tl_adj_list, curr_tl_pos, prev_tl_pos,prev2_tl_pos, next_tl_pos, next2_tl_pos, matched, sp_index, wp_index, tl_adj_count_list, tl_adj_count, il_adj_count_list, il_adj_count, il_adj_term_count, il_adj_sen, il_adj_count_list_tf, il_sen_len, tl_adj_sen, tl_adj_count_list_idf, tl_adj_count_list_tf, tl_adj_count_tf, tl_sen_len)\n",
    "            \n",
    "            # 5. RB\n",
    "            if il_word_pos == 'RB':\n",
    "                \"\"\"\n",
    "                Adverb matching\n",
    "                if the POS is a adverb, append the index of the adverb to the adverb list\n",
    "                \"\"\"\n",
    "                append_rb_list(il_word, il_adv_list, tl_adv, tl_adv_list, curr_tl_pos, next_tl_pos, next2_tl_pos, next3_tl_pos, prev_tl_pos, matched, sp_index, wp_index, tl_adv_count_list, tl_adv_count, il_adv_count_list, il_adv_count, il_adv_term_count, il_adv_sen, il_adv_count_list_tf, il_sen_len, tl_adv_sen, tl_adv_count_list_idf, tl_adv_count_list_tf, tl_adv_count_tf, tl_sen_len)\n",
    "            \n",
    "            # 6. CC\n",
    "            if il_word_pos == 'CC':\n",
    "                \"\"\"\n",
    "                Conjunction matching\n",
    "                if the POS is a conjunction, append the index of the conjunction to the conjunction list\n",
    "                \"\"\"\n",
    "                append_cc_list(il_word, il_conj_list, tl_conj, tl_conj_list, curr_tl_pos, matched, sp_index, wp_index, tl_conj_count_list, tl_conj_count, il_conj_count_list, il_conj_count, il_conj_term_count, il_conj_sen, il_conj_count_list_tf, il_sen_len, tl_conj_sen, tl_conj_count_list_idf, tl_conj_count_list_tf, tl_conj_count_tf, tl_sen_len)\n",
    "            \n",
    "            # 7. PR\n",
    "            if il_word_pos == 'PR':\n",
    "                \"\"\"\n",
    "                Preposition matching\n",
    "                if the POS is a preposition, append the index of the conjunction to the conjunction list\n",
    "                \"\"\"\n",
    "                append_pr_list(il_word, il_prepo_list, tl_prepo, tl_prepo_list, curr_tl_pos, next_tl_pos, next2_tl_pos, matched, sp_index, wp_index, tl_prepo_count_list, tl_prepo_count, il_prepo_count_list, il_prepo_count, il_prepo_term_count, il_prepo_sen, il_prepo_count_list_tf, il_sen_len, tl_prepo_sen, tl_prepo_count_list_idf, tl_prepo_count_list_tf, tl_prepo_count_tf, tl_sen_len)\n",
    "            \n",
    "            # 8. DT\n",
    "            if il_word_pos == 'DT':\n",
    "                \"\"\"\n",
    "                Determiner matching\n",
    "                if the POS is a determiner, append the index of the conjunction to the conjunction list\n",
    "                \"\"\"\n",
    "                append_dt_list(il_word, il_dt_list, tl_dt, tl_dt_list, curr_tl_pos, next_tl_pos, next2_tl_pos, matched, sp_index, wp_index, tl_dt_count_list, tl_dt_count, il_dt_count_list, il_dt_count, il_dt_term_count, il_dt_sen, il_dt_count_list_tf, il_sen_len, tl_dt_sen, tl_dt_count_list_idf, tl_dt_count_list_tf, tl_dt_count_tf, tl_sen_len)\n",
    "            \n",
    "                          \n",
    "            wp_index += 1  \n",
    "        sp_index += 1\n",
    "    \n",
    "    il_verb_idf = get_idf(il_verb_count_list)\n",
    "    il_noun_idf = get_idf(il_noun_count_list)\n",
    "    il_adj_idf = get_idf(il_adj_count_list)\n",
    "    il_adv_idf = get_idf(il_adv_count_list)\n",
    "    il_conj_idf = get_idf(il_conj_count_list)\n",
    "    il_prepo_idf = get_idf(il_prepo_count_list)\n",
    "    il_dt_idf = get_idf(il_dt_count_list)\n",
    "\n",
    "    il_verb_tf = get_tf(il_verb_count_list_tf)\n",
    "    il_noun_tf = get_tf(il_noun_count_list_tf)\n",
    "    il_adj_tf = get_tf(il_adj_count_list_tf)\n",
    "    il_adv_tf = get_tf(il_adv_count_list_tf)\n",
    "    il_conj_tf = get_tf(il_conj_count_list_tf)\n",
    "    il_prepo_tf = get_tf(il_prepo_count_list_tf)\n",
    "    il_dt_tf = get_tf(il_dt_count_list_tf)\n",
    "    \n",
    "    il_verb_tf_idf = get_tf_idf(il_verb_tf, il_verb_idf)\n",
    "    il_noun_tf_idf = get_tf_idf(il_noun_tf, il_noun_idf)\n",
    "    il_adj_tf_idf = get_tf_idf(il_adj_tf, il_adj_idf)\n",
    "    il_adv_tf_idf = get_tf_idf(il_adv_tf, il_adv_idf)\n",
    "    il_conj_tf_idf = get_tf_idf(il_conj_tf, il_conj_idf)\n",
    "    il_prepo_tf_idf = get_tf_idf(il_prepo_tf, il_prepo_idf)\n",
    "    il_dt_tf_idf = get_tf_idf(il_dt_tf, il_dt_idf)\n",
    "        \n",
    "    tl_verb_idf = get_idf_il(tl_verb_count_list_idf)\n",
    "    tl_noun_idf = get_idf_il(tl_noun_count_list_idf)\n",
    "    tl_adj_idf = get_idf_il(tl_adj_count_list_idf)\n",
    "    tl_adv_idf = get_idf_il(tl_adv_count_list_idf)\n",
    "    tl_conj_idf = get_idf_il(tl_conj_count_list_idf)\n",
    "    tl_prepo_idf = get_idf_il(tl_prepo_count_list_idf)\n",
    "    tl_dt_idf = get_idf_il(tl_dt_count_list_idf)\n",
    "    \n",
    "    tl_verb_tf_idf = get_tf_idf_il(tl_verb_count_list_tf, tl_verb_idf)\n",
    "    tl_noun_tf_idf = get_tf_idf_il(tl_noun_count_list_tf, tl_noun_idf)\n",
    "    tl_adj_tf_idf = get_tf_idf_il(tl_adj_count_list_tf, tl_adj_idf)\n",
    "    tl_adv_tf_idf = get_tf_idf_il(tl_adv_count_list_tf, tl_adv_idf)\n",
    "    tl_conj_tf_idf = get_tf_idf_il(tl_conj_count_list_tf, tl_conj_idf)\n",
    "    tl_prepo_tf_idf = get_tf_idf_il(tl_prepo_count_list_tf, tl_prepo_idf)\n",
    "    tl_dt_tf_idf = get_tf_idf_il(tl_dt_count_list_tf, tl_dt_idf)\n",
    "    \n",
    "    dict_il_tl_sw['Ilokano Single Words'] = il_sw_list\n",
    "    dict_il_tl_sw['Tagalog Single Words'] = tl_sw_list\n",
    "    \n",
    "    dict_il_tl_vb['Ilokano Verb'] = il_verb_list\n",
    "    dict_il_tl_vb['Ilokano Verb TF-IDF'] = il_verb_tf_idf\n",
    "    dict_il_tl_vb['Ilokano Verb Count'] = il_verb_term_count\n",
    "    dict_il_tl_vb['Tagalog Verb'] = tl_verb_list\n",
    "    dict_il_tl_vb['Tagalog Verb Count'] = tl_verb_count_list\n",
    "    dict_il_tl_vb['Tagalog Verb TF-IDF'] = tl_verb_tf_idf\n",
    "    \n",
    "    dict_il_tl_nn['Ilokano Noun'] = il_noun_list\n",
    "    dict_il_tl_nn['Ilokano Noun TF-IDF'] = il_noun_tf_idf\n",
    "    dict_il_tl_nn['Ilokano Noun Count'] = il_noun_count_list\n",
    "    dict_il_tl_nn['Tagalog Noun'] = tl_noun_list\n",
    "    dict_il_tl_nn['Tagalog Noun Count'] = tl_noun_count_list\n",
    "    dict_il_tl_nn['Tagalog Noun TF-IDF'] = tl_noun_tf_idf\n",
    "    \n",
    "    dict_il_tl_jj['Ilokano Adjective'] = il_adj_list\n",
    "    dict_il_tl_jj['Ilokano Adjective TF-IDF'] = il_adj_tf_idf\n",
    "    dict_il_tl_jj['Ilokano Adjective Count'] = il_adj_count_list\n",
    "    dict_il_tl_jj['Tagalog Adjective'] = tl_adj_list\n",
    "    dict_il_tl_jj['Tagalog Adjective Count'] = tl_adj_count_list\n",
    "    dict_il_tl_jj['Tagalog Adjective TF-IDF'] = tl_adj_tf_idf\n",
    "\n",
    "    dict_il_tl_rb['Ilokano Adverb'] = il_adv_list\n",
    "    dict_il_tl_rb['Ilokano Adverb TF-IDF'] = il_adv_tf_idf\n",
    "    dict_il_tl_rb['Ilokano Adverb Count'] = il_adv_count_list\n",
    "    dict_il_tl_rb['Tagalog Adverb'] = tl_adv_list\n",
    "    dict_il_tl_rb['Tagalog Adverb Count'] = tl_adv_count_list\n",
    "    dict_il_tl_rb['Tagalog Adverb TF-IDF'] = tl_adv_tf_idf\n",
    "\n",
    "    dict_il_tl_cc['Ilokano Conjunction'] = il_conj_list\n",
    "    dict_il_tl_cc['Ilokano Conjunction TF-IDF'] = il_conj_tf_idf\n",
    "    dict_il_tl_cc['Ilokano Conjunction Count'] = il_conj_count_list\n",
    "    dict_il_tl_cc['Tagalog Conjunction'] = tl_conj_list\n",
    "    dict_il_tl_cc['Tagalog Conjunction Count'] = tl_conj_count_list\n",
    "    dict_il_tl_cc['Tagalog Conjunction TF-IDF'] = tl_conj_tf_idf\n",
    "\n",
    "    dict_il_tl_pr['Ilokano Preposition'] = il_prepo_list\n",
    "    dict_il_tl_pr['Ilokano Preposition TF-IDF'] = il_prepo_tf_idf\n",
    "    dict_il_tl_pr['Ilokano Preposition Count'] = il_prepo_count_list\n",
    "    dict_il_tl_pr['Tagalog Preposition'] = tl_prepo_list\n",
    "    dict_il_tl_pr['Tagalog Preposition Count'] = tl_prepo_count_list\n",
    "    dict_il_tl_pr['Tagalog Preposition TF-IDF'] = tl_prepo_tf_idf\n",
    "    \n",
    "    dict_il_tl_dt['Ilokano Determiner'] = il_dt_list\n",
    "    dict_il_tl_dt['Ilokano Determiner TF-IDF'] = il_dt_tf_idf\n",
    "    dict_il_tl_dt['Ilokano Determiner Count'] = il_dt_count_list\n",
    "    dict_il_tl_dt['Tagalog Determiner'] = tl_dt_list\n",
    "    dict_il_tl_dt['Tagalog Determiner Count'] = tl_dt_count_list\n",
    "    dict_il_tl_dt['Tagalog Determiner TF-IDF'] = tl_dt_tf_idf\n",
    "    \n",
    "match_il_tl_pos()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ilokano Verb</th>\n",
       "      <th>Tagalog Verb</th>\n",
       "      <th>Ilokano Verb TF-IDF</th>\n",
       "      <th>Ilokano Verb Count</th>\n",
       "      <th>Tagalog Verb Count</th>\n",
       "      <th>Tagalog Verb TF-IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aramid</td>\n",
       "      <td>[nilalang, gawa, None, paglilingkod, ginawa, p...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[1, 4, 0, 1, 2, 1, 1, 1]</td>\n",
       "      <td>[0.85, 0.95, 0.0, 0.13, 0.46, 0.0, 0.0, 0.08]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pinarsuana</td>\n",
       "      <td>[nilikha, None]</td>\n",
       "      <td>0.18</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[1, 0]</td>\n",
       "      <td>[0.39, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adda</td>\n",
       "      <td>[None, magkaroon, taglay, may, hininga, nagkar...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>[1389]</td>\n",
       "      <td>[0, 9, 4, 13, 1, 33, 1, 1, 1, 1, 1, 11, 5, 1, ...</td>\n",
       "      <td>[0.0, 1.5, 0.77, 2.14, 0.12, 4.43, 0.18, 0.21,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>addada</td>\n",
       "      <td>[None, umapaw, dalawa, nangasa, nakakawala, ni...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>[225]</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 2, 1, 1, 6, 3, 1, 1, 1, 2, ...</td>\n",
       "      <td>[0.0, 0.24, 0.08, 0.22, 0.17, 0.18, 0.25, 0.15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kinunana</td>\n",
       "      <td>[None, sinabi, nagsabi, nasabi, narito, baka, ...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>[1115]</td>\n",
       "      <td>[0, 184, 59, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0.0, 16.37, 5.64, 0.2, 0.13, 0.1, 0.49, 0.15,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nagadda</td>\n",
       "      <td>[nagkaroon]</td>\n",
       "      <td>0.39</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.39]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nakitana</td>\n",
       "      <td>[None, nakita, nakakita, naritot, sapagkat, ni...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>[83]</td>\n",
       "      <td>[0, 8, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[0.0, 0.98, 0.7, 0.13, 0.12, 0.16, 0.11, 0.11,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>inlasin</td>\n",
       "      <td>[inihiwalay]</td>\n",
       "      <td>0.24</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[0.48]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ninaganna</td>\n",
       "      <td>[None, tinawag]</td>\n",
       "      <td>0.18</td>\n",
       "      <td>[20]</td>\n",
       "      <td>[0, 5]</td>\n",
       "      <td>[0.0, 1.21]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ninagananna</td>\n",
       "      <td>[None, tinawag, lupain]</td>\n",
       "      <td>0.17</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>[0.0, 0.18, 0.39]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>naadda</td>\n",
       "      <td>[None, nagkahapon, nagkagutom, nagbigay]</td>\n",
       "      <td>0.21</td>\n",
       "      <td>[10]</td>\n",
       "      <td>[0, 5, 1, 1]</td>\n",
       "      <td>[0.0, 1.87, 0.19, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>inaramidna</td>\n",
       "      <td>[None, nilikha, nito, ginawa, iginawad, pinana...</td>\n",
       "      <td>0.08</td>\n",
       "      <td>[201]</td>\n",
       "      <td>[0, 2, 1, 40, 1, 1, 15, 1, 3, 4, 1, 1, 1, 1, 1...</td>\n",
       "      <td>[0.0, 0.23, 0.1, 4.6, 0.18, 0.13, 1.74, 0.11, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>insinana</td>\n",
       "      <td>[inihiwalay, ito]</td>\n",
       "      <td>0.13</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[0.18, 0.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>naaramid a casta</td>\n",
       "      <td>[None, nagkagayon]</td>\n",
       "      <td>0.13</td>\n",
       "      <td>[7]</td>\n",
       "      <td>[0, 3]</td>\n",
       "      <td>[0.0, 0.52]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mapagtitipon</td>\n",
       "      <td>[mapisan]</td>\n",
       "      <td>0.16</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>agparang</td>\n",
       "      <td>[None, gaya, pakita, pakilala]</td>\n",
       "      <td>0.11</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[0, 1, 2, 1]</td>\n",
       "      <td>[0.0, 0.27, 0.23, 0.15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nacatiponan</td>\n",
       "      <td>[None]</td>\n",
       "      <td>0.21</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>patuboen</td>\n",
       "      <td>[sibulan]</td>\n",
       "      <td>0.13</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>agbunga</td>\n",
       "      <td>[None, magpalaanakin]</td>\n",
       "      <td>0.10</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.0, 0.09]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pinataud</td>\n",
       "      <td>[None]</td>\n",
       "      <td>0.13</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>addaan</td>\n",
       "      <td>[nagkakabinhi, None, buhay, hinga, kung, mahip...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>[104]</td>\n",
       "      <td>[1, 0, 1, 1, 2, 1, 1, 1, 10, 2, 1, 1, 1, 1, 1,...</td>\n",
       "      <td>[0.12, 0.0, 0.12, 0.24, 0.24, 0.12, 0.15, 0.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>casisigudda</td>\n",
       "      <td>[None]</td>\n",
       "      <td>0.11</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>aglasin</td>\n",
       "      <td>[None]</td>\n",
       "      <td>0.16</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>maipaayda</td>\n",
       "      <td>[None, pinakatanglaw]</td>\n",
       "      <td>0.30</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.0, 0.28]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>pagilaslasinan</td>\n",
       "      <td>[None]</td>\n",
       "      <td>0.14</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>panpanawen</td>\n",
       "      <td>[None]</td>\n",
       "      <td>0.14</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>aggundaway</td>\n",
       "      <td>[magpuno]</td>\n",
       "      <td>0.15</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[0.43]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>insaadna</td>\n",
       "      <td>[None, inilagay, humantong, isinapuso, ipinato...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>[40]</td>\n",
       "      <td>[0, 12, 1, 1, 3, 1, 6, 1]</td>\n",
       "      <td>[0.0, 1.48, 0.3, 0.19, 0.9, 0.12, 0.64, 0.53]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lawaganda</td>\n",
       "      <td>[tumanglaw]</td>\n",
       "      <td>0.28</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.28]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>agpangen</td>\n",
       "      <td>[bukalan]</td>\n",
       "      <td>0.18</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>agtayab</td>\n",
       "      <td>[None]</td>\n",
       "      <td>0.23</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>aggaraw</td>\n",
       "      <td>[None, nabubuhay, gumagalaw, napapabago]</td>\n",
       "      <td>0.19</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[0, 1, 1, 1]</td>\n",
       "      <td>[0.0, 0.21, 0.14, 0.71]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>binendicionanna</td>\n",
       "      <td>[None, binasbasan, pinagpala, mainam, pinagbab...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>[29]</td>\n",
       "      <td>[0, 9, 2, 1, 1]</td>\n",
       "      <td>[0.0, 1.05, 0.25, 0.11, 0.16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>agbungacayo</td>\n",
       "      <td>[magpalaanakin, None]</td>\n",
       "      <td>0.17</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[2, 0]</td>\n",
       "      <td>[0.42, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>agaducayo</td>\n",
       "      <td>[magpakarami, magpalaanakin, None]</td>\n",
       "      <td>0.18</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[2, 2, 0]</td>\n",
       "      <td>[0.42, 0.25, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>punnoenyo</td>\n",
       "      <td>[punuin, magpakarami]</td>\n",
       "      <td>0.14</td>\n",
       "      <td>[3]</td>\n",
       "      <td>[2, 1]</td>\n",
       "      <td>[0.34, 0.09]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>agaduda</td>\n",
       "      <td>[magpakarami]</td>\n",
       "      <td>0.18</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>patauden</td>\n",
       "      <td>[bukalan]</td>\n",
       "      <td>0.15</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0.11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>daga</td>\n",
       "      <td>[None, lupain, pagkamatay, tinamo, bayong, pat...</td>\n",
       "      <td>0.11</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[0.0, 0.24, 0.14, 0.25, 0.09, 0.1, 0.08, 0.1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>agcarcarayam</td>\n",
       "      <td>[None, karumaldumal, umuusad]</td>\n",
       "      <td>0.25</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>[0.0, 0.15, 0.71]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>agcacarungsot</td>\n",
       "      <td>[None]</td>\n",
       "      <td>0.15</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>cakikitada</td>\n",
       "      <td>[None]</td>\n",
       "      <td>0.12</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>aguy</td>\n",
       "      <td>[umuusad, None, gumagalaw]</td>\n",
       "      <td>0.12</td>\n",
       "      <td>[13]</td>\n",
       "      <td>[5, 0, 1]</td>\n",
       "      <td>[0.85, 0.0, 0.14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>uyas</td>\n",
       "      <td>[None, gumagalaw, umuusad]</td>\n",
       "      <td>0.12</td>\n",
       "      <td>[13]</td>\n",
       "      <td>[0, 1, 1]</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>aramidentayo</td>\n",
       "      <td>[lalangin, None, gawan]</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[1, 0, 1]</td>\n",
       "      <td>[0.09, 0.0, 0.08]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>iturayanda</td>\n",
       "      <td>[None]</td>\n",
       "      <td>0.09</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ican</td>\n",
       "      <td>[None, ibinibigay]</td>\n",
       "      <td>0.17</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>[0.0, 0.11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>agbalincayo</td>\n",
       "      <td>[None]</td>\n",
       "      <td>0.11</td>\n",
       "      <td>[2]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>appo</td>\n",
       "      <td>[None]</td>\n",
       "      <td>0.10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>iturayanyo</td>\n",
       "      <td>[None]</td>\n",
       "      <td>0.10</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Ilokano Verb                                       Tagalog Verb  \\\n",
       "0             aramid  [nilalang, gawa, None, paglilingkod, ginawa, p...   \n",
       "1         pinarsuana                                    [nilikha, None]   \n",
       "2               adda  [None, magkaroon, taglay, may, hininga, nagkar...   \n",
       "3             addada  [None, umapaw, dalawa, nangasa, nakakawala, ni...   \n",
       "4           kinunana  [None, sinabi, nagsabi, nasabi, narito, baka, ...   \n",
       "5            nagadda                                        [nagkaroon]   \n",
       "6           nakitana  [None, nakita, nakakita, naritot, sapagkat, ni...   \n",
       "7            inlasin                                       [inihiwalay]   \n",
       "8          ninaganna                                    [None, tinawag]   \n",
       "9        ninagananna                            [None, tinawag, lupain]   \n",
       "10            naadda           [None, nagkahapon, nagkagutom, nagbigay]   \n",
       "11        inaramidna  [None, nilikha, nito, ginawa, iginawad, pinana...   \n",
       "12          insinana                                  [inihiwalay, ito]   \n",
       "13  naaramid a casta                                 [None, nagkagayon]   \n",
       "14      mapagtitipon                                          [mapisan]   \n",
       "15          agparang                     [None, gaya, pakita, pakilala]   \n",
       "16       nacatiponan                                             [None]   \n",
       "17          patuboen                                          [sibulan]   \n",
       "18           agbunga                              [None, magpalaanakin]   \n",
       "19          pinataud                                             [None]   \n",
       "20            addaan  [nagkakabinhi, None, buhay, hinga, kung, mahip...   \n",
       "21       casisigudda                                             [None]   \n",
       "22           aglasin                                             [None]   \n",
       "23         maipaayda                              [None, pinakatanglaw]   \n",
       "24    pagilaslasinan                                             [None]   \n",
       "25        panpanawen                                             [None]   \n",
       "26        aggundaway                                          [magpuno]   \n",
       "27          insaadna  [None, inilagay, humantong, isinapuso, ipinato...   \n",
       "28         lawaganda                                        [tumanglaw]   \n",
       "29          agpangen                                          [bukalan]   \n",
       "30           agtayab                                             [None]   \n",
       "31           aggaraw           [None, nabubuhay, gumagalaw, napapabago]   \n",
       "32   binendicionanna  [None, binasbasan, pinagpala, mainam, pinagbab...   \n",
       "33       agbungacayo                              [magpalaanakin, None]   \n",
       "34         agaducayo                 [magpakarami, magpalaanakin, None]   \n",
       "35         punnoenyo                              [punuin, magpakarami]   \n",
       "36           agaduda                                      [magpakarami]   \n",
       "37          patauden                                          [bukalan]   \n",
       "38              daga  [None, lupain, pagkamatay, tinamo, bayong, pat...   \n",
       "39      agcarcarayam                      [None, karumaldumal, umuusad]   \n",
       "40     agcacarungsot                                             [None]   \n",
       "41        cakikitada                                             [None]   \n",
       "42              aguy                         [umuusad, None, gumagalaw]   \n",
       "43              uyas                         [None, gumagalaw, umuusad]   \n",
       "44      aramidentayo                            [lalangin, None, gawan]   \n",
       "45        iturayanda                                             [None]   \n",
       "46              ican                                 [None, ibinibigay]   \n",
       "47       agbalincayo                                             [None]   \n",
       "48              appo                                             [None]   \n",
       "49        iturayanyo                                             [None]   \n",
       "\n",
       "    Ilokano Verb TF-IDF Ilokano Verb Count  \\\n",
       "0                  0.14               [27]   \n",
       "1                  0.18                [7]   \n",
       "2                  0.05             [1389]   \n",
       "3                  0.08              [225]   \n",
       "4                  0.07             [1115]   \n",
       "5                  0.39                [1]   \n",
       "6                  0.10               [83]   \n",
       "7                  0.24                [2]   \n",
       "8                  0.18               [20]   \n",
       "9                  0.17                [6]   \n",
       "10                 0.21               [10]   \n",
       "11                 0.08              [201]   \n",
       "12                 0.13                [2]   \n",
       "13                 0.13                [7]   \n",
       "14                 0.16                [1]   \n",
       "15                 0.11                [9]   \n",
       "16                 0.21                [1]   \n",
       "17                 0.13                [1]   \n",
       "18                 0.10                [4]   \n",
       "19                 0.13                [1]   \n",
       "20                 0.10              [104]   \n",
       "21                 0.11                [4]   \n",
       "22                 0.16                [2]   \n",
       "23                 0.30                [3]   \n",
       "24                 0.14                [1]   \n",
       "25                 0.14                [1]   \n",
       "26                 0.15                [3]   \n",
       "27                 0.12               [40]   \n",
       "28                 0.28                [1]   \n",
       "29                 0.18                [1]   \n",
       "30                 0.23                [2]   \n",
       "31                 0.19                [9]   \n",
       "32                 0.12               [29]   \n",
       "33                 0.17                [4]   \n",
       "34                 0.18                [5]   \n",
       "35                 0.14                [3]   \n",
       "36                 0.18                [1]   \n",
       "37                 0.15                [1]   \n",
       "38                 0.11               [27]   \n",
       "39                 0.25                [8]   \n",
       "40                 0.15                [1]   \n",
       "41                 0.12                [1]   \n",
       "42                 0.12               [13]   \n",
       "43                 0.12               [13]   \n",
       "44                 0.09                [6]   \n",
       "45                 0.09                [1]   \n",
       "46                 0.17                [6]   \n",
       "47                 0.11                [2]   \n",
       "48                 0.10                [1]   \n",
       "49                 0.10                [1]   \n",
       "\n",
       "                                   Tagalog Verb Count  \\\n",
       "0                            [1, 4, 0, 1, 2, 1, 1, 1]   \n",
       "1                                              [1, 0]   \n",
       "2   [0, 9, 4, 13, 1, 33, 1, 1, 1, 1, 1, 11, 5, 1, ...   \n",
       "3   [0, 1, 1, 1, 1, 1, 2, 1, 1, 6, 3, 1, 1, 1, 2, ...   \n",
       "4   [0, 184, 59, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, ...   \n",
       "5                                                 [1]   \n",
       "6    [0, 8, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "7                                                 [2]   \n",
       "8                                              [0, 5]   \n",
       "9                                           [0, 1, 1]   \n",
       "10                                       [0, 5, 1, 1]   \n",
       "11  [0, 2, 1, 40, 1, 1, 15, 1, 3, 4, 1, 1, 1, 1, 1...   \n",
       "12                                             [1, 1]   \n",
       "13                                             [0, 3]   \n",
       "14                                                [1]   \n",
       "15                                       [0, 1, 2, 1]   \n",
       "16                                                [0]   \n",
       "17                                                [1]   \n",
       "18                                             [0, 1]   \n",
       "19                                                [0]   \n",
       "20  [1, 0, 1, 1, 2, 1, 1, 1, 10, 2, 1, 1, 1, 1, 1,...   \n",
       "21                                                [0]   \n",
       "22                                                [0]   \n",
       "23                                             [0, 1]   \n",
       "24                                                [0]   \n",
       "25                                                [0]   \n",
       "26                                                [3]   \n",
       "27                          [0, 12, 1, 1, 3, 1, 6, 1]   \n",
       "28                                                [1]   \n",
       "29                                                [1]   \n",
       "30                                                [0]   \n",
       "31                                       [0, 1, 1, 1]   \n",
       "32                                    [0, 9, 2, 1, 1]   \n",
       "33                                             [2, 0]   \n",
       "34                                          [2, 2, 0]   \n",
       "35                                             [2, 1]   \n",
       "36                                                [1]   \n",
       "37                                                [1]   \n",
       "38               [0, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]   \n",
       "39                                          [0, 1, 1]   \n",
       "40                                                [0]   \n",
       "41                                                [0]   \n",
       "42                                          [5, 0, 1]   \n",
       "43                                          [0, 1, 1]   \n",
       "44                                          [1, 0, 1]   \n",
       "45                                                [0]   \n",
       "46                                             [0, 1]   \n",
       "47                                                [0]   \n",
       "48                                                [0]   \n",
       "49                                                [0]   \n",
       "\n",
       "                                  Tagalog Verb TF-IDF  \n",
       "0       [0.85, 0.95, 0.0, 0.13, 0.46, 0.0, 0.0, 0.08]  \n",
       "1                                         [0.39, 0.0]  \n",
       "2   [0.0, 1.5, 0.77, 2.14, 0.12, 4.43, 0.18, 0.21,...  \n",
       "3   [0.0, 0.24, 0.08, 0.22, 0.17, 0.18, 0.25, 0.15...  \n",
       "4   [0.0, 16.37, 5.64, 0.2, 0.13, 0.1, 0.49, 0.15,...  \n",
       "5                                              [0.39]  \n",
       "6   [0.0, 0.98, 0.7, 0.13, 0.12, 0.16, 0.11, 0.11,...  \n",
       "7                                              [0.48]  \n",
       "8                                         [0.0, 1.21]  \n",
       "9                                   [0.0, 0.18, 0.39]  \n",
       "10                             [0.0, 1.87, 0.19, 0.0]  \n",
       "11  [0.0, 0.23, 0.1, 4.6, 0.18, 0.13, 1.74, 0.11, ...  \n",
       "12                                        [0.18, 0.1]  \n",
       "13                                        [0.0, 0.52]  \n",
       "14                                              [0.2]  \n",
       "15                            [0.0, 0.27, 0.23, 0.15]  \n",
       "16                                              [0.0]  \n",
       "17                                             [0.13]  \n",
       "18                                        [0.0, 0.09]  \n",
       "19                                              [0.0]  \n",
       "20  [0.12, 0.0, 0.12, 0.24, 0.24, 0.12, 0.15, 0.12...  \n",
       "21                                              [0.0]  \n",
       "22                                              [0.0]  \n",
       "23                                        [0.0, 0.28]  \n",
       "24                                              [0.0]  \n",
       "25                                              [0.0]  \n",
       "26                                             [0.43]  \n",
       "27      [0.0, 1.48, 0.3, 0.19, 0.9, 0.12, 0.64, 0.53]  \n",
       "28                                             [0.28]  \n",
       "29                                             [0.13]  \n",
       "30                                              [0.0]  \n",
       "31                            [0.0, 0.21, 0.14, 0.71]  \n",
       "32                      [0.0, 1.05, 0.25, 0.11, 0.16]  \n",
       "33                                        [0.42, 0.0]  \n",
       "34                                  [0.42, 0.25, 0.0]  \n",
       "35                                       [0.34, 0.09]  \n",
       "36                                              [0.0]  \n",
       "37                                             [0.11]  \n",
       "38  [0.0, 0.24, 0.14, 0.25, 0.09, 0.1, 0.08, 0.1, ...  \n",
       "39                                  [0.0, 0.15, 0.71]  \n",
       "40                                              [0.0]  \n",
       "41                                              [0.0]  \n",
       "42                                  [0.85, 0.0, 0.14]  \n",
       "43                                    [0.0, 0.0, 0.0]  \n",
       "44                                  [0.09, 0.0, 0.08]  \n",
       "45                                              [0.0]  \n",
       "46                                        [0.0, 0.11]  \n",
       "47                                              [0.0]  \n",
       "48                                              [0.0]  \n",
       "49                                              [0.0]  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dict_il_tl_sw.head()\n",
    "dict_il_tl_vb.head(50)\n",
    "# dict_il_tl_nn.head(50)\n",
    "#dict_il_tl_jj.head(50)\n",
    "# dict_il_tl_rb.head(50)\n",
    "#dict_il_tl_cc.head(50)\n",
    "# dict_il_tl_pr.head(50)\n",
    "#dict_il_tl_dt.head(50)\n",
    "\n",
    "# temp_dict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the dictionary in the json file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Single Word Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved the dict_sw.json file\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "dict_sw = dict_il_tl_sw.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_sw.json\", \"w\") as outfile:\n",
    "        json.dump(dict_sw, outfile)\n",
    "    print(\"successfully saved the dict_sw.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_sw.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Verb Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved the dict_vb.json file\n"
     ]
    }
   ],
   "source": [
    "dict_vb = dict_il_tl_vb.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_vb.json\", \"w\") as outfile:\n",
    "        json.dump(dict_vb, outfile)\n",
    "    print(\"successfully saved the dict_vb.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_vb.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Noun Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved the dict_nn.json file\n"
     ]
    }
   ],
   "source": [
    "dict_nn = dict_il_tl_nn.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_nn.json\", \"w\") as outfile:\n",
    "        json.dump(dict_nn, outfile)\n",
    "    print(\"successfully saved the dict_nn.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_nn.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Adjective Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved the dict_jj.json file\n"
     ]
    }
   ],
   "source": [
    "dict_jj = dict_il_tl_jj.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_jj.json\", \"w\") as outfile:\n",
    "        json.dump(dict_jj, outfile)\n",
    "    print(\"successfully saved the dict_jj.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_jj.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Adverb Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved the dict_rb.json file\n"
     ]
    }
   ],
   "source": [
    "dict_rb = dict_il_tl_rb.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_rb.json\", \"w\") as outfile:\n",
    "        json.dump(dict_rb, outfile)\n",
    "    print(\"successfully saved the dict_rb.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_rb.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Conjunction Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved the dict_cc.json file\n"
     ]
    }
   ],
   "source": [
    "dict_cc = dict_il_tl_cc.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_cc.json\", \"w\") as outfile:\n",
    "        json.dump(dict_cc, outfile)\n",
    "    print(\"successfully saved the dict_cc.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_cc.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Preposition Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved the dict_pr.json file\n"
     ]
    }
   ],
   "source": [
    "dict_pr = dict_il_tl_pr.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_pr.json\", \"w\") as outfile:\n",
    "        json.dump(dict_pr, outfile)\n",
    "    print(\"successfully saved the dict_pr.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_pr.json file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Determiner Dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully saved the dict_dt.json file\n"
     ]
    }
   ],
   "source": [
    "dict_dt = dict_il_tl_dt.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_dt.json\", \"w\") as outfile:\n",
    "        json.dump(dict_dt, outfile)\n",
    "    print(\"successfully saved the dict_dt.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_dt.json file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2]]\n"
     ]
    }
   ],
   "source": [
    "temp_sen_list = []\n",
    "\n",
    "temp_sen_list.append([1])\n",
    "# temp_sen_list[0].append(1)\n",
    "temp_sen_list[0][0] += 1\n",
    "print(temp_sen_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "temp_arr = ''\n",
    "\n",
    "print(len(temp_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd5e40cb983109c15fc1053f6f3e661cc97e68e07c1758cdbd2441c60186ce19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
