{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ilokano to Tagalog Standard Translator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INITIALIZATION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opening and Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Opening the file\n",
    "test_doc = open(\"../../src/text data/testing/il_test_data_bible.txt\", encoding='utf-8').read()\n",
    "target_op = open(\"../../src/text data/testing/tl_test_data_bible.txt\", encoding='utf-8').read()\n",
    "\n",
    "# Splitting the raw data into sentences\n",
    "parsed_test_doc = test_doc.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punct(pText):\n",
    "    text_nopunct = \"\".join([char for char in pText if char not in string.punctuation])\n",
    "    return text_nopunct\n",
    "\n",
    "cleaned_test_doc = [remove_punct(word) for word in parsed_test_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = re.split('\\W+', text.lower())\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token == '':\n",
    "            tokens.remove(token)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "tokenized_test_doc = [tokenize(word) for word in cleaned_test_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_test_doc = pd.DataFrame({'Tokenized': tokenized_test_doc})  \n",
    "dict_test_doc.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lists and Fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Determiner Lists\n",
    "\"\"\"\n",
    "noun_dtmn_list = [\"dagiti\", \"ti\", \"cadagiti\", \"kadagiti\", \"ni\", \"ken\", \"ni\", \"coma\", \"koma\", \"a\", \"iti\"]\n",
    "\n",
    "adv_dtmn_list = [\"idi\", \"iti\"]\n",
    "\n",
    "prepo_dtmn_list = [\"ti\", \"addaak\", \"iti\"]\n",
    "\n",
    "adv_time_list = ['madamdama', 'ita', 'kalman', 'inton bigat', 'ditoy', 'idiay', 'ita a rabii', 'iti kaaldawantayo', 'idi rabii', 'sumaruno a lawas', 'nga', 'nabiit pay', 'nasapa', 'dagus', 'pay laeng', 'pay', 'napalabas']\n",
    "\n",
    "adv_place_list = ['ditoy', 'sadiay', 'iti labesna', 'iti sadinoman a lugar', 'sadinoman', 'balay', 'pabuya']\n",
    "\n",
    "adv_manner_list = ['naan-anay', 'medio', 'napartak', 'narigat', 'napartak', 'sibabannayat', 'kasla saan', 'dandani amin', 'dandani', 'awan pagpambarna', 'sangsangkamaysa', 'agmaymaysa']\n",
    "\n",
    "adv_freq_list = ['masansan', 'kadawyan', 'maminsan', 'sagpaminsan', 'manmanon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX_SET = [\n",
    "'na', 'ag', 'ka', 'ca', 'nag', 'im', 'maipa',\n",
    "'maki', 'panna', 'maka', 'naki', 'naka', 'nang', \n",
    "'makapag','mang', 'agan', 'agay', 'pananga', 'agam', \n",
    "'nagpa', 'magpa', 'ipa', 'pag', 'pam', 'taga', 'i', \n",
    "'napa', 'in', 'manang','ma', 'para', 'pang', 'panag', \n",
    "'nai', 'manag', 'man', 'kina', 'nai', 'nai', 'nagpa', 'mapag'\n",
    "]\n",
    "\n",
    "ADJ_PREFIX =[\n",
    "'ka', 'na'\n",
    "]\n",
    "\n",
    "INFIX_SET = ['in']\n",
    "\n",
    "SUFFIX_SET = [\n",
    "'to', 'nto', 'ak' 'en'\n",
    "'na', 'an', 'm', 'nyo', \n",
    "'cayo', 'tayo', 'anda',\n",
    "]\n",
    "\n",
    "ADJ_SUFFIX = [\n",
    "'an'\n",
    "]\n",
    "\n",
    "PREPO_SET = [\n",
    "    'tengnga', 'rabaw', 'rabao', 'baba', 'babaen', \n",
    "    'ngatuen', 'ngato', 'sirok', 'sidong', 'sango', \n",
    "    'sarang', 'saklang', 'sanguanan', 'likud', 'ruar', \n",
    "    'uneg', 'baet', 'sango', 'umuna', 'ngudo', 'ungto', \n",
    "    'abay', 'igid'\n",
    "]\n",
    "\n",
    "CONJ_SET = [\n",
    "    'ken', 'ket', 'gapu', 'ta', 'agsipud', 'laeng', \n",
    "    'ngem', 'nupay kasta', 'bayat', 'uray', 'intono', \n",
    "    'no', 'ta', 'ngamin', 'kaso', 'gapuna', 'ngem', 'idi',\n",
    "    'nga', 'ni',  'wenno', 'para', 'tapno', 'agraman', 'numpay kasta', \n",
    "    'ken', 'ket', 'kabayatanna', 'bayat', 'kada', 'cas'\n",
    "]\n",
    "\n",
    "PER_PRONOUN = [\n",
    "    'siak', 'sika', 'isu', 'dakami', 'datayo', 'dakayo', \n",
    "    'kayo', 'da', 'caycayo', 'kaykayo', 'dinak', 'diak', \n",
    "    'kaniak', 'kadakami', 'kami','kadakayo', 'dakayo', 'kayo',\n",
    "    'ida', 'da','ko', 'kukuami', 'kadatayo', 'kukuatayo', 'tayo', \n",
    "    'kata', 'mo', 'cadacuada', 'kenkuana', 'kencuana','mi','yo', \n",
    "    'nyo', 'na'\n",
    "]\n",
    "\n",
    "VOWELS = ['a', 'e', 'i', 'o', 'u']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Determiner Checker Function\n",
    "\"\"\"\n",
    "def isDtmn(word):\n",
    "    \"\"\"\n",
    "    This function checks if the specific word in the sentence is a determiner, and extracts it.\n",
    "    \"\"\"\n",
    "    if word in (noun_dtmn_list + adv_dtmn_list + prepo_dtmn_list + adv_time_list):\n",
    "        ans = True\n",
    "    else:\n",
    "        ans = False\n",
    "\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Verb Affixer Checker Function\n",
    "\"\"\"\n",
    "def check_verb_affixes(word, prev_word, isTagged, hasVerbAffixes):\n",
    "    for prefix in PREFIX_SET:\n",
    "        if word.startswith(prefix) and not isTagged:\n",
    "            hasVerbAffixes = True\n",
    "            isTagged = True\n",
    "            \n",
    "    for infix in INFIX_SET:\n",
    "        if word.__contains__(infix) and not isTagged:\n",
    "            hasVerbAffixes = True\n",
    "            isTagged = True\n",
    "    \n",
    "    for suffix in SUFFIX_SET:\n",
    "        if word.endswith(suffix) and not isTagged:\n",
    "            hasVerbAffixes = True\n",
    "            isTagged = True\n",
    "    \n",
    "    return hasVerbAffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Verb Checker Function\n",
    "\"\"\"\n",
    "def isVerb(word, prev_word, prev2_word, next_word, next2_word, hasVerbAffixes):\n",
    "    isDone = False\n",
    "    isVerb = False\n",
    "    \n",
    "    if word not in PREPO_SET:    \n",
    "        if word == 'espiritu' and not isDone:\n",
    "            isVerb = False\n",
    "            isDone = True\n",
    "           \n",
    "        if word == 'naimbag' and not isDone:\n",
    "            if next_word == 'iti':\n",
    "                isVerb = False\n",
    "                isDone = True\n",
    "            \n",
    "        if word == 'amin' and not isDone:\n",
    "            isVerb = False\n",
    "            isDone = True\n",
    "        \n",
    "        if (word.find(\"adda\") != -1) and not isDone:\n",
    "            isVerb = True\n",
    "            isDone = True\n",
    "            \n",
    "        if word == 'nagtignay' and not isDone:\n",
    "            if next_word == 'iti':\n",
    "                isVerb = False\n",
    "                isDone = True\n",
    "    \n",
    "        if word == 'ninagananna' and not isDone:\n",
    "            can2Viterbi = True\n",
    "            isVerb = True\n",
    "            isDone = True\n",
    "        \n",
    "        if word == 'naaramid a casta' and not isDone:\n",
    "            isVerb = True\n",
    "            isDone = True\n",
    "    \n",
    "        if word not in (PREPO_SET + PER_PRONOUN + CONJ_SET) and not isDone:\n",
    "            if prev_word not in (noun_dtmn_list + adv_dtmn_list + prepo_dtmn_list):\n",
    "                if next_word in (noun_dtmn_list): \n",
    "                    if hasVerbAffixes:\n",
    "                        isVerb = True\n",
    "                        isDone = True\n",
    "            \n",
    "                if next_word in PER_PRONOUN and not isDone:\n",
    "                    isVerb = True\n",
    "                    isDone = True                \n",
    "        \n",
    "            if word.startswith('pa') and (word.endswith('en') or word.endswith('in')):\n",
    "                isVerb = True\n",
    "                isDone = True                \n",
    "        \n",
    "            if word.startswith('ag') and prev_word == 'nga' and next_word in ('nga', 'a'):\n",
    "                isVerb = True\n",
    "                isDone = True                \n",
    "        \n",
    "            if word.startswith('ag') and (word.endswith('kayo') or word.endswith('cayo')):\n",
    "                isVerb = True\n",
    "                isDone = True\n",
    "\n",
    "            if prev_word == 'ti' and next_word in (noun_dtmn_list) and (not next_word in ('a','iti', 'ken')) and not isDone:\n",
    "                if word == 'aramid' and next_word == 'ti':\n",
    "                    isVerb = True\n",
    "                    isDone = True\n",
    "\n",
    "                elif next_word != 'ti':\n",
    "                    isVerb = True\n",
    "                    isDone = True\n",
    "            \n",
    "            if prev_word in CONJ_SET and hasVerbAffixes and next_word in noun_dtmn_list and not isDone:\n",
    "                isVerb = True\n",
    "                isDone = True\n",
    "\n",
    "            if word.startswith(\"ag\") and word[2:5] == word[5:8] and not isDone:\n",
    "                isVerb = True\n",
    "                isDone = True\n",
    "\n",
    "            if prev_word == 'nga' and next_word =='a':\n",
    "                isVerb = True\n",
    "                isDone = True\n",
    "\n",
    "            if word == 'aguy' and next_word == 'uyas':\n",
    "                isVerb = True\n",
    "                isDone = True\n",
    "\n",
    "            if prev_word == 'aguy' and word == 'uyas':\n",
    "                isVerb = True\n",
    "                isDone = True\n",
    "\n",
    "            if prev_word == 'iti' and next_word == 'ken' and word.endswith('da') and hasVerbAffixes:\n",
    "                isVerb = True\n",
    "                isDone = True\n",
    "\n",
    "            if prev2_word == 'ti' and not isDone:\n",
    "                if next_word in (noun_dtmn_list) and not next_word == 'a':\n",
    "                    isVerb = True\n",
    "                    isDone = True\n",
    "                \n",
    "                if hasVerbAffixes and not isDone:\n",
    "                    isVerb = True\n",
    "                    isDone = True\n",
    "        \n",
    "        if hasVerbAffixes and prev_word == None and not isDone:\n",
    "            isVerb = True\n",
    "            isDone = True\n",
    "    \n",
    "    return isVerb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Noun Checker Function\n",
    "\"\"\"\n",
    "def isNoun(word, prev_word, prev2_word, next_word, next2_word, hasVerbAffixes):\n",
    "    isDone = False\n",
    "    isNoun = False\n",
    "    \n",
    "    if word in PER_PRONOUN and word not in PREPO_SET:\n",
    "        isNoun = True\n",
    "        isDone = True\n",
    "\n",
    "    if word and not isDone:\n",
    "        if prev_word in (noun_dtmn_list) and word not in (PREPO_SET + CONJ_SET + noun_dtmn_list) and not isDone:\n",
    "            isNoun = True\n",
    "            \n",
    "            if not word.startswith(\"maica\") and not isDone:\n",
    "                isNoun = True\n",
    "                isDone = True\n",
    "                \n",
    "            elif word.startswith(\"maica\"):\n",
    "                isNoun = False\n",
    "                isDone = True\n",
    "\n",
    "            if next2_word.startswith(\"maica\") and next_word == \"a\" and not isDone:\n",
    "                isNoun = True\n",
    "                isDone = True\n",
    "\n",
    "            if word[:2] == word[2:4]:\n",
    "                if prev_word in (noun_dtmn_list) and next_word not in (\"ti\", \"nga\", \"a\"):\n",
    "                    isNoun = True\n",
    "                    isDone = True\n",
    "                else:\n",
    "                    isNoun = False\n",
    "                    isDone = False\n",
    "            \n",
    "            if word[:3] == word[3:6]:\n",
    "                if prev_word in (noun_dtmn_list) and next_word not in (noun_dtmn_list):\n",
    "                    isNoun = False\n",
    "\n",
    "                elif prev_word in (noun_dtmn_list) and next_word == None:\n",
    "                    isNoun = True\n",
    "\n",
    "            isDone = True\n",
    "\n",
    "        if prev_word == 'idi' and  not hasVerbAffixes and not isDone:\n",
    "            isNoun = True\n",
    "            isDone = True           \n",
    "        \n",
    "        if (word.startswith('ka') or word.startswith('ca')) and word.endswith('tayo'):\n",
    "            isNoun = True\n",
    "            isDone = True \n",
    "\n",
    "        if next_word in CONJ_SET and not hasVerbAffixes and not isDone:\n",
    "            isNoun = True\n",
    "            isDone = True\n",
    "        \n",
    "        if prev_word in noun_dtmn_list and (next_word.find(\"adda\") != -1):\n",
    "            isNoun = True\n",
    "            isDone = True\n",
    "        \n",
    "        if next_word =='a' and prev2_word == 'nga':\n",
    "            isNoun = True\n",
    "            isDone = True\n",
    "\n",
    "        if prev_word == word[:2]:\n",
    "            isNoun = True\n",
    "            isDone = True\n",
    "\n",
    "        if prev_word == 'nga' and next_word == 'ti':\n",
    "            isNoun = True\n",
    "            isDone = True\n",
    "\n",
    "        if prev2_word in noun_dtmn_list and not isDone:\n",
    "            isNoun = True\n",
    "            isDone = True\n",
    "\n",
    "        if word.endswith('um') or word.endswith('en'):\n",
    "            isNoun = True\n",
    "            isDone = True\n",
    "\n",
    "        if word in PER_PRONOUN:\n",
    "            isNoun = True\n",
    "            isDone = True\n",
    "    return isNoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Adjective Checker Function\n",
    "\"\"\"\n",
    "def isAdj(word, prev_word, prev2_word, next_word, hasVerbAffixes):\n",
    "    isDone = False\n",
    "    isAdj = False\n",
    "        \n",
    "    if word not in (noun_dtmn_list + adv_dtmn_list + prepo_dtmn_list + PREPO_SET + PER_PRONOUN + CONJ_SET):\n",
    "            \n",
    "        if word.startswith(\"na\") and (next_word in noun_dtmn_list or next_word == 'a' or prev_word == 'ti') and  not hasVerbAffixes and not isDone:\n",
    "            isAdj = True\n",
    "            isDone = True\n",
    "\n",
    "        if word.startswith(\"na\") and word[:3] != 'nag' and prev2_word in noun_dtmn_list and (next_word in noun_dtmn_list or next_word == 'ket') and not isDone:\n",
    "            isAdj = True\n",
    "            isDone = True\n",
    "\n",
    "        if word.startswith(\"na\") and not word.startswith(\"nag\") and (prev_word in (\"ti\", \"nga\", \"a\")) and (word.find(\"biag\") == -1) and not word.endswith('sua') and not isDone:\n",
    "            isAdj = True\n",
    "            isDone = True \n",
    "\n",
    "        if word.startswith(\"ka\") and word.endswith(\"an\") and not isDone:\n",
    "            isAdj = True\n",
    "            isDone = True \n",
    "    \n",
    "        if (word.find(\"una\") != -1) and (next_word == 'a' or next_word == 'nga') and  not hasVerbAffixes and not isDone:\n",
    "            isAdj = True\n",
    "            isDone = True\n",
    "\n",
    "        if word == 'awan' and next_word in noun_dtmn_list and not isDone:\n",
    "            isAdj = True\n",
    "            isDone = True\n",
    "        \n",
    "        if word == 'awan' and prev_word in noun_dtmn_list and not isDone:\n",
    "            isAdj = True\n",
    "            isDone = True\n",
    "\n",
    "        if word == 'amin' and prev_word in PER_PRONOUN:\n",
    "            isAdj = True\n",
    "            isDone = True\n",
    "    \n",
    "        if word == 'maysa' and (next_word == 'a' or next_word == 'nga') and  not hasVerbAffixes and not isDone:\n",
    "            isAdj = True\n",
    "            isDone = True \n",
    "\n",
    "        if word.startswith(\"maika\") or word.startswith(\"maica\"):\n",
    "            isAdj = True\n",
    "            isDone = True \n",
    "\n",
    "        if word[:3] == word[3:6] and not word.endswith('aw') and (next_word in noun_dtmn_list or prev_word == 'a') and  not hasVerbAffixes and not isDone:\n",
    "            isAdj = True\n",
    "            isDone = True \n",
    "\n",
    "        if word[:2] == word[2:4] and (next_word in noun_dtmn_list or prev_word in ('a', 'dagiti')) and not hasVerbAffixes and not isDone:\n",
    "            if word =='lalaki' or word == 'babai':\n",
    "                isAdj = False\n",
    "                isNoun = True \n",
    "                isDone= False\n",
    "            else:\n",
    "                isAdj = True\n",
    "                isDone = True\n",
    "\n",
    "        if word.startswith(\"na\") and word[2:5] == word[5:8] and not isDone:\n",
    "            isAdj = True\n",
    "            isDone = True\n",
    "        \n",
    "        if word.startswith(\"na\") and word[2:6] == word[6:10] and not isDone:\n",
    "            isAdj = True\n",
    "            isDone = True\n",
    "\n",
    "    return isAdj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Adverb Checker Function\n",
    "\"\"\"\n",
    "def isAdv(word, prev_word, next_word, next2_word, hasVerbAffixes):\n",
    "   isDone = False\n",
    "   isAdv = False\n",
    "   \n",
    "   if word not in PER_PRONOUN and word not in PREPO_SET:\n",
    "      if word.startswith('idi') or word.startswith('di') and not prev_word == 'nga' and not isDone:\n",
    "         isAdv = True\n",
    "         isDone = True\n",
    "           \n",
    "      if word in adv_time_list and not isDone:\n",
    "         isAdv = True\n",
    "         isDone = True\n",
    "         \n",
    "      if word in adv_manner_list and not isDone:\n",
    "         isAdv = True\n",
    "         isDone = True\n",
    "         \n",
    "      if word in adv_freq_list and not isDone:\n",
    "         isAdv = True\n",
    "         isDone = True\n",
    "         \n",
    "      if word in adv_place_list and not isDone:\n",
    "         isAdv = True\n",
    "         isDone = True\n",
    "         \n",
    "      if prev_word in adv_dtmn_list and not isVerb and not isNoun and not isDone:\n",
    "         isAdv = True\n",
    "         isDone = True\n",
    "            \n",
    "      if next_word =='nga' or next_word == 'a' and word.startswith(\"na\") and not isDone: \n",
    "         isAdv = True\n",
    "         isDone = True \n",
    "         \n",
    "      if word.startswith('na') and not next_word in noun_dtmn_list and not isDone:\n",
    "         isAdv = True\n",
    "         isDone = True\n",
    "         \n",
    "      if word == \"awan\" and not next_word in noun_dtmn_list or isNoun and not isDone:\n",
    "         isAdv = True\n",
    "         isDone = True\n",
    "                  \n",
    "   return isAdv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Preposition Checker Function\n",
    "\"\"\"\n",
    "def isPrepo(word, prev_word):\n",
    "    isPrepo = False\n",
    "    isDone = False\n",
    "    prev_word = \"\"\n",
    "    \n",
    "    if prev_word in (prepo_dtmn_list) and word in (PREPO_SET) and not isDone:\n",
    "        isPrepo = True\n",
    "        isDone = True\n",
    "        \n",
    "    if word not in (PREPO_SET) and not isDone:\n",
    "        isPrepo = True\n",
    "        isDone = True\n",
    "        \n",
    "    if word in (PREPO_SET) and not isDone:\n",
    "        isPrepo = True\n",
    "        isDone = True\n",
    "    if (word.find(\"ruar\") != -1):\n",
    "        isPrepo = True\n",
    "        isDone = True\n",
    "\n",
    "    return isPrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Conjunction Checker Function\n",
    "\"\"\"\n",
    "\n",
    "def isConj(word):\n",
    "    if word in CONJ_SET:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSLATION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "    Ilokano to Tagalog Dictionaries\n",
    "\"\"\"\n",
    "\n",
    "dict_sw = pd.read_json('../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_sw.json')\n",
    "dict_vb = pd.read_json('../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_vb.json')\n",
    "dict_nn = pd.read_json('../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_nn.json')\n",
    "dict_jj = pd.read_json('../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_jj.json')\n",
    "dict_rb = pd.read_json('../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_rb.json')\n",
    "dict_cc = pd.read_json('../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_cc.json')\n",
    "dict_pr = pd.read_json('../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_pr.json')\n",
    "dict_dt = pd.read_json('../../src/json data/Ilokano to Tagalog/Example-Based/dict_il_dt.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Putting the columns in a list\n",
    "\"\"\"\n",
    "sw_il_list = dict_sw['Ilokano Single Words'].tolist()\n",
    "sw_tl_list = dict_sw['Tagalog Single Words'].tolist()\n",
    "vb_il_list = dict_vb['Ilokano Verb'].tolist()\n",
    "vb_tl_list = dict_vb['Tagalog Verb'].tolist()\n",
    "nn_il_list = dict_nn['Ilokano Noun'].tolist()\n",
    "nn_tl_list = dict_nn['Tagalog Noun'].tolist()\n",
    "jj_il_list = dict_jj['Ilokano Adjective'].tolist()\n",
    "jj_tl_list = dict_jj['Tagalog Adjective'].tolist()\n",
    "rb_il_list = dict_rb['Ilokano Adverb'].tolist()\n",
    "rb_tl_list = dict_rb['Tagalog Adverb'].tolist()\n",
    "cc_il_list = dict_cc['Ilokano Conjunction'].tolist()\n",
    "cc_tl_list = dict_cc['Tagalog Conjunction'].tolist()\n",
    "pr_il_list = dict_pr['Ilokano Preposition'].tolist()\n",
    "pr_tl_list = dict_pr['Tagalog Preposition'].tolist()\n",
    "dt_il_list = dict_dt['Ilokano Determiner'].tolist()\n",
    "dt_tl_list = dict_dt['Tagalog Determiner'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(sentence_list):\n",
    "    isTagged = None\n",
    "    hasVerbAffixes = None\n",
    "    pos_sen_list = []\n",
    "\n",
    "    for sentence in sentence_list:\n",
    "        pos_list = []\n",
    "        prev_word = \"\"\n",
    "        prev2_word = \"\"\n",
    "        sen_len = len(sentence)\n",
    "        \n",
    "        for word in sentence:\n",
    "            \n",
    "            isTagged = False\n",
    "            hasVerbAffixes = False\n",
    "    \n",
    "            try:\n",
    "                next_word = sentence[sentence.index(word) + 1]\n",
    "            except (ValueError, IndexError):\n",
    "                next_word = \"\"\n",
    "           \n",
    "            try:\n",
    "                next2_word = sentence[sentence.index(word) + 2]\n",
    "            except (ValueError, IndexError):\n",
    "                next2_word = \"\"\n",
    "            \n",
    "            try:\n",
    "                hasVerbAffixes = check_verb_affixes(word, prev_word, isTagged, hasVerbAffixes)\n",
    "            except (ValueError, IndexError):\n",
    "                hasVerbAffixes = False\n",
    "            \n",
    "            if sen_len == 1:\n",
    "                pos_list.append('SW')\n",
    "                isTagged = True\n",
    "            \n",
    "            elif isDtmn(word) and not isTagged:\n",
    "                pos_list.append('DT')\n",
    "                isTagged = True\n",
    "                \n",
    "            elif isConj(word) and not isTagged:\n",
    "                pos_list.append('CC')\n",
    "                isTagged = True\n",
    "            \n",
    "            elif isVerb(word, prev_word, prev2_word, next_word, next2_word, hasVerbAffixes) and not isTagged:\n",
    "                pos_list.append('VB')\n",
    "                isTagged = True\n",
    "\n",
    "            elif isAdj(word, prev_word, prev2_word, next_word, hasVerbAffixes) and not isTagged:\n",
    "                pos_list.append('JJ')\n",
    "                isTagged = True\n",
    "\n",
    "            elif isNoun(word, prev_word, prev2_word, next_word, next2_word, hasVerbAffixes) and not isTagged:\n",
    "                pos_list.append('NN')\n",
    "                isTagged = True\n",
    "\n",
    "            elif isAdv(word, prev_word, next_word, next2_word, hasVerbAffixes) and not isTagged:\n",
    "                pos_list.append('RB')\n",
    "                isTagged = True\n",
    "            \n",
    "            elif isPrepo(word, prev_word) and not isTagged:\n",
    "                pos_list.append('PR')\n",
    "                isTagged = True\n",
    "                \n",
    "            else:\n",
    "                pos_list.append('UNK')\n",
    "                isTagged = True\n",
    "            \n",
    "            prev_word = word\n",
    "           \n",
    "            try:\n",
    "                prev2_word = sentence[sentence.index(word) - 1]\n",
    "            except (ValueError, IndexError):\n",
    "                prev2_word = None\n",
    "           \n",
    "        pos_sen_list.append(pos_list)\n",
    "        \n",
    "    dict_test_doc['POS'] = pos_sen_list\n",
    "\n",
    "tag(dict_test_doc['Tokenized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_test_doc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Token Combiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_tokens(sen_translation_list):\n",
    "    temp_sen_list = []\n",
    "\n",
    "    for sen_translation in sen_translation_list:\n",
    "        temp_sen = ''\n",
    "        for word_translation in sen_translation:\n",
    "            temp_index = sen_translation.index(word_translation)\n",
    "            if temp_index == len(sen_translation) - 1:\n",
    "                temp_sen += word_translation\n",
    "            else:\n",
    "                temp_sen += word_translation + ' '\n",
    "        temp_sen_list.append(temp_sen)\n",
    "    \n",
    "    return temp_sen_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_phrases = pd.read_csv('../../src/csv data/f_phrases.csv')\n",
    "il_phrases = f_phrases['Ilokano'].to_list()\n",
    "il_phrases = [remove_punct(word) for word in il_phrases]\n",
    "il_phrases = [tokenize(word) for word in il_phrases]\n",
    "\n",
    "tl_phrases = f_phrases['Tagalog'].to_list()\n",
    "tl_phrases = [remove_punct(word) for word in tl_phrases]\n",
    "tl_phrases = [tokenize(word) for word in tl_phrases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inFPhrases(word, word2, word3, word4, word5, word6, word7, il_phrases):\n",
    "    inFPhrases = False\n",
    "    il_phrase = []\n",
    "    w_used = 0\n",
    "    for phrase in il_phrases:\n",
    "        length = len(phrase)\n",
    "        if length == 7:\n",
    "            if word == phrase[0] and word2 == phrase[1] and word3 == phrase[2] and word4 == phrase[3] and word5 == phrase[4] and word6 == phrase[5] and word7 == phrase[6]:\n",
    "                inFPhrases = True\n",
    "                tl_phrase = phrase\n",
    "                w_used = 7\n",
    "                break        \n",
    "        if length == 6:\n",
    "            if word == phrase[0] and word2 == phrase[1] and word3 == phrase[2] and word4 == phrase[3] and word5 == phrase[4] and word6 == phrase[5]:\n",
    "                inFPhrases = True\n",
    "                tl_phrase = phrase\n",
    "                w_used = 6\n",
    "                break\n",
    "        if length == 5:\n",
    "            if word == phrase[0] and word2 == phrase[1] and word3 == phrase[2] and word4 == phrase[3] and word5 == phrase[4]:\n",
    "                inFPhrases = True\n",
    "                tl_phrase = phrase\n",
    "                w_used = 5\n",
    "                break\n",
    "        if length == 4:\n",
    "            if word == phrase[0] and word2 == phrase[1] and word3 == phrase[2] and word4 == phrase[3]:\n",
    "                inFPhrases = True\n",
    "                tl_phrase = phrase\n",
    "                w_used = 4\n",
    "                break\n",
    "        if length == 3:\n",
    "            if word == phrase[0] and word2 == phrase[1] and word3 == phrase[2]:\n",
    "                inFPhrases = True\n",
    "                il_phrase = phrase\n",
    "                w_used = 3\n",
    "                break\n",
    "        if length == 2:\n",
    "            if word == phrase[0] and word2 == phrase[1]:\n",
    "                inFPhrases = True\n",
    "                il_phrase = phrase\n",
    "                w_used = 2\n",
    "                break\n",
    "        if length == 1:\n",
    "            if word == phrase[0]:\n",
    "                inFPhrases = True\n",
    "                il_phrase = phrase\n",
    "                w_used = 1\n",
    "                break\n",
    "                \n",
    "    return inFPhrases, il_phrase, w_used"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sen_poss_list):\n",
    "    sp_index = 0\n",
    "    sen_translation_list = []\n",
    "    \n",
    "    for sen_poss in sen_poss_list:\n",
    "        sen_translation = []\n",
    "        \n",
    "        wp_index = 0\n",
    "        cur_wp_index = 0\n",
    "        \n",
    "        for word_pos in sen_poss:\n",
    "            if wp_index == cur_wp_index:\n",
    "                word = dict_test_doc['Tokenized'][sp_index][wp_index]\n",
    "                \n",
    "                try: \n",
    "                    word2 = dict_test_doc['Tokenized'][sp_index][wp_index+1]\n",
    "                except:\n",
    "                    word2 = None\n",
    "                try:\n",
    "                    word3 = dict_test_doc['Tokenized'][sp_index][wp_index+2]\n",
    "                except:\n",
    "                    word3 = None\n",
    "                try:\n",
    "                    word4 = dict_test_doc['Tokenized'][sp_index][wp_index+3]\n",
    "                except:\n",
    "                    word4 = None\n",
    "                try:\n",
    "                    word5 = dict_test_doc['Tokenized'][sp_index][wp_index+4]\n",
    "                except:\n",
    "                    word5 = None\n",
    "                try:\n",
    "                    word6 = dict_test_doc['Tokenized'][sp_index][wp_index+5]\n",
    "                except:\n",
    "                    word6 = None\n",
    "                try:\n",
    "                    word7 = dict_test_doc['Tokenized'][sp_index][wp_index+6]\n",
    "                except:\n",
    "                    word7 = None\n",
    "                \n",
    "                ans = inFPhrases(word, word2, word3, word4, word5, word6, word7, il_phrases)\n",
    "                inFPDict = ans[0]\n",
    "                il_phrase = ans[1]\n",
    "                w_used = ans[2]                \n",
    "                \n",
    "                if inFPDict and il_phrase != []:\n",
    "                    p_index = il_phrases.index(il_phrase)\n",
    "                    tl_phrase = tl_phrases[p_index]\n",
    "                    for tl_word in tl_phrase:\n",
    "                        sen_translation.append(tl_word)\n",
    "                    cur_wp_index = wp_index + w_used\n",
    "                    \n",
    "                else:\n",
    "                    cur_wp_index = wp_index + 1\n",
    "\n",
    "                    # 1. SW\n",
    "                    if word_pos == 'SW':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'SW'\n",
    "                        \"\"\"\n",
    "                        if word in sw_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Ilokano list of single words\n",
    "                            \"\"\"\n",
    "                            temp_index = sw_il_list.index(word)\n",
    "                            isNone = False\n",
    "                            if sw_tl_list[temp_index][0] == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(sw_tl_list[temp_index][0])\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                    \n",
    "                    # 2. VB\n",
    "                    elif word_pos == 'VB':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'VB'\n",
    "                        \"\"\"\n",
    "                        if word in vb_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Ilokano list of verbs\n",
    "                            \"\"\"\n",
    "                            temp_index = vb_il_list.index(word)\n",
    "                            isNone = False\n",
    "                            if vb_tl_list[temp_index][0] == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(vb_tl_list[temp_index][0])\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                            \n",
    "                    # 3. NN\n",
    "                    elif word_pos == 'NN':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'NN'\n",
    "                        \"\"\"\n",
    "                        if word in nn_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of nouns\n",
    "                            \"\"\"\n",
    "                            temp_index = nn_il_list.index(word)\n",
    "                            isNone = False\n",
    "                            if nn_tl_list[temp_index][0] == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(nn_tl_list[temp_index][0])\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                                        \n",
    "                    # 4. JJ\n",
    "                    elif word_pos == 'JJ':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'JJ'\n",
    "                        \"\"\"\n",
    "                        if word in jj_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of nouns\n",
    "                            \"\"\"\n",
    "                            temp_index = jj_il_list.index(word)\n",
    "                            isNone = False\n",
    "                            if jj_tl_list[temp_index][0] == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(jj_tl_list[temp_index][0])\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                                    \n",
    "                    # 5. RB\n",
    "                    elif word_pos == 'RB':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'RB'\n",
    "                        \"\"\"\n",
    "                        if word in rb_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of nouns\n",
    "                            \"\"\"\n",
    "                            temp_index = rb_il_list.index(word)\n",
    "                            isNone = False\n",
    "                            if rb_tl_list[temp_index][0] == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(rb_tl_list[temp_index][0])\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                            \n",
    "                    # 6. CC\n",
    "                    elif word_pos == 'CC':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'CC'\n",
    "                        \"\"\"\n",
    "                        if word in cc_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of nouns\n",
    "                            \"\"\"\n",
    "                            temp_index = cc_il_list.index(word)\n",
    "                            isNone = False\n",
    "                            if cc_tl_list[temp_index][0] == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(cc_tl_list[temp_index][0])\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                                    \n",
    "                    # 7. PR\n",
    "                    elif word_pos == 'PR':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'CC'\n",
    "                        \"\"\"\n",
    "                        if word in pr_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of nouns\n",
    "                            \"\"\"\n",
    "                            temp_index = pr_il_list.index(word)\n",
    "                            if pr_tl_list[temp_index][0] == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(pr_tl_list[temp_index][0])\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                            \n",
    "                    # 7. DT\n",
    "                    elif word_pos == 'DT':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'DT'\n",
    "                        \"\"\"\n",
    "                        if word in dt_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of nouns\n",
    "                            \"\"\"\n",
    "                            temp_index = dt_il_list.index(word)\n",
    "                            if dt_tl_list[temp_index][0] == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(dt_tl_list[temp_index][0])\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                            \n",
    "                    else:\n",
    "                        sen_translation.append(word)\n",
    "            \n",
    "            wp_index += 1\n",
    "        sp_index += 1\n",
    "        sen_translation_list.append(sen_translation)\n",
    "    \n",
    "    return sen_translation_list\n",
    "\n",
    "sen_translation_list = translate(dict_test_doc['POS'])\n",
    "temp_sen_list = combine_tokens(sen_translation_list)\n",
    "\n",
    "dict_op_ex = pd.DataFrame({'Source Text': cleaned_test_doc, 'System Output': temp_sen_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_test_doc = target_op.split(\"\\n\")\n",
    "cleaned_target_op = [remove_punct(word) for word in parsed_test_doc]\n",
    "tokenized_target_op = [tokenize(word) for word in cleaned_target_op]\n",
    "combine_tokens_target_op = combine_tokens(tokenized_target_op)\n",
    "\n",
    "dict_op_ex['Target Output'] = combine_tokens_target_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_op_ex.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVING FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dict_il_tl_result = dict_op_ex.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"../../src/json data/Ilokano to Tagalog/Standard Translator/dict_il_tl_test.json\", \"w\") as outfile:\n",
    "        json.dump(dict_il_tl_result, outfile)\n",
    "    print(\"successfully saved the dict_il_tl_result.json file\")\n",
    "except:\n",
    "    print(\"Error in saving the dict_il_tl_result.json file\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1d54cc6ba22d92170a9f9c24d6077688435e22a85a4273e6fe4e4e6bdebfd02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
