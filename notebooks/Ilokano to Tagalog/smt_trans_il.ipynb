{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Machine Translation "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INITIALIZATION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.il_tl.rule_based_il import dict_il, remove_punct, tokenize, tag\n",
    "from module.tl_il.rule_based_tl import dict_tl\n",
    "from module.tl_il.doc_trans_tl import combine_tokens\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opening Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_il_tl_lm = pd.read_json('src/json data/Ilokano to Tagalog/Example-Based/Language Model/dict_il_tl_lang_mod.json')\n",
    "\n",
    "dict_il_tl_lm.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "il_struct = dict_il_tl_lm['Ilokano Structure'].tolist()\n",
    "tl_struct = dict_il_tl_lm['Tagalog Structure'].tolist()\n",
    "tl_struct_count = dict_il_tl_lm['Tagalog Structure Count'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    TF-IDF\n",
    "\"\"\"\n",
    "vb_il_tf_idf_list = dict_il.dict_vb['Ilokano Verb TF-IDF'].tolist()\n",
    "nn_il_tf_idf_list = dict_il.dict_nn['Ilokano Noun TF-IDF'].tolist()\n",
    "jj_il_tf_idf_list = dict_il.dict_jj['Ilokano Adjective TF-IDF'].tolist()\n",
    "rb_il_tf_idf_list = dict_il.dict_rb['Ilokano Adverb TF-IDF'].tolist()\n",
    "cc_il_tf_idf_list = dict_il.dict_cc['Ilokano Conjunction TF-IDF'].tolist()\n",
    "pr_il_tf_idf_list = dict_il.dict_pr['Ilokano Preposition TF-IDF'].tolist()\n",
    "dt_il_tf_idf_list = dict_il.dict_dt['Ilokano Determiner TF-IDF'].tolist()\n",
    "\n",
    "\"\"\"\n",
    "    Count Vectors\n",
    "\"\"\"\n",
    "vb_tl_tf_cnt_list = dict_il.dict_vb['Tagalog Verb Count'].tolist()\n",
    "nn_tl_tf_cnt_list = dict_il.dict_nn['Tagalog Noun Count'].tolist()\n",
    "jj_tl_tf_cnt_list = dict_il.dict_jj['Tagalog Adjective Count'].tolist()\n",
    "rb_tl_tf_cnt_list = dict_il.dict_rb['Tagalog Adverb Count'].tolist()\n",
    "cc_tl_tf_cnt_list = dict_il.dict_cc['Tagalog Conjunction Count'].tolist()\n",
    "pr_tl_tf_cnt_list = dict_il.dict_pr['Tagalog Preposition Count'].tolist()\n",
    "dt_tl_tf_cnt_list = dict_il.dict_dt['Tagalog Determiner Count'].tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HIERARCHIAL DEPENDENCE MODEL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding the SMT values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum_il(sen_poss_list, dict_source, not_in_sw, not_in_vb, not_in_nn, not_in_jj, not_in_rb, not_in_cc, not_in_pr, not_in_dt, not_tagged, sum_tf_idf_il_list):\n",
    "    sp_index = 0\n",
    "    \n",
    "    for sen_poss in sen_poss_list:\n",
    "        sen_translation = []\n",
    "        \n",
    "        sum_tf_idf_il = 0\n",
    "        wp_index = 0\n",
    "        \n",
    "        for word_pos in sen_poss:\n",
    "            word = dict_source['Tokenized'][sp_index][wp_index]\n",
    "               \n",
    "            # 1. SW\n",
    "            if word_pos == 'SW':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'SW'\n",
    "                \"\"\"\n",
    "                if word in dict_il.sw_il_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of single words\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_il.sw_il_list.index(word)\n",
    "                    \n",
    "                else:\n",
    "                    not_in_sw.append(word)\n",
    "                                \n",
    "            # 2. SW\n",
    "            elif word_pos == 'VB':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'VB'\n",
    "                \"\"\"\n",
    "                if word in dict_il.vb_il_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of verbs\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_il.vb_il_list.index(word)\n",
    "                    sum_tf_idf_il += vb_il_tf_idf_list[temp_index]\n",
    "                else:\n",
    "                    not_in_vb.append(word)\n",
    "            \n",
    "            # 3. NN\n",
    "            elif word_pos == 'NN':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'NN'\n",
    "                \"\"\"\n",
    "                if word in dict_il.nn_il_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of nouns\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_il.nn_il_list.index(word)\n",
    "                    sum_tf_idf_il += nn_il_tf_idf_list[temp_index]\n",
    "                else:\n",
    "                    not_in_nn.append(word)\n",
    "            \n",
    "            # 4. JJ\n",
    "            elif word_pos == 'JJ':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'JJ'\n",
    "                \"\"\"\n",
    "                if word in dict_il.jj_il_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of nouns\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_il.jj_il_list.index(word)\n",
    "                    sum_tf_idf_il += jj_il_tf_idf_list[temp_index]\n",
    "                else:\n",
    "                    not_in_jj.append(word)\n",
    "            \n",
    "            # 5. RB\n",
    "            elif word_pos == 'RB':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'RB'\n",
    "                \"\"\"\n",
    "                if word in dict_il.rb_il_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of nouns\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_il.rb_il_list.index(word)\n",
    "                    sum_tf_idf_il += rb_il_tf_idf_list[temp_index]\n",
    "                else:\n",
    "                    not_in_rb.append(word)\n",
    "                    \n",
    "            # 6. CC\n",
    "            elif word_pos == 'CC':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'CC'\n",
    "                \"\"\"\n",
    "                if word in dict_il.cc_il_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of nouns\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_il.cc_il_list.index(word)\n",
    "                    sum_tf_idf_il += cc_il_tf_idf_list[temp_index]\n",
    "                else:\n",
    "                    not_in_cc.append(word)\n",
    "                    \n",
    "            # 7. PR\n",
    "            elif word_pos == 'PR':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'CC'\n",
    "                \"\"\"\n",
    "                if word in dict_il.pr_il_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of nouns\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_il.pr_il_list.index(word)\n",
    "                    sum_tf_idf_il += pr_il_tf_idf_list[temp_index]\n",
    "                else:\n",
    "                    not_in_pr.append(word)\n",
    "            \n",
    "             # 8. DT\n",
    "            elif word_pos == 'DT':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'DT'\n",
    "                \"\"\"\n",
    "                if word in dict_il.dt_il_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of nouns\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_il.dt_il_list.index(word)\n",
    "                    sum_tf_idf_il += dt_il_tf_idf_list[temp_index]\n",
    "                else:\n",
    "                    not_in_dt.append(word)\n",
    "            \n",
    "            else:\n",
    "                not_tagged.append(word)\n",
    "                \n",
    "            wp_index += 1\n",
    "        \n",
    "        sum_tf_idf_il_list.append(round(sum_tf_idf_il, 5))\n",
    "        sp_index += 1\n",
    "        \n",
    "    return sum_tf_idf_il_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_lm(ngram_data):\n",
    "    trans_ngram_data = []\n",
    "    for ngram_sen in ngram_data:\n",
    "        trans_ngram_sen = []\n",
    "        \n",
    "        for ngram in ngram_sen:\n",
    "            if ngram in il_struct:\n",
    "                temp_index = il_struct.index(ngram)\n",
    "                max_count = max(tl_struct_count[temp_index])\n",
    "                trans_index = tl_struct_count[temp_index].index(max_count)\n",
    "                trans_ngram = tl_struct[temp_index][trans_index]\n",
    "                trans_ngram_sen.append(trans_ngram)\n",
    "            else:\n",
    "                trans_ngram_sen.append(ngram)\n",
    "        \n",
    "        trans_ngram_data.append(trans_ngram_sen)\n",
    "        \n",
    "    return trans_ngram_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "il_phrases = [remove_punct(word) for word in dict_il.il_phrases]\n",
    "il_phrases = [tokenize(word) for word in il_phrases]\n",
    "\n",
    "tl_phrases = [remove_punct(word) for word in dict_tl.tl_phrases]\n",
    "tl_phrases = [tokenize(word) for word in tl_phrases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inFPhrases(word, word2, word3, word4, word5, word6, word7, il_phrases):\n",
    "    inFPhrases = False\n",
    "    il_phrase = []\n",
    "    w_used = 0\n",
    "    for phrase in il_phrases:\n",
    "        length = len(phrase)\n",
    "        if length == 7:\n",
    "            if word == phrase[0] and word2 == phrase[1] and word3 == phrase[2] and word4 == phrase[3] and word5 == phrase[4] and word6 == phrase[5] and word7 == phrase[6]:\n",
    "                inFPhrases = True\n",
    "                tl_phrase = phrase\n",
    "                w_used = 7\n",
    "                break        \n",
    "        if length == 6:\n",
    "            if word == phrase[0] and word2 == phrase[1] and word3 == phrase[2] and word4 == phrase[3] and word5 == phrase[4] and word6 == phrase[5]:\n",
    "                inFPhrases = True\n",
    "                tl_phrase = phrase\n",
    "                w_used = 6\n",
    "                break\n",
    "        if length == 5:\n",
    "            if word == phrase[0] and word2 == phrase[1] and word3 == phrase[2] and word4 == phrase[3] and word5 == phrase[4]:\n",
    "                inFPhrases = True\n",
    "                tl_phrase = phrase\n",
    "                w_used = 5\n",
    "                break\n",
    "        if length == 4:\n",
    "            if word == phrase[0] and word2 == phrase[1] and word3 == phrase[2] and word4 == phrase[3]:\n",
    "                inFPhrases = True\n",
    "                tl_phrase = phrase\n",
    "                w_used = 4\n",
    "                break\n",
    "        if length == 3:\n",
    "            if word == phrase[0] and word2 == phrase[1] and word3 == phrase[2]:\n",
    "                inFPhrases = True\n",
    "                il_phrase = phrase\n",
    "                w_used = 3\n",
    "                break\n",
    "        if length == 2:\n",
    "            if word == phrase[0] and word2 == phrase[1]:\n",
    "                inFPhrases = True\n",
    "                il_phrase = phrase\n",
    "                w_used = 2\n",
    "                break\n",
    "        if length == 1:\n",
    "            if word == phrase[0]:\n",
    "                inFPhrases = True\n",
    "                il_phrase = phrase\n",
    "                w_used = 1\n",
    "                break\n",
    "                \n",
    "    return inFPhrases, il_phrase, w_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.smt import encapsulate, ngram_var\n",
    "\n",
    "def translate_smt(sen_poss_list, dict_source):\n",
    "    not_in_sw = []\n",
    "    not_in_vb = []\n",
    "    not_in_nn = []\n",
    "    not_in_jj = []\n",
    "    not_in_rb = []\n",
    "    not_in_cc = []\n",
    "    not_in_pr = []\n",
    "    not_in_dt = []\n",
    "    not_tagged = []\n",
    "    sum_tf_idf_il_list = []\n",
    "\n",
    "    sum_tf_idf_il_list = get_sum_il(sen_poss_list, dict_source, not_in_sw, not_in_vb, not_in_nn, not_in_jj, not_in_rb, not_in_cc, not_in_pr, not_in_dt, not_tagged, sum_tf_idf_il_list)\n",
    "    \n",
    "    encapsulate(sen_poss_list, ngram_var.fourgram_list, ngram_var.trigram_list, ngram_var.bigram_list, ngram_var.unigram_list, ngram_var.ngram_list, ngram_var.notencap_list, ngram_var.fourgram_count_sen, ngram_var.trigram_count_sen, ngram_var.bigram_count_sen, ngram_var.unigram_count_sen, ngram_var.notencap_count_sen)\n",
    "    \n",
    "    ngram_data = ngram_var.ngram_list\n",
    "    \n",
    "    trans_ngram_data = trans_lm(ngram_data)\n",
    "    \n",
    "    sp_index = 0\n",
    "    sen_translation_list = []\n",
    "    \n",
    "    for sen_poss in sen_poss_list:\n",
    "        \"\"\"\n",
    "        sen_poss is a list of POS of a sentence\n",
    "        eg. ['VB', 'DT', 'NN', 'DT', 'NN']\n",
    "        \"\"\"\n",
    "        sen_translation = []\n",
    "        wp_index = 0\n",
    "        cur_wp_index = 0\n",
    "        \n",
    "        for word_pos in sen_poss:\n",
    "            if wp_index == cur_wp_index:\n",
    "                word = dict_source['Tokenized'][sp_index][wp_index]\n",
    "                \n",
    "                try: \n",
    "                    word2 = dict_source['Tokenized'][sp_index][wp_index+1]\n",
    "                except:\n",
    "                    word2 = None\n",
    "                try:\n",
    "                    word3 = dict_source['Tokenized'][sp_index][wp_index+2]\n",
    "                except:\n",
    "                    word3 = None\n",
    "                try:\n",
    "                    word4 = dict_source['Tokenized'][sp_index][wp_index+3]\n",
    "                except:\n",
    "                    word4 = None\n",
    "                try:\n",
    "                    word5 = dict_source['Tokenized'][sp_index][wp_index+4]\n",
    "                except:\n",
    "                    word5 = None\n",
    "                try:\n",
    "                    word6 = dict_source['Tokenized'][sp_index][wp_index+5]\n",
    "                except:\n",
    "                    word6 = None\n",
    "                try:\n",
    "                    word7 = dict_source['Tokenized'][sp_index][wp_index+6]\n",
    "                except:\n",
    "                    word7 = None\n",
    "                \n",
    "                ans = inFPhrases(word, word2, word3, word4, word5, word6, word7, il_phrases)\n",
    "                inFPDict = ans[0]\n",
    "                il_phrase = ans[1]\n",
    "                w_used = ans[2]                \n",
    "                \n",
    "                if inFPDict and il_phrase != []:\n",
    "                    \"\"\"\n",
    "                    if the word is in the list of Tagalog phrases\n",
    "                    \"\"\"\n",
    "                    p_index = il_phrases.index(il_phrase)\n",
    "                    tl_phrase = tl_phrases[p_index]\n",
    "                    for tl_word in tl_phrase:\n",
    "                        sen_translation.append(tl_word)\n",
    "                    cur_wp_index = wp_index + w_used\n",
    "                    \n",
    "                else:\n",
    "                    cur_wp_index = wp_index + 1\n",
    "                \n",
    "                    # 1. SW\n",
    "                    if word_pos == 'SW':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'SW'\n",
    "                        \"\"\"\n",
    "                        if word in dict_il.sw_il_list:\n",
    "                            temp_index = dict_il.sw_il_list.index(word)\n",
    "                            if dict_il.sw_tl_list[temp_index][0] == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(dict_il.sw_tl_list[temp_index][0])\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                    \n",
    "                    # 2. VB\n",
    "                    elif word_pos == 'VB':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'VB'\n",
    "                        \"\"\"\n",
    "                        if word in dict_il.vb_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of verbs\n",
    "                            \"\"\"\n",
    "                            il_index = dict_il.vb_il_list.index(word)\n",
    "                            max_ilidf = max(dict_il.vb_tfidf_tl_list[il_index])\n",
    "                            tl_index = dict_il.vb_tfidf_tl_list[il_index].index(max_ilidf)\n",
    "                            tl_word = dict_il.vb_tl_list[il_index][tl_index]\n",
    "                            \n",
    "                            if tl_word == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(tl_word)\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                    \n",
    "                    # 3. NN\n",
    "                    elif word_pos == 'NN':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'NN'\n",
    "                        \"\"\"\n",
    "                        if word in dict_il.nn_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of noun\n",
    "                            \"\"\"\n",
    "                            il_index = dict_il.nn_il_list.index(word)\n",
    "                            max_ilidf = max(dict_il.nn_tfidf_tl_list[il_index])\n",
    "                            tl_index = dict_il.nn_tfidf_tl_list[il_index].index(max_ilidf)\n",
    "                            tl_word = dict_il.nn_tl_list[il_index][tl_index]\n",
    "                            \n",
    "                            if tl_word == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(tl_word)\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                    \n",
    "                    # 4. JJ\n",
    "                    elif word_pos == 'JJ':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'JJ'\n",
    "                        \"\"\"\n",
    "                        if word in dict_il.jj_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of adjectives\n",
    "                            \"\"\"\n",
    "                            il_index = dict_il.jj_il_list.index(word)\n",
    "                            max_ilidf = max(dict_il.jj_tfidf_tl_list[il_index])\n",
    "                            tl_index = dict_il.jj_tfidf_tl_list[il_index].index(max_ilidf)\n",
    "                            tl_word = dict_il.jj_tl_list[il_index][tl_index]\n",
    "                            \n",
    "                            if tl_word == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(tl_word)\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                            \n",
    "                    # 5. RB\n",
    "                    elif word_pos == 'RB':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'RB'\n",
    "                        \"\"\"\n",
    "                        if word in dict_il.rb_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of adverbs\n",
    "                            \"\"\"\n",
    "                            il_index = dict_il.rb_il_list.index(word)\n",
    "                            max_ilidf = max(dict_il.rb_tfidf_tl_list[il_index])\n",
    "                            tl_index = dict_il.rb_tfidf_tl_list[il_index].index(max_ilidf)\n",
    "                            tl_word = dict_il.rb_tl_list[il_index][tl_index]\n",
    "                            \n",
    "                            if tl_word == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(tl_word)\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                    \n",
    "                    # 6. CC\n",
    "                    elif word_pos == 'CC':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'CC'\n",
    "                        \"\"\"\n",
    "                        if word in dict_il.cc_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of conjunctions\n",
    "                            \"\"\"\n",
    "                            il_index = dict_il.cc_il_list.index(word)\n",
    "                            max_ilidf = max(dict_il.cc_tfidf_tl_list[il_index])\n",
    "                            tl_index = dict_il.cc_tfidf_tl_list[il_index].index(max_ilidf)\n",
    "                            tl_word = dict_il.cc_tl_list[il_index][tl_index]\n",
    "                            \n",
    "                            if tl_word == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(tl_word)\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                            \n",
    "                    # 7. PR\n",
    "                    elif word_pos == 'PR':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'PR'\n",
    "                        \"\"\"\n",
    "                        if word in dict_il.pr_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of prepositions\n",
    "                            \"\"\"\n",
    "                            il_index = dict_il.pr_il_list.index(word)\n",
    "                            max_ilidf = max(dict_il.pr_tfidf_tl_list[il_index])\n",
    "                            tl_index = dict_il.pr_tfidf_tl_list[il_index].index(max_ilidf)\n",
    "                            tl_word = dict_il.pr_tl_list[il_index][tl_index]\n",
    "                            \n",
    "                            if tl_word == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(tl_word)\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                            \n",
    "                    # 8. DT\n",
    "                    elif word_pos == 'DT':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'DT'\n",
    "                        \"\"\"\n",
    "                        if word in dict_il.dt_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of determiners\n",
    "                            \"\"\"\n",
    "                            il_index = dict_il.dt_il_list.index(word)\n",
    "                            max_ilidf = max(dict_il.dt_tfidf_tl_list[il_index])\n",
    "                            tl_index = dict_il.dt_tfidf_tl_list[il_index].index(max_ilidf)\n",
    "                            tl_word = dict_il.dt_tl_list[il_index][tl_index]\n",
    "                            \n",
    "                            if tl_word == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(tl_word)\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                    \n",
    "                    else:\n",
    "                        sen_translation.append(word)\n",
    "\n",
    "            wp_index += 1\n",
    "        sp_index += 1\n",
    "        sen_translation_list.append(sen_translation)\n",
    "    \n",
    "    return sen_translation_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRANSLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_smt_nb(test_doc, target_op):\n",
    "    parsed_source = test_doc.split(\"\\n\")\n",
    "\n",
    "    cleaned_source = [remove_punct(word) for word in parsed_source]\n",
    "    toklenized_source = [tokenize(word) for word in cleaned_source]\n",
    "    dict_source = pd.DataFrame({'Tokenized': toklenized_source})\n",
    "    pos_sen_list = tag(dict_source['Tokenized'])\n",
    "\n",
    "    dict_source['POS'] = pos_sen_list\n",
    "    sen_translation_list = translate_smt(dict_source['POS'], dict_source)\n",
    "    temp_sen_list = combine_tokens(sen_translation_list)\n",
    "\n",
    "    dict_op_ex = pd.DataFrame({'Source Text': cleaned_source})\n",
    "\n",
    "    parsed_expected_op = target_op.split(\"\\n\")\n",
    "    cleaned_expected_op = [remove_punct(word) for word in parsed_expected_op]\n",
    "    toklenized_expected_op = [tokenize(word) for word in cleaned_expected_op]\n",
    "    combine_tokens_expected_op = combine_tokens(toklenized_expected_op)\n",
    "    dict_op_ex['Target Output'] = combine_tokens_expected_op\n",
    "    dict_op_ex['System Output'] = temp_sen_list\n",
    "\n",
    "    dict_op_ex.head()\n",
    "    return dict_op_ex"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc = open(\"src/text data/Bible_Ilokano.txt\", encoding='utf-8').read()\n",
    "target_op = open(\"src/text data/Bible_Tagalog.txt\", encoding='utf-8').read()\n",
    "\n",
    "dict_train = translate_smt_nb(test_doc, target_op)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc = open(\"src/text data/testing/il_test_data_bible.txt\", encoding='utf-8').read()\n",
    "target_op = open(\"src/text data/testing/tl_test_data_bible.txt\", encoding='utf-8').read()\n",
    "\n",
    "dict_test = translate_smt_nb(test_doc, target_op)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVING FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_json(file_name, data):\n",
    "    try:\n",
    "        with open(file_name, \"w\") as outfile:\n",
    "            json.dump(data, outfile)\n",
    "        print(\"Successfully saved the file.\")\n",
    "    except: \n",
    "        print(\"Error in saving the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_op_ex_rec = dict_train.to_dict('records')\n",
    "dict_test_rec = dict_test.to_dict('records')\n",
    "\n",
    "save_to_json(\"src/json data/Ilokano to Tagalog/Hybrid Translator/dict_il-tl_op_ex.json\", dict_op_ex_rec)\n",
    "save_to_json(\"src/json data/Ilokano to Tagalog/Hybrid Translator/dict_il-tl_test.json\", dict_test_rec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1d54cc6ba22d92170a9f9c24d6077688435e22a85a4273e6fe4e4e6bdebfd02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
