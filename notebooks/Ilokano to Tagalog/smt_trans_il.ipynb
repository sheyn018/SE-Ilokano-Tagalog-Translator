{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Machine Translation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.il_tl.rule_based_il import dict_il, remove_punct, tokenize, tag\n",
    "from module.tl_il.rule_based_tl import dict_tl\n",
    "from module.tl_il.doc_trans_tl import combine_tokens\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of the Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ilokano Structure</th>\n",
       "      <th>Tagalog Structure</th>\n",
       "      <th>Tagalog Structure Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[SW]</td>\n",
       "      <td>[[SW]]</td>\n",
       "      <td>[10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[DT, VB, DT, NN]</td>\n",
       "      <td>[[VB, DT, NN], [DT, VB, DT, NN], [DT, NN, DT, ...</td>\n",
       "      <td>[97, 192, 37, 39, 46, 27]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[DT, NN]</td>\n",
       "      <td>[[DT, NN]]</td>\n",
       "      <td>[6140]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[DT, NN, VB]</td>\n",
       "      <td>[[DT, VB, DT, NN], [VB, DT, NN], [DT, NN, VB],...</td>\n",
       "      <td>[47, 344, 443, 158, 124, 47]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[CC]</td>\n",
       "      <td>[[CC]]</td>\n",
       "      <td>[3590]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ilokano Structure                                  Tagalog Structure  \\\n",
       "0              [SW]                                             [[SW]]   \n",
       "1  [DT, VB, DT, NN]  [[VB, DT, NN], [DT, VB, DT, NN], [DT, NN, DT, ...   \n",
       "2          [DT, NN]                                         [[DT, NN]]   \n",
       "3      [DT, NN, VB]  [[DT, VB, DT, NN], [VB, DT, NN], [DT, NN, VB],...   \n",
       "4              [CC]                                             [[CC]]   \n",
       "\n",
       "        Tagalog Structure Count  \n",
       "0                          [10]  \n",
       "1     [97, 192, 37, 39, 46, 27]  \n",
       "2                        [6140]  \n",
       "3  [47, 344, 443, 158, 124, 47]  \n",
       "4                        [3590]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_il_tl_lm = pd.read_json('src/json data/Ilokano to Tagalog/Example-Based/Language Model/dict_il_tl_lang_mod.json')\n",
    "\n",
    "dict_il_tl_lm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting the Structure Columns in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "il_struct = dict_il_tl_lm['Ilokano Structure'].tolist()\n",
    "tl_struct = dict_il_tl_lm['Tagalog Structure'].tolist()\n",
    "tl_struct_count = dict_il_tl_lm['Tagalog Structure Count'].tolist()\n",
    "\n",
    "# print(tl_struct_count[0].index(max(tl_struct_count[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting the SMT columns in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    TF-IDF\n",
    "\"\"\"\n",
    "vb_il_tf_idf_list = dict_il.dict_vb['Ilokano Verb TF-IDF'].tolist()\n",
    "nn_il_tf_idf_list = dict_il.dict_nn['Ilokano Noun TF-IDF'].tolist()\n",
    "jj_il_tf_idf_list = dict_il.dict_jj['Ilokano Adjective TF-IDF'].tolist()\n",
    "rb_il_tf_idf_list = dict_il.dict_rb['Ilokano Adverb TF-IDF'].tolist()\n",
    "cc_il_tf_idf_list = dict_il.dict_cc['Ilokano Conjunction TF-IDF'].tolist()\n",
    "pr_il_tf_idf_list = dict_il.dict_pr['Ilokano Preposition TF-IDF'].tolist()\n",
    "dt_il_tf_idf_list = dict_il.dict_dt['Ilokano Determiner TF-IDF'].tolist()\n",
    "\n",
    "\"\"\"\n",
    "    Count Vectors\n",
    "\"\"\"\n",
    "vb_tl_tf_cnt_list = dict_il.dict_vb['Tagalog Verb Count'].tolist()\n",
    "nn_tl_tf_cnt_list = dict_il.dict_nn['Tagalog Noun Count'].tolist()\n",
    "jj_tl_tf_cnt_list = dict_il.dict_jj['Tagalog Adjective Count'].tolist()\n",
    "rb_tl_tf_cnt_list = dict_il.dict_rb['Tagalog Adverb Count'].tolist()\n",
    "cc_tl_tf_cnt_list = dict_il.dict_cc['Tagalog Conjunction Count'].tolist()\n",
    "pr_tl_tf_cnt_list = dict_il.dict_pr['Tagalog Preposition Count'].tolist()\n",
    "dt_tl_tf_cnt_list = dict_il.dict_dt['Tagalog Determiner Count'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchial Dependence Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the SMT values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum_il(sen_poss_list, dict_source, not_in_sw, not_in_vb, not_in_nn, not_in_jj, not_in_rb, not_in_cc, not_in_pr, not_in_dt, not_tagged, sum_tf_idf_il_list):\n",
    "    sp_index = 0 # sentence POS index\n",
    "    \n",
    "    for sen_poss in sen_poss_list:\n",
    "        # loop for getting the pos structure of every sentence\n",
    "        \"\"\"\n",
    "        sen_poss is a list of POS of a sentence\n",
    "        eg. ['VB', 'DT', 'NN', 'DT', 'NN']\n",
    "        \"\"\"\n",
    "        sen_translation = []\n",
    "        \n",
    "        sum_tf_idf_il = 0\n",
    "        wp_index = 0 # word POS index\n",
    "        \n",
    "        for word_pos in sen_poss:\n",
    "            word = dict_source['Tokenized'][sp_index][wp_index]\n",
    "            # gets the word in every sentence\n",
    "            \n",
    "            # Matching Conditions    \n",
    "            # 1. SW\n",
    "            if word_pos == 'SW':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'SW'\n",
    "                \"\"\"\n",
    "                if word in dict_il.sw_il_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of single words\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_il.sw_il_list.index(word)\n",
    "                    \n",
    "                else:\n",
    "                    not_in_sw.append(word) # for debugging purposes\n",
    "                                \n",
    "            # 2. SW\n",
    "            elif word_pos == 'VB':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'VB'\n",
    "                \"\"\"\n",
    "                if word in dict_il.vb_il_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of verbs\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_il.vb_il_list.index(word)\n",
    "                    sum_tf_idf_il += vb_il_tf_idf_list[temp_index]\n",
    "                else:\n",
    "                    not_in_vb.append(word) # for debugging purposes\n",
    "            \n",
    "            # 3. NN\n",
    "            elif word_pos == 'NN':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'NN'\n",
    "                \"\"\"\n",
    "                if word in dict_il.nn_il_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of nouns\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_il.nn_il_list.index(word)\n",
    "                    sum_tf_idf_il += nn_il_tf_idf_list[temp_index]\n",
    "                else:\n",
    "                    not_in_nn.append(word) # for debugging purposes\n",
    "            \n",
    "            # 4. JJ\n",
    "            elif word_pos == 'JJ':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'JJ'\n",
    "                \"\"\"\n",
    "                if word in dict_il.jj_il_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of nouns\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_il.jj_il_list.index(word)\n",
    "                    sum_tf_idf_il += jj_il_tf_idf_list[temp_index]\n",
    "                else:\n",
    "                    not_in_jj.append(word) # for debugging purposes\n",
    "            \n",
    "            # 5. RB\n",
    "            elif word_pos == 'RB':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'RB'\n",
    "                \"\"\"\n",
    "                if word in dict_il.rb_il_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of nouns\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_il.rb_il_list.index(word)\n",
    "                    sum_tf_idf_il += rb_il_tf_idf_list[temp_index]\n",
    "                else:\n",
    "                    not_in_rb.append(word) # for debugging purposes\n",
    "                    \n",
    "            # 6. CC\n",
    "            elif word_pos == 'CC':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'CC'\n",
    "                \"\"\"\n",
    "                if word in dict_il.cc_il_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of nouns\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_il.cc_il_list.index(word)\n",
    "                    sum_tf_idf_il += cc_il_tf_idf_list[temp_index]\n",
    "                else:\n",
    "                    not_in_cc.append(word) # for debugging purposes\n",
    "                    \n",
    "            # 7. PR\n",
    "            elif word_pos == 'PR':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'CC'\n",
    "                \"\"\"\n",
    "                if word in dict_il.pr_il_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of nouns\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_il.pr_il_list.index(word)\n",
    "                    sum_tf_idf_il += pr_il_tf_idf_list[temp_index]\n",
    "                else:\n",
    "                    not_in_pr.append(word) # for debugging purposes\n",
    "            \n",
    "             # 8. DT\n",
    "            elif word_pos == 'DT':\n",
    "                \"\"\"\n",
    "                if the POS of the word is 'DT'\n",
    "                \"\"\"\n",
    "                if word in dict_il.dt_il_list:\n",
    "                    \"\"\"\n",
    "                    if the word is in the Tagalog list of nouns\n",
    "                    \"\"\"\n",
    "                    temp_index = dict_il.dt_il_list.index(word)\n",
    "                    sum_tf_idf_il += dt_il_tf_idf_list[temp_index]\n",
    "                else:\n",
    "                    not_in_dt.append(word) # for debugging purposes\n",
    "            \n",
    "            else:\n",
    "                not_tagged.append(word) # for debugging purposes\n",
    "                \n",
    "            wp_index += 1\n",
    "        \n",
    "        sum_tf_idf_il_list.append(round(sum_tf_idf_il, 5))\n",
    "        sp_index += 1\n",
    "        \n",
    "    return sum_tf_idf_il_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating with SMT translation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_lm(ngram_data):\n",
    "    trans_ngram_data = []\n",
    "    for ngram_sen in ngram_data:\n",
    "        trans_ngram_sen = []\n",
    "        \n",
    "        for ngram in ngram_sen:\n",
    "            if ngram in il_struct:\n",
    "                temp_index = il_struct.index(ngram)\n",
    "                max_count = max(tl_struct_count[temp_index])\n",
    "                trans_index = tl_struct_count[temp_index].index(max_count)\n",
    "                trans_ngram = tl_struct[temp_index][trans_index]\n",
    "                trans_ngram_sen.append(trans_ngram)\n",
    "            else:\n",
    "                trans_ngram_sen.append(ngram)\n",
    "                \n",
    "            # np_index += 1\n",
    "        \n",
    "        trans_ngram_data.append(trans_ngram_sen)\n",
    "        \n",
    "    return trans_ngram_data\n",
    "# end of function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "il_phrases = [remove_punct(word) for word in dict_il.il_phrases]\n",
    "il_phrases = [tokenize(word) for word in il_phrases]\n",
    "\n",
    "tl_phrases = [remove_punct(word) for word in dict_tl.tl_phrases]\n",
    "tl_phrases = [tokenize(word) for word in tl_phrases]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inFPhrases(word, word2, word3, word4, word5, word6, word7, il_phrases):\n",
    "    inFPhrases = False\n",
    "    il_phrase = []\n",
    "    w_used = 0\n",
    "    for phrase in il_phrases:\n",
    "        length = len(phrase)\n",
    "        if length == 7:\n",
    "            if word == phrase[0] and word2 == phrase[1] and word3 == phrase[2] and word4 == phrase[3] and word5 == phrase[4] and word6 == phrase[5] and word7 == phrase[6]:\n",
    "                inFPhrases = True\n",
    "                tl_phrase = phrase\n",
    "                w_used = 7\n",
    "                break        \n",
    "        if length == 6:\n",
    "            if word == phrase[0] and word2 == phrase[1] and word3 == phrase[2] and word4 == phrase[3] and word5 == phrase[4] and word6 == phrase[5]:\n",
    "                inFPhrases = True\n",
    "                tl_phrase = phrase\n",
    "                w_used = 6\n",
    "                break\n",
    "        if length == 5:\n",
    "            if word == phrase[0] and word2 == phrase[1] and word3 == phrase[2] and word4 == phrase[3] and word5 == phrase[4]:\n",
    "                inFPhrases = True\n",
    "                tl_phrase = phrase\n",
    "                w_used = 5\n",
    "                break\n",
    "        if length == 4:\n",
    "            if word == phrase[0] and word2 == phrase[1] and word3 == phrase[2] and word4 == phrase[3]:\n",
    "                inFPhrases = True\n",
    "                tl_phrase = phrase\n",
    "                w_used = 4\n",
    "                break\n",
    "        if length == 3:\n",
    "            if word == phrase[0] and word2 == phrase[1] and word3 == phrase[2]:\n",
    "                inFPhrases = True\n",
    "                il_phrase = phrase\n",
    "                w_used = 3\n",
    "                break\n",
    "        if length == 2:\n",
    "            if word == phrase[0] and word2 == phrase[1]:\n",
    "                inFPhrases = True\n",
    "                il_phrase = phrase\n",
    "                w_used = 2\n",
    "                break\n",
    "        if length == 1:\n",
    "            if word == phrase[0]:\n",
    "                inFPhrases = True\n",
    "                il_phrase = phrase\n",
    "                w_used = 1\n",
    "                break\n",
    "                \n",
    "    return inFPhrases, il_phrase, w_used\n",
    "# end of function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.smt import encapsulate, ngram_var\n",
    "\n",
    "def translate_smt(sen_poss_list, dict_source):\n",
    "    not_in_sw = []\n",
    "    not_in_vb = []\n",
    "    not_in_nn = []\n",
    "    not_in_jj = []\n",
    "    not_in_rb = []\n",
    "    not_in_cc = []\n",
    "    not_in_pr = []\n",
    "    not_in_dt = []\n",
    "    not_tagged = []\n",
    "    sum_tf_idf_il_list = []\n",
    "\n",
    "    sum_tf_idf_il_list = get_sum_il(sen_poss_list, dict_source, not_in_sw, not_in_vb, not_in_nn, not_in_jj, not_in_rb, not_in_cc, not_in_pr, not_in_dt, not_tagged, sum_tf_idf_il_list)\n",
    "    \n",
    "    encapsulate(sen_poss_list, ngram_var.fourgram_list, ngram_var.trigram_list, ngram_var.bigram_list, ngram_var.unigram_list, ngram_var.ngram_list, ngram_var.notencap_list, ngram_var.fourgram_count_sen, ngram_var.trigram_count_sen, ngram_var.bigram_count_sen, ngram_var.unigram_count_sen, ngram_var.notencap_count_sen)\n",
    "    \n",
    "    ngram_data = ngram_var.ngram_list\n",
    "    \n",
    "    trans_ngram_data = trans_lm(ngram_data)\n",
    "    \n",
    "    sp_index = 0 # sentence POS index\n",
    "    sen_translation_list = []\n",
    "    \n",
    "    for sen_poss in sen_poss_list:\n",
    "        # loop for getting the pos structure of every sentence\n",
    "        \"\"\"\n",
    "        sen_poss is a list of POS of a sentence\n",
    "        eg. ['VB', 'DT', 'NN', 'DT', 'NN']\n",
    "        \"\"\"\n",
    "        sen_translation = []\n",
    "        wp_index = 0\n",
    "        cur_wp_index = 0\n",
    "        \n",
    "        for word_pos in sen_poss:\n",
    "            if wp_index == cur_wp_index:\n",
    "                word = dict_source['Tokenized'][sp_index][wp_index]\n",
    "                # gets the word in every sentence\n",
    "                \n",
    "                try: \n",
    "                    word2 = dict_source['Tokenized'][sp_index][wp_index+1]\n",
    "                except:\n",
    "                    word2 = None\n",
    "                try:\n",
    "                    word3 = dict_source['Tokenized'][sp_index][wp_index+2]\n",
    "                except:\n",
    "                    word3 = None\n",
    "                try:\n",
    "                    word4 = dict_source['Tokenized'][sp_index][wp_index+3]\n",
    "                except:\n",
    "                    word4 = None\n",
    "                try:\n",
    "                    word5 = dict_source['Tokenized'][sp_index][wp_index+4]\n",
    "                except:\n",
    "                    word5 = None\n",
    "                try:\n",
    "                    word6 = dict_source['Tokenized'][sp_index][wp_index+5]\n",
    "                except:\n",
    "                    word6 = None\n",
    "                try:\n",
    "                    word7 = dict_source['Tokenized'][sp_index][wp_index+6]\n",
    "                except:\n",
    "                    word7 = None\n",
    "                \n",
    "                ans = inFPhrases(word, word2, word3, word4, word5, word6, word7, il_phrases)\n",
    "                inFPDict = ans[0]\n",
    "                il_phrase = ans[1]\n",
    "                w_used = ans[2]                \n",
    "                \n",
    "                if inFPDict and il_phrase != []:\n",
    "                    \"\"\"\n",
    "                    if the word is in the list of Tagalog phrases\n",
    "                    \"\"\"\n",
    "                    p_index = il_phrases.index(il_phrase)\n",
    "                    tl_phrase = tl_phrases[p_index]\n",
    "                    for tl_word in tl_phrase:\n",
    "                        sen_translation.append(tl_word)\n",
    "                    cur_wp_index = wp_index + w_used\n",
    "                    \n",
    "                else:\n",
    "                    cur_wp_index = wp_index + 1\n",
    "                \n",
    "                    # Matching Conditions    \n",
    "                    # 1. SW\n",
    "                    if word_pos == 'SW':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'SW'\n",
    "                        \"\"\"\n",
    "                        if word in dict_il.sw_il_list:\n",
    "                            temp_index = dict_il.sw_il_list.index(word)\n",
    "                            if dict_il.sw_tl_list[temp_index][0] == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(dict_il.sw_tl_list[temp_index][0])\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                    \n",
    "                    # 2. VB\n",
    "                    elif word_pos == 'VB':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'VB'\n",
    "                        \"\"\"\n",
    "                        if word in dict_il.vb_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of verbs\n",
    "                            \"\"\"\n",
    "                            il_index = dict_il.vb_il_list.index(word)\n",
    "                            max_ilidf = max(dict_il.vb_tfidf_tl_list[il_index])\n",
    "                            tl_index = dict_il.vb_tfidf_tl_list[il_index].index(max_ilidf)\n",
    "                            tl_word = dict_il.vb_tl_list[il_index][tl_index]\n",
    "                            \n",
    "                            if tl_word == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(tl_word)\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                    \n",
    "                    # 3. NN\n",
    "                    elif word_pos == 'NN':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'NN'\n",
    "                        \"\"\"\n",
    "                        if word in dict_il.nn_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of noun\n",
    "                            \"\"\"\n",
    "                            il_index = dict_il.nn_il_list.index(word)\n",
    "                            max_ilidf = max(dict_il.nn_tfidf_tl_list[il_index])\n",
    "                            tl_index = dict_il.nn_tfidf_tl_list[il_index].index(max_ilidf)\n",
    "                            tl_word = dict_il.nn_tl_list[il_index][tl_index]\n",
    "                            \n",
    "                            if tl_word == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(tl_word)\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                    \n",
    "                    # 4. JJ\n",
    "                    elif word_pos == 'JJ':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'JJ'\n",
    "                        \"\"\"\n",
    "                        if word in dict_il.jj_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of adjectives\n",
    "                            \"\"\"\n",
    "                            il_index = dict_il.jj_il_list.index(word)\n",
    "                            max_ilidf = max(dict_il.jj_tfidf_tl_list[il_index])\n",
    "                            tl_index = dict_il.jj_tfidf_tl_list[il_index].index(max_ilidf)\n",
    "                            tl_word = dict_il.jj_tl_list[il_index][tl_index]\n",
    "                            \n",
    "                            if tl_word == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(tl_word)\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                            \n",
    "                    # 5. RB\n",
    "                    elif word_pos == 'RB':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'RB'\n",
    "                        \"\"\"\n",
    "                        if word in dict_il.rb_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of adverbs\n",
    "                            \"\"\"\n",
    "                            il_index = dict_il.rb_il_list.index(word)\n",
    "                            max_ilidf = max(dict_il.rb_tfidf_tl_list[il_index])\n",
    "                            tl_index = dict_il.rb_tfidf_tl_list[il_index].index(max_ilidf)\n",
    "                            tl_word = dict_il.rb_tl_list[il_index][tl_index]\n",
    "                            \n",
    "                            if tl_word == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(tl_word)\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                    \n",
    "                    # 6. CC\n",
    "                    elif word_pos == 'CC':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'CC'\n",
    "                        \"\"\"\n",
    "                        if word in dict_il.cc_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of conjunctions\n",
    "                            \"\"\"\n",
    "                            il_index = dict_il.cc_il_list.index(word)\n",
    "                            max_ilidf = max(dict_il.cc_tfidf_tl_list[il_index])\n",
    "                            tl_index = dict_il.cc_tfidf_tl_list[il_index].index(max_ilidf)\n",
    "                            tl_word = dict_il.cc_tl_list[il_index][tl_index]\n",
    "                            \n",
    "                            if tl_word == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(tl_word)\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                            \n",
    "                    # 7. PR\n",
    "                    elif word_pos == 'PR':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'PR'\n",
    "                        \"\"\"\n",
    "                        if word in dict_il.pr_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of prepositions\n",
    "                            \"\"\"\n",
    "                            il_index = dict_il.pr_il_list.index(word)\n",
    "                            max_ilidf = max(dict_il.pr_tfidf_tl_list[il_index])\n",
    "                            tl_index = dict_il.pr_tfidf_tl_list[il_index].index(max_ilidf)\n",
    "                            tl_word = dict_il.pr_tl_list[il_index][tl_index]\n",
    "                            \n",
    "                            if tl_word == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(tl_word)\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                            \n",
    "                    # 8. DT\n",
    "                    elif word_pos == 'DT':\n",
    "                        \"\"\"\n",
    "                        if the POS of the word is 'DT'\n",
    "                        \"\"\"\n",
    "                        if word in dict_il.dt_il_list:\n",
    "                            \"\"\"\n",
    "                            if the word is in the Tagalog list of determiners\n",
    "                            \"\"\"\n",
    "                            il_index = dict_il.dt_il_list.index(word)\n",
    "                            max_ilidf = max(dict_il.dt_tfidf_tl_list[il_index])\n",
    "                            tl_index = dict_il.dt_tfidf_tl_list[il_index].index(max_ilidf)\n",
    "                            tl_word = dict_il.dt_tl_list[il_index][tl_index]\n",
    "                            \n",
    "                            if tl_word == 'None':\n",
    "                                sen_translation.append(word)\n",
    "                            else:\n",
    "                                sen_translation.append(tl_word)\n",
    "                        else:\n",
    "                            sen_translation.append(word)\n",
    "                    \n",
    "                    else:\n",
    "                        sen_translation.append(word)\n",
    "\n",
    "            wp_index += 1\n",
    "        sp_index += 1\n",
    "        sen_translation_list.append(sen_translation)\n",
    "    \n",
    "    return sen_translation_list\n",
    "# end of function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and processing the Source Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_smt_nb(test_doc, target_op):\n",
    "    parsed_source = test_doc.split(\"\\n\")\n",
    "\n",
    "    cleaned_source = [remove_punct(word) for word in parsed_source]\n",
    "    toklenized_source = [tokenize(word) for word in cleaned_source]\n",
    "    dict_source = pd.DataFrame({'Tokenized': toklenized_source})\n",
    "    pos_sen_list = tag(dict_source['Tokenized'])\n",
    "\n",
    "    dict_source['POS'] = pos_sen_list\n",
    "    # sen_translation_list = translate_smt(dict_source['POS'], dict_source)\n",
    "    sen_translation_list = translate_smt(dict_source['POS'], dict_source)\n",
    "    temp_sen_list = combine_tokens(sen_translation_list)\n",
    "\n",
    "    # Dictionary of the system output and the expected output and their scores\n",
    "    dict_op_ex = pd.DataFrame({'Source Text': cleaned_source})\n",
    "\n",
    "    parsed_expected_op = target_op.split(\"\\n\")\n",
    "    cleaned_expected_op = [remove_punct(word) for word in parsed_expected_op]\n",
    "    toklenized_expected_op = [tokenize(word) for word in cleaned_expected_op]\n",
    "    combine_tokens_expected_op = combine_tokens(toklenized_expected_op)\n",
    "    dict_op_ex['Target Output'] = combine_tokens_expected_op\n",
    "    dict_op_ex['System Output'] = temp_sen_list\n",
    "\n",
    "    dict_op_ex.head()\n",
    "    return dict_op_ex\n",
    "# end of function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the file\n",
    "# test_doc = open(\"src/text data/Bible_Ilokano.txt\", encoding='utf-8').read()\n",
    "# target_op = open(\"src/text data/Bible_Tagalog.txt\", encoding='utf-8').read()\n",
    "\n",
    "# dict_train = translate_smt_nb(test_doc, target_op)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the file\n",
    "test_doc = open(\"src/text data/testing data/Ilokano/il_test_data_bible.txt\", encoding='utf-8').read()\n",
    "target_op = open(\"src/text data/testing data/Tagalog/tl_test_data_bible.txt\", encoding='utf-8').read()\n",
    "\n",
    "dict_test = translate_smt_nb(test_doc, target_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# dict_op_ex_rec = dict_train.to_dict('records')\n",
    "\n",
    "# try:\n",
    "#     with open(\"src/json data/Ilokano to Tagalog/Hybrid Translator/dict_il-tl_op_ex.json\", \"w\") as outfile:\n",
    "#         json.dump(dict_op_ex_rec, outfile)\n",
    "#     print(\"Successfully saved the file.\")\n",
    "# except: \n",
    "#     print(\"Error in saving the file.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Testing result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved the file.\n"
     ]
    }
   ],
   "source": [
    "dict_test_rec = dict_test.to_dict('records')\n",
    "\n",
    "try:\n",
    "    with open(\"src/json data/Ilokano to Tagalog/Hybrid Translator/dict_il-tl_test.json\", \"w\") as outfile:\n",
    "        json.dump(dict_test_rec, outfile)\n",
    "    print(\"Successfully saved the file.\")\n",
    "except:\n",
    "    print(\"Error in saving the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dict_op_ex' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodule\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mscoring\u001b[39;00m \u001b[39mimport\u001b[39;00m scoring_bleu, scoring_ter\n\u001b[1;32m----> 3\u001b[0m ave_bleu \u001b[39m=\u001b[39m scoring_bleu(dict_op_ex)\n\u001b[0;32m      4\u001b[0m ave_ter \u001b[39m=\u001b[39m scoring_ter(dict_op_ex)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dict_op_ex' is not defined"
     ]
    }
   ],
   "source": [
    "from module.scoring import scoring_bleu, scoring_ter\n",
    "\n",
    "ave_bleu = scoring_bleu(dict_op_ex)\n",
    "ave_ter = scoring_ter(dict_op_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average TER Score: \", ave_ter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd5e40cb983109c15fc1053f6f3e661cc97e68e07c1758cdbd2441c60186ce19"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
